[
    {
        "index": 1,
        "question_id": 79621642,
        "title": "Is implicit conversion to std::optional guaranteed to use move constructor?",
        "body": "<p>The following code block illustrates a difference between returning a <code>std::optional</code> via an implicit conversion (i.e. <code>fn</code>) vs. an explicit construction (i.e. <code>fn2</code>).  Specifically, the implicit conversion (of an lvalue) invokes the move constructor, whereas the explicit construction invokes the copy constructor.</p>\n<p>How is it legal for the move constructor to be used in this situation?  Is the use of the move constructor guaranteed in this situation?</p>\n<pre><code>#include &lt;iostream&gt;\n#include &lt;optional&gt;\n\nclass Foo {\npublic:\n    Foo() { std::cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; '\\n'; }\n    ~Foo() { std::cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; '\\n'; }\n    Foo(const Foo&amp;) { std::cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; '\\n'; }\n    Foo&amp; operator=(const Foo&amp;) { std::cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; '\\n'; return *this; }\n    Foo(Foo&amp;&amp;) { std::cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; '\\n'; }\n    Foo&amp; operator=(Foo&amp;&amp;) { std::cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; '\\n'; return *this; }\n\n    int data[100];\n};\n\nstd::optional&lt;Foo&gt; fn(const Foo&amp; in)\n{\n    Foo out = in;\n    return out; // invokes Foo's move constructor\n}\n\nstd::optional&lt;Foo&gt; fn2(const Foo&amp; in)\n{\n    Foo out = in;\n    return std::optional&lt;Foo&gt;(out); // invokes Foo's copy constructor\n}\n\nint main()\n{\n    fn(Foo{});\n    fn2(Foo{});\n    return 0;\n}\n</code></pre>\n",
        "tags": [
            "c++",
            "move-constructor",
            "stdoptional"
        ]
    },
    {
        "index": 2,
        "question_id": 79620436,
        "title": "Combining fold expressions with lambdas in C++17",
        "body": "<p>I have a class that is derived from a variadic template parameter. The derived class and base classes have a method with the same signature.  The return type from each method is an object pointer.  I would like to call that method for each base class using a fold expression in such a way that the return\nvalue of the fold expression is a return value of a method that belongs to a certain base class type, or <code>nullptr</code> if that base type is not present in the variadic template parameter.</p>\n<p>The following working code illustrates this.   I am returning a non-null pointer from <code>Base::onMethod()</code> if Base is one of the template parameters, and <code>nullptr</code> if it is not.\nIn any case, <code>onMethod()</code> is called for all templates.</p>\n<pre><code>#include &lt;iostream&gt;  \n#include &lt;type_traits&gt;  \n  \n\nstruct Ret {  \n};  \n  \nstruct B1 {  \n    Ret* onMethod() {  \n        std::cerr &lt;&lt; &quot;B1\\n&quot;;  \n        return nullptr;  \n    }  \n};  \n  \nstruct B2 {  \n    Ret* onMethod() {  \n        std::cerr &lt;&lt; &quot;B2\\n&quot;;  \n        return nullptr;  \n    }  \n};  \n  \nstruct Base {  \n    Ret* onMethod() {  \n        std::cerr &lt;&lt; &quot;Base\\n&quot;;  \n        return new Ret();  \n    }  \n};  \n  \ntemplate&lt;typename... Bases&gt;  \nstruct D : public Bases... {  \n    Ret* onMethod() {  \n        Ret* result = nullptr;                                                                                                                       \n        ( [&amp;result, this]() {                                                                                                                        \n           auto* r = Bases::onMethod();                                                                                                              \n           if constexpr (std::is_same&lt;Bases, Base&gt;::value) result = r;                                                                               \n           }(), ...);                                                                                                                                \n        return result;                                                                                                                               \n    }                                                                                                                                                \n};                                                                                                                                                   \n                                                                                                                                                     \nint main(void) {                                                                                                                                     \n    D&lt;B1, B2, Base&gt; d;                                                                                                                               \n    auto* r = d.onMethod();                                                                                                                          \n    std::cerr &lt;&lt; (r == nullptr) &lt;&lt; std::endl;                                                                                                        \n    D&lt;B1, B2&gt; d1;                                                                                                                                    \n    auto r1 = d1.onMethod();                                                                                                                         \n    std::cerr &lt;&lt; (r1 == nullptr) &lt;&lt; std::endl;                                                                                                       \n    return 0;                                                                                                                                        \n}     \n</code></pre>\n<p>To compile:</p>\n<pre><code>g++ -std=c++17 file.cpp\n</code></pre>\n<p>Notice that I have used a lambda in the <code>onMethod()</code> method of the derived class.</p>\n<p>Is there a better and shorter syntax for <code>D::onMethod()</code>, potentially the one that does not use a lambda call?</p>\n",
        "tags": [
            "c++",
            "c++17",
            "fold-expression"
        ]
    },
    {
        "index": 3,
        "question_id": 79624592,
        "title": "ERROR: (gcloud.app.deploy) Error Response: [13] Failed to create cloud build: API key expired. Please renew the API key",
        "body": "<p>Today, all of my projects started returning the mysterious un-googlable error when running <code>gcloud app deploy</code>:</p>\n<pre><code>ERROR: (gcloud.app.deploy) Error Response: [13] Failed to create cloud build: API key expired. Please renew the API key..\n</code></pre>\n<p>Doing <code>gcloud auth login</code> and even removing <code>.config/gcloud/</code> completely doesn't fix this issue. How can I debug this further? Just a few hours ago everything was functioning correctly.</p>\n<p>File upload succeeds, just the &quot;Updating service&quot; step that fails.</p>\n",
        "tags": [
            "google-app-engine"
        ]
    },
    {
        "index": 4,
        "question_id": 79623397,
        "title": "Why does the variadic template function behave differently from the template function?",
        "body": "<p>Let suppose I have this example:</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>template&lt;class... T&gt; struct Strct\n{\n    Strct(double){};\n};\n    \ntemplate&lt;class... T&gt; void foo(Strct&lt;T...&gt;) {}\ntemplate&lt;class  T&gt;   void foo2(Strct&lt;T&gt;) {}\n</code></pre>\n<p>If I call this:</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>foo&lt;double&gt;(1.); // error: no matching function for call to 'foo&lt;double&gt;(double)'\nfoo2&lt;double&gt;(1.); // Ok \n</code></pre>\n<p><a href=\"https://godbolt.org/z/vbP9ebfoc\" rel=\"nofollow noreferrer\">Demo</a></p>\n<p>I don't understand why there is a difference. In my mind, since I give the full list of the templates parameters, the compiler shouldn't have anything to deduce, and both call should be equivalent to this:</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>void foo2(Strct&lt;double&gt;) {}\n</code></pre>\n<p>It's obviously not the case. If the answer can give the name of the mechanism in play in here, it will be great.</p>\n<hr />\n<p>PS:</p>\n<p>I have a gut feeling it should be close to <a href=\"https://stackoverflow.com/questions/68675444/\">why would type_identity make a difference?</a> but I didn't find anything in the related documentation.</p>\n",
        "tags": [
            "c++",
            "variadic-templates"
        ]
    },
    {
        "index": 5,
        "question_id": 79620522,
        "title": "How do I make a generic method that can convert all strings in a record to lowercase in Delphi?",
        "body": "<p>I want a procedure that does something like this:</p>\n<pre><code>procedure RecordStringToLower(var MyRecord);\nbegin\n  // 1. Loop through all fields\n  // 2. Find string fields\n  // 3. Convert all string fields to lowercase\nend;\n</code></pre>\n<p>I know there are probably various ways to accomplish this, but it'll probably need to happen via generics and RTTI?. Any suggestions?</p>\n<p>I'm not picky at all in terms of how the procedure or function works.</p>\n<hr />\n<p>I tried a couple of different things, and this is the closest that I came, but it doesn't work:</p>\n<pre><code>class procedure TRecordHelper.RecordStringToLower&lt;T&gt;(var ARecord: T);\nbegin\n  var Context := TRttiContext.Create;\n  try\n    var RttiType := Context.GetType(TypeInfo(T));\n    for var Field in RttiType.GetFields do\n    begin\n      if (Field.FieldType.TypeKind = TTypeKind.tkString) then\n        Field.SetValue(@ARecord, Field.GetValue(@ARecord).AsString.ToLower);\n    end;\n  finally\n    Context.Free;\n  end;\nend;\n</code></pre>\n<p>I don't understand RTTI enough.</p>\n",
        "tags": [
            "delphi",
            "generics",
            "record",
            "rtti",
            "delphi-12-athens"
        ]
    },
    {
        "index": 6,
        "question_id": 79622707,
        "title": "Why doesn&#39;t my Gatherer short-circuit the Stream if the source is an IntStream?",
        "body": "<p>I'm playing around with Stream Gatherers, which were introduced (or, at least, lost preview-status) in Java 24. As an exercise, I implemented my own version of the <code>limit</code> intermediate operation:</p>\n<pre><code>public class LimitDemo {\n\n    private static class State {\n        int count;\n    }\n\n    static &lt;T&gt; Gatherer&lt;T, ?, T&gt; limit(int size) {\n        Supplier&lt;State&gt; initializer = State::new;\n        Gatherer.Integrator&lt;State, T, T&gt; integrator = (state, element, downstream) -&gt; {\n            if (++state.count &gt; size) {\n                return false;\n            }\n            return downstream.push(element);\n        };\n        return Gatherer.ofSequential(initializer, integrator);\n    }\n\n    public static void main(String[] args) {\n        var rng = new Random();\n        var result = \n            Stream.generate(() -&gt; rng.nextInt(10)) // here\n            .gather(limit(10))\n            .toList();\n        System.out.println(result);\n    }\n}\n</code></pre>\n<p>This works very well: a list of 10 random numbers is printed on the screen, as I expected. The infinite stream of random Integers is short-circuited.</p>\n<p>However, if I generate the infinite stream in another way, it doesn't work anymore. If I replace the line marked <code>// here</code> with</p>\n<pre><code>rng.ints(0, 10).boxed()\n</code></pre>\n<p>then my program terminates with an OutOfMemoryException. Apparently, the IntStream generated by the <code>Random</code> instance doesn't notice that my Gatherer short-circuits. Of course, when I use the standard <code>limit</code> instead of my custom one, it works in both cases.</p>\n<p>What am I missing?</p>\n",
        "tags": [
            "java",
            "java-stream",
            "java-24"
        ]
    },
    {
        "index": 7,
        "question_id": 79620364,
        "title": "unsigned arithmetic - an indication that an overflow happened (ok! not happened but avoided by modular arithmetic)",
        "body": "<p>I perform a subtraction with an unsigned type, say std::uint8_t. I can understand if the result will be obtained by modular arithmetic or not, by means of a comparison:</p>\n<pre><code>auto subtract (std::uint8_t x, std::uint8_t y) -&gt; std::pair&lt;std::uint8_t, bool&gt;\n{\nreturn {x - y, x &lt; y};\n}\n</code></pre>\n<p>My question is the following: Can I avoid the comparison to know if modular arithmetic was in action or not? In other words, does the cpu provide an indication that it happened? Or shall I not worry: Would the compiler somehow optimize the subtraction and comparison operations somehow that the additional comparison won't introduce additional cost?</p>\n<p>edt: adapt the example code so that the focus is on the question.</p>\n",
        "tags": [
            "c++",
            "unsigned",
            "modular-arithmetic"
        ]
    },
    {
        "index": 8,
        "question_id": 79620502,
        "title": "PHP Reference Map - Const vs Static",
        "body": "<p>I'm newer to PHP 8.  I'm working in code where there are a number of 'constant' mappings.  They are done using a static array in various classe.  Example:</p>\n<pre><code>public static $mapNamedIds = array(\n    &quot;NamedItem1&quot; =&gt; 1234, \n    &quot;NamedItem2&quot; =&gt; 2345, \n    &quot;NamedItem3&quot; =&gt; 3456,\n);\n</code></pre>\n<p>Is there a reason it should not be implemented like this?  Example:</p>\n<pre><code>public const NAMED_IDS_MAP = array(\n    &quot;NamedItem1&quot; =&gt; 1234, \n    &quot;NamedItem2&quot; =&gt; 2345, \n    &quot;NamedItem3&quot; =&gt; 3456,\n);\n</code></pre>\n<p>Is there a reason why static would be better than using a const array?  Other than the 'const' actually being constant.  Is there a performance benefit of const over static?  Again these are typically defined in classes and are not globals...</p>\n",
        "tags": [
            "php",
            "arrays",
            "performance",
            "mapping"
        ]
    },
    {
        "index": 9,
        "question_id": 79620845,
        "title": "How is np.repeat so fast?",
        "body": "<p>I am implementing the Poisson bootstrap in Rust and wanted to benchmark my repeat function against numpy's. Briefly, <code>repeat</code> takes in two arguments, data and weight, and repeats each element of data by the weight, e.g. [1, 2, 3], [1, 2, 0] -&gt; [1, 2, 2]. My naive version was around 4.5x slower than <code>np.repeat</code>.</p>\n<pre class=\"lang-rust prettyprint-override\"><code>pub fn repeat_by(arr: &amp;[f64], repeats: &amp;[u64]) -&gt; Vec&lt;f64&gt; {\n    // Use flat_map to create a single iterator of all repeated elements\n    let result: Vec&lt;f64&gt; = arr\n        .iter()\n        .zip(repeats.iter())\n        .flat_map(|(&amp;value, &amp;count)| std::iter::repeat_n(value, count as usize))\n        .collect();\n\n    result\n}\n</code></pre>\n<p>I also tried a couple of more versions, e.g. one where I pre-allocated a vector with the necessary capacity, but all performed similarly.</p>\n<p>While doing more investigating though, I found that <code>np.repeat</code> is actually way faster than other numpy functions that I expected to perform similarly. For example, we can build a list of indices and use numpy slicing / take to perform the same operation as <code>np.repeat</code>. However, doing this (and even removing the list construction from the timings), <code>np.repeat</code> is around 3x faster than numpy slicing / take.</p>\n<pre class=\"lang-py prettyprint-override\"><code>import timeit\n\nimport numpy as np\n\nN_ROWS = 100_000\nx = np.random.rand(N_ROWS)\n\nweight = np.random.poisson(1, len(data))\n\n\n# pre-compute the indices so slow python looping doesn't affect the timing\nindices = []\nfor w in weight:\n    for i in range(w):\n        indices.append(i)\n\n\nprint(timeit.timeit(lambda: np.repeat(x, weight), number=1_000))  # 0.8337333500003297\nprint(timeit.timeit(lambda: np.take(x, indices), number=1_000))  # 3.1320624930012855\n</code></pre>\n<p>My C is not so good, but it seems like the relevant implementation is here: <a href=\"https://github.com/numpy/numpy/blob/main/numpy/_core/src/multiarray/item_selection.c#L785\" rel=\"nofollow noreferrer\">https://github.com/numpy/numpy/blob/main/numpy/_core/src/multiarray/item_selection.c#L785</a>. It would be amazing if someone could help me understand at a high level what this code is doing--on the surface, it doesn't look like anything particularly special (SIMD, etc.), and looks pretty similar to my naive Rust version (memcpy vs repeat_n). In addition, I am struggling to understand why it performs so much better than even numpy slicing.</p>\n",
        "tags": [
            "python",
            "arrays",
            "numpy",
            "rust"
        ]
    },
    {
        "index": 10,
        "question_id": 79620882,
        "title": "Why does pointer != NULL, but prints as (nil) with %p format specifier?",
        "body": "<p>I'm experiencing an unusual issue in my C program where a pointer that is checked to be not <code>NULL</code> prints as (nil) when using the <code>%p</code> format specifier.</p>\n<p>Here's a simplified version of my code:</p>\n<pre class=\"lang-c prettyprint-override\"><code>#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n\nint main(int argc, char *argv[]){\n\n    int arg1 = atoi(argv[1]);\n    int arg2 = atoi(argv[2]);\n\n    double * res = NULL; \n    res = (double *) malloc(sizeof(double)* 100);\n    \n    double * tmp = NULL; \n\n    for (; arg1 != arg2; ++arg1)\n    {\n        tmp = (double *)realloc(tmp, sizeof(double) * 1);\n    }\n    \n    memcpy(res, tmp, 0);\n    \n    if(tmp != NULL){\n        printf(&quot;addr =  %p\\n&quot;, tmp);\n        printf(&quot;val =  %u\\n&quot;, tmp);\n    }\n\n    return 0;\n}\n</code></pre>\n<p>I compiled and run with :</p>\n<pre><code>gcc ./test.c -O2\n./a.out 1 1\n</code></pre>\n<p>Despite checking that tmp is not <code>NULL</code>, the output I get is:</p>\n<pre class=\"lang-none prettyprint-override\"><code>addr =  (nil)\nval =  0\n</code></pre>\n<p>My understanding is that a pointer with the address <code>0</code> represents <code>NULL</code>.</p>\n<p>But I compiled and run with :</p>\n<pre><code>gcc ./test.c\n./a.out 1 1\n</code></pre>\n<p>There no output.</p>\n<p>I've compiled this code using GCC 11.4.0 on Ubuntu 22.04.4 LTS.</p>\n<p>What could be causing this discrepancy? How does flags <code>O2</code> effect the output? Any insights would be greatly appreciated.</p>\n",
        "tags": [
            "c",
            "pointers",
            "gcc"
        ]
    },
    {
        "index": 11,
        "question_id": 79620893,
        "title": "How to tidy messy data",
        "body": "<p>I have a messy data set, which generally resembles the output of the following</p>\n<pre><code>schools_messy &lt;- tibble::tribble(\n  ~data,\n  &quot;state:maryland&quot;,\n  &quot;location:bowie||name:bowie state university&quot;,\n  &quot;grade:freshman||count:100&quot;,\n  &quot;grade:sophomore||count:200&quot;,\n  &quot;grade:junior||count:300&quot;,\n  &quot;grade:senior||count:400&quot;,\n  &quot;location:baltimore||name:coppin state university&quot;,\n  &quot;grade:freshman||count:100&quot;,\n  &quot;grade:sophomore||count:200&quot;,\n  &quot;grade:junior||count:300&quot;,\n  &quot;grade:senior||count:400&quot;,\n  \n  &quot;state:virginia&quot;,\n  &quot;location:williamsburg||name:college of william and mary&quot;,\n  &quot;grade:freshman||count:100&quot;,\n  &quot;grade:sophomore||count:200&quot;,\n  &quot;grade:junior||count:300&quot;,\n  &quot;grade:senior||count:400&quot;,\n  &quot;location:fairfax||name:george mason university&quot;,\n  &quot;grade:freshman||count:100&quot;,\n  &quot;grade:sophomore||count:200&quot;,\n  &quot;grade:junior||count:300&quot;,\n  &quot;grade:senior||count:400&quot;,\n)\n</code></pre>\n<p>My desired end state is to have it resemble the output of the following</p>\n<pre><code>schools_tidy &lt;- tribble(\n  ~state, ~location, ~name, ~grade, ~count,\n  &quot;maryland&quot;, &quot;bowie&quot;, &quot;bowie state university&quot;, &quot;freshman&quot;, 100,\n  &quot;maryland&quot;, &quot;bowie&quot;, &quot;bowie state university&quot;, &quot;sophomore&quot;, 200,\n  &quot;maryland&quot;, &quot;bowie&quot;, &quot;bowie state university&quot;, &quot;junior&quot;, 300,\n  &quot;maryland&quot;, &quot;bowie&quot;, &quot;bowie state university&quot;, &quot;senior&quot;, 400,\n  &quot;maryland&quot;, &quot;baltimore&quot;, &quot;coppin state university&quot;, &quot;freshman&quot;, 100,\n  &quot;maryland&quot;, &quot;baltimore&quot;, &quot;coppin state university&quot;, &quot;sophomore&quot;, 200,\n  &quot;maryland&quot;, &quot;baltimore&quot;, &quot;coppin state university&quot;, &quot;junior&quot;, 300,\n  &quot;maryland&quot;, &quot;baltimore&quot;, &quot;coppin state university&quot;, &quot;senior&quot;, 400,\n  &quot;virginia&quot;, &quot;williamsburg&quot;, &quot;college of william and mary&quot;, &quot;freshman&quot;, 100,\n  &quot;virginia&quot;, &quot;williamsburg&quot;, &quot;college of william and mary&quot;, &quot;sophomore&quot;, 200,\n  &quot;virginia&quot;, &quot;williamsburg&quot;, &quot;college of william and mary&quot;, &quot;junior&quot;, 300,\n  &quot;virginia&quot;, &quot;williamsburg&quot;, &quot;college of william and mary&quot;, &quot;senior&quot;, 400,\n  &quot;virginia&quot;, &quot;fairfax&quot;, &quot;george mason university&quot;, &quot;freshman&quot;, 100,\n  &quot;virginia&quot;, &quot;fairfax&quot;, &quot;george mason university&quot;, &quot;sophomore&quot;, 200,\n  &quot;virginia&quot;, &quot;fairfax&quot;, &quot;george mason university&quot;, &quot;junior&quot;, 300,\n  &quot;virginia&quot;, &quot;fairfax&quot;, &quot;george mason university&quot;, &quot;senior&quot;, 400,\n)\n</code></pre>\n<p>I'm afraid that I'm quite at a loss for how to go about cleaning up the data set.  It almost resembles a mangled json data set.  I tried to do some manipulation to turn it into a proper json data set, then convert it to the desired tibble end state from there, but I was unsuccessful.</p>\n",
        "tags": [
            "r",
            "tidyverse",
            "data-wrangling"
        ]
    },
    {
        "index": 12,
        "question_id": 79620897,
        "title": "GNU as recursive/loop macro expected output",
        "body": "<p>In this assembly file below, the macro <code>jump_table</code> should automagically create ... a <em>jump table</em> to consecutively numbered labels like <code>jump_0</code>, <code>jump_1</code>, ... <code>jump_&lt;n&gt;</code>.</p>\n<p>It seems there is no loop feature in <code>as</code> <code>.macro</code> directive and the official <a href=\"https://sourceware.org/binutils/docs/as/Macro.html\" rel=\"nofollow noreferrer\">documentation</a> seems to suggest what appears to be a recursive macro.</p>\n<p>Anyway, this is the file:</p>\n<pre class=\"lang-none prettyprint-override\"><code>.section .text\n.align 4\n\n.macro jump_table name init last\n  j \\name\\()_\\init\n  .if \\last &gt; \\init\n  jump_table \\name \\init+1 \\last\n  .endif\n.endm\n\njump_table jump 0 3\n\njump_0:\n  nop\njump_1:\n  nop\n  nop\njump_2:\n  nop\n  nop\n  nop\njump_3:\n  nop\n  nop\n  nop\n  nop\n</code></pre>\n<p>The resulting binary, once disassembled with <code>objdump</code>, yields this:</p>\n<pre><code>0000000000000000 &lt;jump_0-0x1c&gt;:\n   0:   00000013            nop\n   4:   00000013            nop\n   8:   00000013            nop\n   c:   0100006f            j   1c &lt;jump_0&gt;\n  10:   00c0006f            j   1c &lt;jump_0&gt;\n  14:   00a0006f            j   1e &lt;jump_0+0x2&gt;\n  18:   0060006f            j   1e &lt;jump_0+0x2&gt;\n\n000000000000001c &lt;jump_0&gt;:\n  1c:   00000013            nop\n\n0000000000000020 &lt;jump_1&gt;:\n  20:   00000013            nop\n  24:   00000013            nop\n\n0000000000000028 &lt;jump_2&gt;:\n  28:   00000013            nop\n  2c:   00000013            nop\n  30:   00000013            nop\n\n0000000000000034 &lt;jump_3&gt;:\n  34:   00000013            nop\n  38:   00000013            nop\n  3c:   00000013            nop\n  40:   00000013            nop\n  44:   00000013            nop\n  48:   00000013            nop\n  4c:   00000013            nop\n</code></pre>\n<p>The jump table looks weird to me: offsets are decreasing while I would expect them to increase. Moreover, labelling also looks weird.</p>\n<p>If I understood correctly, I should expect something like:</p>\n<pre><code>  j   1c &lt;jump_0&gt;\n  j   20 &lt;jump_1&gt;\n  j   28 &lt;jump_2&gt;\n  j   34 &lt;jump_3&gt;\n</code></pre>\n<p>I bet I am missing something and some explanation would help me greatly.</p>\n<p>I am using <code>riscv64-elf-as</code> and <code>riscv64-elf-objdump</code> v2.44 on MacOS M4.</p>\n",
        "tags": [
            "assembly",
            "macros",
            "riscv",
            "gnu-assembler"
        ]
    },
    {
        "index": 13,
        "question_id": 79621488,
        "title": "What is the use of std::ranges::views::lazy_split when we have std::ranges::views::split?",
        "body": "<p>C++20 introduced two range adapters for splitting sequences: <a href=\"https://en.cppreference.com/w/cpp/ranges/split_view\" rel=\"nofollow noreferrer\"><code>std::ranges::views::split</code></a> and <a href=\"https://en.cppreference.com/w/cpp/ranges/lazy_split_view\" rel=\"nofollow noreferrer\"><code>std::ranges::views::lazy_split</code></a>.</p>\n<p>At first glance, <code>views::split</code> seems clearly superior:</p>\n<ul>\n<li>Subranges preserve their continuity and allow direct conversion to <code>std::string_view</code> or <code>std::span</code>.</li>\n<li>You can use <code>.data()</code>, <code>.size()</code>, and standard parsing functions like <code>std::from_chars</code>.</li>\n<li>It works well for parsing, tokenization, and storing results for later use.</li>\n</ul>\n<p>In contrast, <code>views::lazy_split</code> has significant limitations:</p>\n<ul>\n<li>Its subranges don’t provide contiguous storage.</li>\n<li>You cannot directly convert subranges to <code>std::string_view</code>.</li>\n<li>Accessing the split parts often requires manual copying or <code>std::ranges::to</code> (C++23).</li>\n</ul>\n<p>Is there a practical scenario where <code>lazy_split</code> is actually better or preferred over <code>split</code>? Or is it mostly a legacy artifact after the design changes introduced by <a href=\"https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p2210r2.html\" rel=\"nofollow noreferrer\">P2210R2</a>?</p>\n",
        "tags": [
            "c++",
            "c++20"
        ]
    },
    {
        "index": 14,
        "question_id": 79622113,
        "title": "Go GC doesn&#39;t collect dead weak pointers",
        "body": "<p>I am trying to use weak pointers introduced in go1.24 to build a system in which weak pointers can be passed as interfaces. The problem is that weak.Pointer doesn't follow the same interface as the strong pointer it wraps. To fix this I create a wrapper which holds a weak pointer and implements the interface of the original pointer, it passes calls to the referenced object or returns an error if it was already GC-ed.</p>\n<p>Here is the code:</p>\n<pre class=\"lang-golang prettyprint-override\"><code>package main\n\nimport (\n    &quot;errors&quot;\n    &quot;fmt&quot;\n    &quot;runtime&quot;\n    &quot;runtime/debug&quot;\n    &quot;weak&quot;\n)\n\n// Job is the interface your layers all share.\ntype Job interface {\n    Execute() error\n}\n\n// ErrInvalidJob signals the underlying *MyJob has been GC’d.\nvar ErrInvalidJob = errors.New(&quot;job invalid (GC’ed)&quot;)\n\n// MyJob is your concrete implementation.\ntype MyJob struct {\n    id int\n}\n\nfunc (j *MyJob) Execute() error {\n    fmt.Printf(&quot;running MyJob %d\\n&quot;, j.id)\n    return nil\n}\n\n// WeakMyJob wraps a *MyJob into a Job by using a weak.Pointer.\ntype WeakMyJob struct {\n    wp weak.Pointer[MyJob]\n}\n\nfunc NewWeakMyJob(job *MyJob) *WeakMyJob {\n    wp := weak.Make(job)\n\n    runtime.AddCleanup(job, func(jobID int) {\n        fmt.Printf(&quot;cleanup: MyJob %d finalized\\n&quot;, jobID)\n    }, job.id)\n\n    return &amp;WeakMyJob{wp: wp}\n}\n\nfunc (w *WeakMyJob) Execute() error {\n    if real := w.wp.Value(); real != nil {\n        return real.Execute()\n    }\n    return ErrInvalidJob\n}\n\n// Manager only holds the Job interface.\ntype Manager struct {\n    jobs []Job\n}\n\nfunc NewManager() *Manager {\n    return &amp;Manager{jobs: make([]Job, 0)}\n}\n\nfunc (m *Manager) Add(job Job) {\n    m.jobs = append(m.jobs, job)\n}\n\nfunc (m *Manager) RunAll() {\n    updatedJobs := m.jobs[:0]\n    for i, job := range m.jobs {\n        err := job.Execute()\n        if errors.Is(err, ErrInvalidJob) {\n            fmt.Printf(&quot;job[%d] removed: %v\\n&quot;, i, err)\n            continue\n        }\n        if err != nil {\n            fmt.Printf(&quot;job[%d] failed: %v\\n&quot;, i, err)\n        }\n        updatedJobs = append(updatedJobs, job)\n    }\n    m.jobs = updatedJobs\n}\n\nfunc main() {\n    mgr := NewManager()\n\n    for i := range 10 {\n        j := &amp;MyJob{id: i}\n        mgr.Add(NewWeakMyJob(j))\n        j = nil\n    }\n\n    fmt.Println(&quot;=== Before GC ===&quot;)\n    mgr.RunAll()\n\n    runtime.GC()\n    debug.FreeOSMemory()\n\n    fmt.Println(&quot;=== After GC ===&quot;)\n    mgr.RunAll()\n}\n</code></pre>\n<p>In this code:</p>\n<ul>\n<li><code>Job</code> is the interface I implement</li>\n<li><code>MyJob</code> is an actual implementation of <code>Job</code></li>\n<li><code>WeakMyJob</code> wraps a weak pointer to <code>MyJob</code> and implements the <code>Job</code> interface. This is what then passed to manager.</li>\n<li><code>Manager</code> holds a slice of <code>Job</code> (being WeakMyJob under the hood) objects and tries to call 1 by 1 in <code>RunAll</code> method. This way I am trying to simulate a struct which works with some objects which are supposed to be GCed without its knowledge and it must handle it gracefully by removing such objects from its slice</li>\n<li>In <code>main</code> jobs are created as pointers, wrapped with MyWeakJob and added to manager. After the for loop finishes all jobs aren't accessible from anywhere except from its weak pointer and, thus, must be GCed, as I see it.</li>\n</ul>\n<p>When I run it locally (Macbook Pro M3) the output isn't consistent. Sometimes it is</p>\n<pre><code>=== Before GC ===\nrunning MyJob 0\nrunning MyJob 1\nrunning MyJob 2\nrunning MyJob 3\nrunning MyJob 4\ncleanup: MyJob 0 finalized\n=== After GC ===\njob[0] removed: job invalid (GC’ed)\nrunning MyJob 1\nrunning MyJob 2\nrunning MyJob 3\nrunning MyJob 4\n</code></pre>\n<p>And other times</p>\n<pre><code>=== Before GC ===\nrunning MyJob 0\nrunning MyJob 1\nrunning MyJob 2\nrunning MyJob 3\nrunning MyJob 4\n=== After GC ===\nrunning MyJob 0\nrunning MyJob 1\nrunning MyJob 2\nrunning MyJob 3\nrunning MyJob 4\n</code></pre>\n<p>Not only they change from run to run but also only 1 job is GCed. I ran it few dozens times and only got this 2 outputs. I also tried running <code>runtime.GC()</code> in a loop but it achieved nothing.</p>\n<p>I tried extracting job creation to a separate function like below and it also hasn't changed anything:</p>\n<pre class=\"lang-golang prettyprint-override\"><code>func createJobs(mgr *Manager) {\n    for i := range 5 {\n        j := &amp;MyJob{id: i}\n        mgr.Add(NewWeakMyJob(j))\n        j = nil\n    }\n}\n\nfunc main() {\n    mgr := NewManager()\n    createJobs(mgr)\n\n    fmt.Println(&quot;=== Before GC ===&quot;)\n    mgr.RunAll()\n\n    runtime.GC()\n    debug.FreeOSMemory()\n\n    fmt.Println(&quot;=== After GC ===&quot;)\n    mgr.RunAll()\n}\n</code></pre>\n<p>Escape anaylis doesn't contain anything unexpected it seems:</p>\n<pre><code>./scratch_68.go:24:7: j does not escape\n./scratch_68.go:25:12: ... argument does not escape\n./scratch_68.go:25:36: j.id escapes to heap\n/opt/homebrew/opt/go/libexec/src/runtime/mcleanup.go:69:52: moved to heap: runtime.arg\n/opt/homebrew/opt/go/libexec/src/runtime/mcleanup.go:75:9: &quot;runtime.AddCleanup: ptr is nil&quot; escapes to heap\n/opt/homebrew/opt/go/libexec/src/runtime/mcleanup.go:80:24: runtime.arg does not escape\n/opt/homebrew/opt/go/libexec/src/runtime/mcleanup.go:82:10: &quot;runtime.AddCleanup: ptr is equal to arg, cleanup will never run&quot; escapes to heap\n/opt/homebrew/opt/go/libexec/src/runtime/mcleanup.go:87:9: &quot;runtime.AddCleanup: ptr is arena-allocated&quot; escapes to heap\n/opt/homebrew/opt/go/libexec/src/runtime/mcleanup.go:96:8: func literal escapes to heap\n/opt/homebrew/opt/go/libexec/src/runtime/mcleanup.go:110:9: &quot;runtime.AddCleanup: ptr not in allocated block&quot; escapes to heap\n./scratch_68.go:38:13: ... argument does not escape\n./scratch_68.go:38:47: jobID escapes to heap\n./scratch_68.go:34:19: leaking param: job\n./scratch_68.go:37:26: func literal escapes to heap\n./scratch_68.go:41:9: &amp;WeakMyJob{...} escapes to heap\n./scratch_68.go:44:7: leaking param content: w\n./scratch_68.go:57:9: &amp;Manager{...} escapes to heap\n./scratch_68.go:57:28: make([]Job, 0) escapes to heap\n./scratch_68.go:60:7: leaking param content: m\n./scratch_68.go:60:23: leaking param: job\n./scratch_68.go:64:7: leaking param content: m\n./scratch_68.go:69:14: ... argument does not escape\n./scratch_68.go:69:40: i escapes to heap\n./scratch_68.go:73:14: ... argument does not escape\n./scratch_68.go:73:39: i escapes to heap\n./scratch_68.go:80:17: leaking param content: mgr\n./scratch_68.go:82:8: &amp;MyJob{...} escapes to heap\n./scratch_68.go:92:13: ... argument does not escape\n./scratch_68.go:92:14: &quot;=== Before GC ===&quot; escapes to heap\n./scratch_68.go:98:13: ... argument does not escape\n./scratch_68.go:98:14: &quot;=== After GC ===&quot; escapes to heap\n</code></pre>\n<p>So, my question is why does go GC fail to collect my objects? Or is it Cleanup not geting run, why?</p>\n",
        "tags": [
            "go",
            "pointers",
            "interface",
            "garbage-collection",
            "weak-references"
        ]
    },
    {
        "index": 15,
        "question_id": 79623445,
        "title": "How to test if object has &quot;as.matrix&quot; method?",
        "body": "<p>In my code, I want to check if object <code>d</code> passed to my function has the method <code>as.matrix</code>, i.e. can be converted to matrix. How to do that?</p>\n<p>I have tried the following:</p>\n<blockquote>\n<p>&quot;as.matrix&quot; %in% methods(class = class(d))</p>\n</blockquote>\n<p>but it doesn't work, because the <code>methods(class = class(d))</code> returns a vector of methods, but these are not character strings, see e.g.:</p>\n<pre><code>&gt; methods(class = &quot;data.frame&quot;)\n  [1] $&lt;-                 %&amp;%                 %*%                 [                   [[                  [[&lt;-                [&lt;-                \n  [8] aggregate           all.equal           anyDuplicated       anyNA               arrange             as.data.frame       as.list            \n [15] as.matrix           as.vector           as_tibble           barchart            bwplot              by                  cbind              \n [22] cbind2              cloud               coerce              coerce&lt;-            contourplot         count               crossprod\n</code></pre>\n<p>... and I don't know how to convert these to character strings (method names) to perform this test.</p>\n<p><strong>EDIT:</strong></p>\n<p>PS: After reading the answers and comments, I see this is much more complicated than I originally thought. However, I would still like the answer to the original question, how to find if an object has that method. I am not interested in basic object like vectors in this case, i.e. the <code>as.matrix.default</code> is not an issue here. However, the answer should be able to deal with multiple classes returned by <code>class()</code>.</p>\n",
        "tags": [
            "r",
            "r-s4",
            "r-s3"
        ]
    },
    {
        "index": 16,
        "question_id": 79623564,
        "title": "UML Class diagram for Chat",
        "body": "<p>I'm designing a UML class diagram for a messaging app.</p>\n<p>Each <code>Chat</code> must have <strong>exactly 2 Users</strong>, and each <code>User</code> can be part of multiple <code>Chats</code>. I originally modeled this with a <strong>composition</strong> from <code>User</code> to <code>Chat</code>.</p>\n<p>However, I'm not sure if this is correct.</p>\n<p>My goal:</p>\n<ul>\n<li>A <code>Chat</code> is between exactly <strong>two Users</strong>.</li>\n<li><strong>Users are not owned</strong> by the chat and can exist independently.</li>\n<li>If <strong>both</strong> users are deleted, their chat is also deleted.</li>\n</ul>\n<p>Should I be using a <strong>normal association</strong> instead of composition here? What’s the best way to represent this in UML?</p>\n<p>Thanks in advance!\n<img src=\"https://i.sstatic.net/gwOon9rI.png\" alt=\"UML\" /></p>\n",
        "tags": [
            "uml",
            "chat",
            "class-diagram"
        ]
    },
    {
        "index": 17,
        "question_id": 79623674,
        "title": "How to filter user input in Angular?",
        "body": "<p>I want to filter user input when they type in an HTML text input.</p>\n<p>I can do that in native HTML/JavaScript as shown in the following demo:</p>\n<pre class=\"lang-html prettyprint-override\"><code>&lt;form&gt;\n    &lt;label for=&quot;tracking&quot;&gt;Tracking Number:&lt;/label&gt;\n    &lt;input\n        type=&quot;text&quot;\n        id=&quot;tracking&quot;\n        name=&quot;tracking&quot;\n        pattern=&quot;^[A-Z]{2}\\d{9}[A-Z]{2}$&quot;\n        title=&quot;Format must be like AB123456789CD&quot;\n        required\n        minlength=&quot;13&quot;\n        maxlength=&quot;13&quot;\n    /&gt;\n&lt;/form&gt;\n\n&lt;script&gt;\n    const input = document.getElementById('tracking');\n\n    input.addEventListener('input', () =&gt; {\n        console.log('input fired');\n\n        // Remove non-alphanumeric chars and force uppercase\n        input.value = input.value.replace(/[^a-zA-Z0-9]/g, '').toUpperCase();\n    });\n&lt;/script&gt;\n</code></pre>\n<p><a href=\"https://i.sstatic.net/7Auqv4ye.gif\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/7Auqv4ye.gif\" alt=\"filtering user input with HTML/JS\" /></a></p>\n<p>In the image above, I'm typing a, b, +, - (filtering works like I want).\nStackBlitz demo: <a href=\"https://stackblitz.com/edit/filter-user-input-native?file=index.html\" rel=\"nofollow noreferrer\">Filter user input (native)</a></p>\n<p>Now, I've done the same thing using Angular (with a template-driven form) as shown in the following demo:</p>\n<pre class=\"lang-js prettyprint-override\"><code>@Component({\n  selector: 'app-root',\n  template: `\n    &lt;form&gt;\n      &lt;label for=&quot;tracking&quot;&gt;Tracking Number:&lt;/label&gt;\n      &lt;input\n        type=&quot;text&quot;\n        id=&quot;tracking&quot;\n        name=&quot;tracking&quot;\n        pattern=&quot;^[A-Z]{2}\\d{9}[A-Z]{2}$&quot;\n        title=&quot;Format must be like AB123456789CD&quot;\n        required\n        minlength=&quot;13&quot;\n        maxlength=&quot;13&quot;\n        [ngModel]=&quot;trackingNumber&quot;\n        (ngModelChange)=&quot;onTrackingChange($event)&quot;\n      /&gt;\n    &lt;/form&gt;\n  `,\n  imports: [FormsModule],\n})\nexport class App {\n  trackingNumber = '';\n\n  onTrackingChange(value: string) {\n    console.log('input fired');\n\n    // Remove non-alphanumeric characters and force uppercase\n    this.trackingNumber = value.replace(/[^a-zA-Z0-9]/g, '').toUpperCase();\n  }\n}\n</code></pre>\n<p><a href=\"https://i.sstatic.net/GPtJuhrQ.gif\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/GPtJuhrQ.gif\" alt=\"filtering user input with Angular\" /></a></p>\n<p>In the image above, I'm typing a, b, +, - (filtering does NOT work like I want). StackBlitz demo: <a href=\"https://stackblitz.com/edit/filter-user-input-angular?file=src%2Fmain.ts\" rel=\"nofollow noreferrer\">Filter user input (Angular)</a></p>\n<p>As far as my Angular knowledge goes, this happens when the current ngModel value is the same as the new/filtered value, thus Angular does not trigger a change on the HTML text input.</p>\n<p>How can I overcome this behavior in Angular?</p>\n<p>Can I force Angular to trigger a change?</p>\n",
        "tags": [
            "javascript",
            "angular",
            "typescript",
            "angular-forms",
            "html-input"
        ]
    },
    {
        "index": 18,
        "question_id": 79623716,
        "title": "Sorting a dataframe column using a list with repeated values",
        "body": "<p>Given a dataframe such as this:</p>\n<pre><code>df = pd.DataFrame({'Drink': ['Beer', 'Beer', 'Wine', 'Wine', 'Wine', 'Whisky', 'Whisky'], 'Units': [14, 5, 9, 15, 7, 12, 17]})\n</code></pre>\n<div class=\"s-table-container\"><table class=\"s-table\">\n<thead>\n<tr>\n<th>Drink</th>\n<th>Units</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Beer</td>\n<td>14</td>\n</tr>\n<tr>\n<td>Beer</td>\n<td>5</td>\n</tr>\n<tr>\n<td>Wine</td>\n<td>9</td>\n</tr>\n<tr>\n<td>Wine</td>\n<td>15</td>\n</tr>\n<tr>\n<td>Wine</td>\n<td>7</td>\n</tr>\n<tr>\n<td>Whisky</td>\n<td>12</td>\n</tr>\n<tr>\n<td>Whisky</td>\n<td>17</td>\n</tr>\n</tbody>\n</table></div>\n<p>How can I sort the Drink column using a list like this one?</p>\n<pre><code>order = ['Wine', 'Beer', 'Whisky', 'Beer', 'Wine', 'Whisky']\n</code></pre>\n<p>So that the resulting dataframe looks like this:</p>\n<div class=\"s-table-container\"><table class=\"s-table\">\n<thead>\n<tr>\n<th>Drink</th>\n<th>Units</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Wine</td>\n<td>9</td>\n</tr>\n<tr>\n<td>Beer</td>\n<td>14</td>\n</tr>\n<tr>\n<td>Whisky</td>\n<td>12</td>\n</tr>\n<tr>\n<td>Beer</td>\n<td>5</td>\n</tr>\n<tr>\n<td>Wine</td>\n<td>15</td>\n</tr>\n<tr>\n<td>Whisky</td>\n<td>17</td>\n</tr>\n</tbody>\n</table></div>\n<p>The initial dataframe has more rows than elements in the list, so once everything in the list has matched to a row, the remaining rows can be dropped.</p>\n",
        "tags": [
            "python",
            "pandas"
        ]
    },
    {
        "index": 19,
        "question_id": 79620184,
        "title": "Not able to retrieve data from FIFO queue in process that calls a program to take user Input and add it into FIFO queue",
        "body": "<p>I have a requirement to call &quot;Program 2&quot; from child process of &quot;Program 1&quot;, where Program takes input from user and writes it to FIFO queue. On returning to &quot;Program 1&quot; , the parent process must be able to retrieve data written to queue by &quot;Program 1&quot; and display it. Given below is the minimum reproducible code of both caller program, &quot;Program 1&quot; and called program &quot;Program 2&quot; respectively.</p>\n<p>Program 1</p>\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;pthread.h&gt; \n\nint main() {\n    const char *fifo_name = &quot;f&quot;;\n    char output[100];\n    pid_t forkCall  =fork();\n    \n    if(forkCall ==0)\n    {\n        printf(&quot;Child process \\n&quot;);\n        execl(&quot;./a.out&quot;, &quot;Program2&quot;,NULL);\n        perror(&quot;execl failed&quot;);\n        exit(1);\n    }\n    else if(forkCall == -1)\n    {\n        perror(&quot;Error creating child process&quot;);\n        exit(0);\n    }\n    else{\n        printf(&quot;Parent process \\n&quot;);\n        int fd = open(fifo_name,O_RDONLY);\n        wait(NULL); \n        read(fd, output, sizeof(output));\n        close(fd);\n        unlink(fifo_name);\n        printf(&quot;Reader process read: %s\\n&quot;, output);\n    }\n    return 0;\n}\n</code></pre>\n<p>Program 2</p>\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;pthread.h&gt;\n\nint main() {\n    const char *fifo_name = &quot;f&quot;;\n    char input[100];\n    fgets(input, sizeof(input), stdin);\n    input[strcspn(input, &quot;\\n&quot;)] = '\\0';\n    printf(&quot;Ucer input accepted \\n&quot;);\n    \n    if(mkfifo(fifo_name, 0777)==-1)\n    {\n        perror(&quot;mkfifo&quot;);\n        return 1;\n    }\n    printf(&quot;FIFO Created \\n&quot;);//********************************\n    int fd = open(fifo_name,O_WRONLY);\n    if (fd == -1) {\n        perror(&quot;Error opening FIFO&quot;);\n        return 1;\n    }\n    printf(&quot;File descriptor (fd) is %d . \\n&quot;, fd); \n    printf(&quot;FIFO opened successfully \\n&quot;);\n    \n    write(fd, input, sizeof(input));\n    printf(&quot;FIFO content written successfully \\n&quot;);\n    \n    printf(&quot; Named pipe created and %s data written \\n&quot;,input);\n    close(fd);\n    \n    return 0;\n}\n</code></pre>\n<p>When I run Program 1, it asks for input at the terminal and prints &quot;FIFO CREATED&quot;. After that the programs halts without terminating.</p>\n<p><a href=\"https://i.sstatic.net/gYv5axhI.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/gYv5axhI.png\" alt=\"No terminal halt\" /></a></p>\n<p>When i run the Program 1 in separate terminal, the previous value entered for input is displayed from the parent process in the previous terminal and program halts.</p>\n<p>What missing aspect of IPC do I need to provide here, so that after taking input from user and writing it to FIFO queue, it returns control back to calling program. I tried opening fifo for writing using O_NONBLOCK.</p>\n<pre><code>int fd = open(fifo_name,O_WRONLY|O_NONBLOCK);\n</code></pre>\n<p>But it terminated the program even before taking input from user.</p>\n",
        "tags": [
            "c",
            "fork",
            "mkfifo"
        ]
    },
    {
        "index": 20,
        "question_id": 79620220,
        "title": "Understanding different translation units in C (the meaning)",
        "body": "<p>While learning storage classes in C, I stumbled upon something called <strong>Linkage</strong></p>\n<p>and the following site <a href=\"https://en.cppreference.com/w/c/language/storage_duration\" rel=\"nofollow noreferrer\">cpp.reference</a>\ndescribes linkage with translation units not in terms of a source file <br />\n(.c file, what I initially expected to learn)</p>\n<h4>Question: what do the terms current translation unit, other translation units, same translation unit, and all translation units mean in the context of linkage?</h4>\n<p><a href=\"https://i.sstatic.net/f7jH16ta.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/f7jH16ta.png\" alt=\"reference of snippet from the webiste\" /></a></p>\n<p>Based on my understanding,<em>from <a href=\"https://stackoverflow.com/questions/42262802/what-exactly-is-a-translation-unit-in-c\">What exactly is a translation unit in C</a></em></p>\n<blockquote>\n<p>A translation unit is what comes after preprocessing (header files inclusions, macros, etc along with the source file)</p>\n</blockquote>\n<p>Can we call <code>.i</code> file a translation unit ?</p>\n<p>I'm having hard time understanding how come storage class matter at translation-unit and furthermore how can I identify different translation units.</p>\n",
        "tags": [
            "c",
            "gcc",
            "translation-unit"
        ]
    },
    {
        "index": 21,
        "question_id": 79620324,
        "title": "Powershell run jobs in parallel",
        "body": "<p>I'm relatively new to PowerShell and I'm trying to create a function to build some installers.  I have it working to build them in series but it would be nice to run in parallel, but it also needs to wait until they are all built to continue.  I believe this would be done with <code>Start-Job</code> and <code>Wait-Job</code> but I can't get it working correctly.  Here is my current code:</p>\n<pre><code>function BuildInstallers {\n  $installerPath = $env:ADVINST_COM\n  $jobs = @();\n  for ($year = 2023; $year -le 2026; $year++) {\n      $jobs += Start-Job -ScriptBlock { Start-Process -FilePath $using:installerPath -ArgumentList &quot;/rebuild `&quot;Installers\\install$using:year.aip`&quot;&quot; -Wait -NoNewWindow }\n  }\n\n  Wait-Job -Job $jobs\n\n  Receive-Job -Job $jobs\n}\n</code></pre>\n<p>When I run this it runs but just immediately gives me this output:</p>\n<pre><code>Id     Name            PSJobTypeName   State         HasMoreData     Location             Command\n--     ----            -------------   -----         -----------     --------             -------\n1      Job1            BackgroundJob   Completed     False           localhost             Start-Process -FilePa...\n3      Job3            BackgroundJob   Completed     False           localhost             Start-Process -FilePa...\n5      Job5            BackgroundJob   Completed     False           localhost             Start-Process -FilePa...\n7      Job7            BackgroundJob   Completed     False           localhost             Start-Process -FilePa...\n</code></pre>\n<p>It's basically saying the processes are instantly completed but nothing happens.  What I would like to happen is that it spins up a process for each installer and starts running them in parallel and then when all are complete it continues execution (returns from this function).  What am I doing wrong?</p>\n<p><strong>EDIT</strong></p>\n<p>I neglected to mention that the path to the installer executable resolves to a .com file instead of a .exe (that's what the company says to call for scripts).  The full current path is <code>C:\\Program Files (x86)\\Caphyon\\Advanced Installer 22.6\\bin\\x86\\AdvancedInstaller.com</code></p>\n",
        "tags": [
            "powershell"
        ]
    },
    {
        "index": 22,
        "question_id": 79620472,
        "title": "Can Boost.Graph find all paths from A to B in a graph containing less than N edges?",
        "body": "<p>I have a use case for a graph algorithm related to finding flight connections, and I would like to determine if Boost.Graph is capable of addressing it.</p>\n<p>My ultimate goal is to find all &quot;attractive&quot; flight connections between two airports given by the customer. My task in this SO question is a bit smaller though: I want to determine all interesting <em>paths</em> (in graph nomenclature) between the two given airports. For instance, when the client wants to fly from KRK to LHR, a possible path is KRK-FRA-LHR.</p>\n<p>I have a list of all airports and their geographical coordinates:</p>\n<pre><code>struct Airport\n{\n  std::string name;\n  double latitude;\n  double longitude;\n};\n\nconst std::vector&lt;Airport&gt; airports\n{\n  {&quot;CDG&quot;, 49.009724,  2.547778  }, //  0\n  {&quot;FRA&quot;, 50.033333,  8.570556  }, //  1\n  {&quot;MUC&quot;, 48.353889,  11.786111 }, //  2\n  {&quot;LHR&quot;, 51.470020,  -0.454295 }, //  3\n  {&quot;LGW&quot;, 51.153629,  -0.182152 }, //  4\n  {&quot;KRK&quot;, 50.077778,  19.784722 }, //  5\n  {&quot;WAW&quot;, 52.165833,  20.967222 }, //  6 \n  {&quot;KTW&quot;, 50.474167,  19.08     }, //  7\n  {&quot;SIN&quot;, 1.359167,   103.989441}, //  8\n  {&quot;SYD&quot;, -33.947346, 151.179428}, //  9\n  {&quot;NRT&quot;, 35.765278,  140.385556}  // 10\n};\n</code></pre>\n<p>I represent the connections between airports as a directed graph, where each vertex represents an airport, and each edge indicates that there is at least one <em>direct</em> connection between the two connected airports. For the time being, I store them as a vector of vectors of int, where the element in the outer vector at index <em>i</em> represents all outgoing edges of vertex <em>i</em> (but I can store them in whatever other way):</p>\n<pre><code>const std::vector&lt;std::vector&lt;int&gt;&gt; connections\n{\n// 0  1  2  3  4  5  6  7  8  9  10\n  {   1, 2, 3, 4, 5, 6,    8, 9    }, //  0\n  {0,    2, 3,    5, 6, 7,         }, //  1\n  {0, 1,    3, 4, 5, 6,            }, //  2\n  {0, 1, 2,          6,    8, 9,   }, //  3\n  {0,    2,       5,       8,      }, //  4\n  {0, 1, 2,    4,    6,            }, //  5\n  {0, 1, 2, 3,    5,    7,       10}, //  6\n  {   1,             6,            }, //  7\n  {0,       3, 4,             9, 10}, //  8\n  {0,       3,             8,      }, //  9\n  {                  6,    8       }, // 10\n};\n</code></pre>\n<p>Given this data, I want to write a function</p>\n<pre><code>std::vector&lt;std::vector&lt;int&gt;&gt; find_paths(int from, int to, int max_connections);\n</code></pre>\n<p>that will return all the paths in the graph that start in <code>from</code> and end in <code>to</code> and:</p>\n<ol>\n<li>The number of edges in a pah is <code>max_connections + 1</code> or less. (Nobody will buy a flight where they need to connect eight times.)</li>\n<li>There are no cycles.</li>\n<li>It does not include any vertex that represents an airport too far away from <code>from</code> and <code>to</code>. (This is to make sure that when I want to fly between two German airports, I will not get a solution via Australia.) So, there will be a predicate that for a given vertex <code>v</code> will return <code>distance(v, from, to)</code> which will tell if <code>v</code> is acceptable.</li>\n</ol>\n<p>And, of course, I want to implement the function efficiently. That is, it would not be acceptable to compute loads of possible useless paths in one step only to discard most of them in the next step.</p>\n<p>Thus my questions are:</p>\n<ol>\n<li>Is this problem is suitable for Boost.Graph library?</li>\n<li>What tools from Boost.Graph to use to solve the above problem?</li>\n</ol>\n<p>I know that I can always implement this algorithm manually, so my question is not how to write it from scratch. My question is if I can implement the solution by composing components from Boost.Graph.</p>\n",
        "tags": [
            "c++",
            "boost-graph"
        ]
    },
    {
        "index": 23,
        "question_id": 79621106,
        "title": "How do I minimize C# memory allocations / GC churn with UDP sockets?",
        "body": "<p>I'm receiving data over UDP in a C# application, using socket.ReceiveFrom calls:</p>\n<pre><code>byte[] buffer = new byte[1024];\nEndPoint remoteEndPoint;\n...\nint byteCount = socket.ReceiveFrom(buffer, SocketFlags.None, ref remoteEndPoint);\n</code></pre>\n<p>My expectation was that by passing in a buffer that's larger than what's needed, then the call would use that buffer rather than allocating any memory itself.  However, looking at the memory allocated during that call under a debugger shows that memory is being allocated by the function:</p>\n<p><img src=\"https://i.sstatic.net/82wItvnT.png\" alt=\"Debugger showing 204 bytes allocated for receive buffer, and 656 bytes allocated for the end point\" /></p>\n<p>[Note that I appreciate that the buffer I supply is being used, and that no memory is allocated that the calling code needs to free (i.e. it seems that the socket call allocates and then frees memory internally as part of reading the data off the wire), nevertheless the internal memory allocation is producing garbage which is hammering GC...it's this that I'm trying to eliminate.]</p>\n<p>Is there a way of receiving data off the wire that doesn't cause any additional GC churn from memory allocations (either for the buffer, or for the EndPoint) and only uses input buffers that I can allocate just once up front and then reuse?</p>\n",
        "tags": [
            "c#",
            "sockets",
            "memory",
            "memory-management",
            "garbage-collection"
        ]
    },
    {
        "index": 24,
        "question_id": 79621376,
        "title": "Fill a sell order using the oldest assets first",
        "body": "<p>I have the following table which holds market assets and the date they were purchased:</p>\n<pre><code>CREATE TABLE ##Holdings\n(\n  HoldingID     INT            NOT NULL IDENTITY (1, 1) PRIMARY KEY,\n  Symbol        VARCHAR(20)    NOT NULL,\n  PurchaseDate  DATE           NOT NULL,\n  Units         INT            NOT NULL,\n  PurchasePrice DECIMAL(19, 2) NOT NULL,\n  SoldDate      DATE,\n  SoldPrice     DECIMAL(19,2)\n)\n</code></pre>\n<p>I have the following records in this table:</p>\n<pre><code>INSERT INTO ##Holdings (Symbol, PurchaseDate, Units, PurchasePrice)\nVALUES\n('ALL','2014-06-30',100, 5.26),\n('ALL','2014-07-01',100, 5.26),\n('ALL','2014-07-02',100, 5.26),\n('ALL','2014-07-03',100, 5.26),\n('ALL','2014-07-04',713, 5.26)\n\nSELECT * FROM ##Holdings\n</code></pre>\n<div class=\"s-table-container\"><table class=\"s-table\">\n<thead>\n<tr>\n<th>HoldingID</th>\n<th>Symbol</th>\n<th>PurchaseDate</th>\n<th>Units</th>\n<th>PurchasePrice</th>\n<th>SoldDate</th>\n<th>SoldPrice</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>ALL</td>\n<td>2014-06-30</td>\n<td>100</td>\n<td>5.26</td>\n<td>NULL</td>\n<td>NULL</td>\n</tr>\n<tr>\n<td>2</td>\n<td>ALL</td>\n<td>2014-07-01</td>\n<td>100</td>\n<td>5.26</td>\n<td>NULL</td>\n<td>NULL</td>\n</tr>\n<tr>\n<td>3</td>\n<td>ALL</td>\n<td>2014-07-02</td>\n<td>100</td>\n<td>5.26</td>\n<td>NULL</td>\n<td>NULL</td>\n</tr>\n<tr>\n<td>4</td>\n<td>ALL</td>\n<td>2014-07-03</td>\n<td>100</td>\n<td>5.26</td>\n<td>NULL</td>\n<td>NULL</td>\n</tr>\n<tr>\n<td>5</td>\n<td>ALL</td>\n<td>2014-07-04</td>\n<td>713</td>\n<td>5.26</td>\n<td>NULL</td>\n<td>NULL</td>\n</tr>\n</tbody>\n</table></div>\n<p>All of these assets were purchased on separate dates but all for the same price and security.</p>\n<p>I then want to process a sell order for 320 units of the security <code>ALL</code> at <code>7.65</code>, selling off the oldest holdings first.</p>\n<p>After the sell order is processed, the <code>##Holdings</code> table should look like this:</p>\n<pre class=\"lang-sql prettyprint-override\"><code>SELECT * FROM ##Holdings\n</code></pre>\n<div class=\"s-table-container\"><table class=\"s-table\">\n<thead>\n<tr>\n<th>HoldingID</th>\n<th>Symbol</th>\n<th>PurchaseDate</th>\n<th>Units</th>\n<th>PurchasePrice</th>\n<th>SoldDate</th>\n<th>SoldPrice</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>ALL</td>\n<td>2014-06-30</td>\n<td>100</td>\n<td>5.26</td>\n<td>2015-06-30</td>\n<td>7.65</td>\n</tr>\n<tr>\n<td>2</td>\n<td>ALL</td>\n<td>2014-07-01</td>\n<td>100</td>\n<td>5.26</td>\n<td>2015-06-30</td>\n<td>7.65</td>\n</tr>\n<tr>\n<td>3</td>\n<td>ALL</td>\n<td>2014-07-02</td>\n<td>100</td>\n<td>5.26</td>\n<td>2015-06-30</td>\n<td>7.65</td>\n</tr>\n<tr>\n<td>4</td>\n<td>ALL</td>\n<td>2014-07-03</td>\n<td>80</td>\n<td>5.26</td>\n<td>NULL</td>\n<td>NULL</td>\n</tr>\n<tr>\n<td>5</td>\n<td>ALL</td>\n<td>2014-07-04</td>\n<td>713</td>\n<td>5.26</td>\n<td>NULL</td>\n<td>NULL</td>\n</tr>\n<tr>\n<td>6</td>\n<td>ALL</td>\n<td>2014-07-03</td>\n<td>20</td>\n<td>5.26</td>\n<td>2015-06-30</td>\n<td>7.65</td>\n</tr>\n</tbody>\n</table></div>\n<p>Rows 1-3 have been used to fill the sell order.  Only 20 units of row 4 were required to fill the remaining units of the order.  A new row has been created (row 6) representing the 20 units, while row 4 has had 20 units removed.</p>\n<p>Row 5 remains untouched.</p>\n<p>I could solve this by using a while loop, altering the records as I go, updating the final row (4) and inserting a new row (6).  I would like to know if there is a better and more efficient way to achive this (I'm sure there is).  I'm sure this approach would be very ugly when the table has millions of rows.</p>\n<p><a href=\"https://stackoverflow.com/questions/12342749/query-matching-stock-trading-buyers-sellers-based-on-conditions\">This</a> article sort of comes close, but not quite what I'm looking for.</p>\n",
        "tags": [
            "sql-server",
            "t-sql",
            "sql-server-2019"
        ]
    },
    {
        "index": 25,
        "question_id": 79621465,
        "title": "How to use new containera in Tailwind v4?",
        "body": "<p>Basically, I want to put @container class in my div. I wanted to make it center and with breakpoints as it was in tailwind v3 e.g.:</p>\n<pre><code>    container: {\n        center: true,\n        padding: {\n            DEFAULT: '1rem',\n            sm: '2rem',\n        },\n        screens: {\n            '2xl': '1400px'\n        }\n    },\n</code></pre>\n<p>but now it's changed i'm trying this</p>\n<pre><code>\n@theme {\n  --breakpoint-default: initial;\n  --breakpoint-tablet: 40rem;\n  --breakpoint-laptop: 64rem;\n  --breakpoint-desktop: 80rem;\n}\n</code></pre>\n<pre><code>\nconst Header = () =&gt; {\n    return (\n        &lt;div className=&quot;@container/Header&quot;&gt;\n            &lt;div className=&quot;flex w-full justify-between items-center blur-filter-sm bg-0.500&quot;&gt;\n                &lt;div className=&quot;title font-bold&quot;&gt;Sensei&lt;/div&gt;\n                &lt;div className=&quot;etc&quot; &gt;\n                    &lt;Button className=&quot;rounded-full&quot;&gt;Contact&lt;/Button&gt;\n\n                &lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    );\n};\n</code></pre>\n<p>however, this doesn't work as it had been working and I don't know what to do.</p>\n<p>I've read new docs but they are not clear for me</p>\n<p>I was expecting it to behave as a container(put center, paddings, etc.) but it doesn't work</p>\n<p><img src=\"https://i.sstatic.net/WxztSViw.png\" alt=\"enter image description here\" /></p>\n<p>here is the header, but it should be with paddings</p>\n",
        "tags": [
            "javascript",
            "css",
            "next.js",
            "tailwind-css",
            "tailwind-css-4"
        ]
    },
    {
        "index": 26,
        "question_id": 79621625,
        "title": "Is there a way in R to parse the values of a vector to create factors?",
        "body": "<p>Let's suppose I have the following vector</p>\n<pre class=\"lang-r prettyprint-override\"><code>f = c(&quot;apple|banana&quot;,&quot;lime&quot;,&quot;apple|lime&quot;,&quot;apple|lime|banana&quot;)\n</code></pre>\n<p>Is there a way to have the factor levels like: <code>apple, banana, lime</code> in a way that <code>R</code> recognizes that?</p>\n<p>E.g. <code>f[[1]]</code> has two levels <code>apple banana</code>.</p>\n",
        "tags": [
            "r"
        ]
    },
    {
        "index": 27,
        "question_id": 79621852,
        "title": "How do I apply conditional formatting in vba?",
        "body": "<p>I haven't used VBA in a while and copied the below code to my workbook, &quot;FY26 01 Apr Finance Analysis&quot;, for use on worksheet &quot;Scorecard&quot;.  I am getting a run-time error 9 and can't figure it out.  I would also like to add to the code that if the cell is blank, don't apply any conditional formatting.  Thanks in advance.</p>\n<pre><code>Sub Conditional_Formatting()\n\nDim Scorecard As String\nsheetNameWhereRangeToBeFormattedIs = ActiveSheet.Name\n\nDim formatted_range As Range\nSet formatted_range = Sheets(Scorecard).Range(&quot;E3:E12&quot;)\n\nformatted_range.FormatConditions.Delete\n\nWith formatted_range\n    .FormatConditions.Add(Type:=xlCellValue, Operator:=xlLess, Formula1:=&quot;-.02&quot;).Interior.Color = RGB(255, 0, 0)\n    .FormatConditions.Add(Type:=xlCellValue, Operator:=xlBetween, Formula1:=&quot;-.02&quot;, Formula2:=&quot;0&quot;).Interior.Color = RGB(255, 255, 0)\n    .FormatConditions.Add(Type:=xlCellValue, Operator:=xlGreater, Formula1:=&quot;0&quot;).Interior.Color = RGB(0, 128, 0)\nEnd With\n    \n\nEnd Sub\n</code></pre>\n",
        "tags": [
            "excel",
            "vba"
        ]
    },
    {
        "index": 28,
        "question_id": 79621895,
        "title": "Alignment for vector of vectors in C++ templated type",
        "body": "<p>In C++, what is the shortest way to declare a vector of vectors, where each inner <code>std::vector</code>'s metadata fields (importantly size and pointer) have a user-chosen alignment?</p>\n<p>Ideally I'd be able to specify the alignment directly inside the template, e.g.</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>vector&lt; alignas(64) vector&lt;int&gt; &gt; my_vector;\n// or\nvector&lt; alignas(std::hardware_destructive_interference_size) vector&lt;int&gt; &gt; my_vector;\n</code></pre>\n<p>But that <strong>doesn't seem to be valid syntax</strong> for the placement of the <code>alignas</code> keyword.</p>\n<p>In absence of this possibility, what is the shortest possible alternative that is still generic (does not create e.g. a non-templated wrapper <code>struct</code> of concrete type to place the <code>alignas</code>)?</p>\n<p>I found some hints to approaches in the Reddit thread &quot;<a href=\"https://old.reddit.com/r/cpp/comments/13spubk/idiomatic_way_to_avoid_false_sharing/\" rel=\"nofollow noreferrer\">Idiomatic way to avoid false sharing</a>&quot; but the boilerplate still looks rather large.</p>\n<h2>Drop-in API requirement</h2>\n<p>A simple way might be something like</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>template &lt;typename T, std::size_t Alignment&gt;\nstruct AlignedObject {\n    alignas(Alignment) T object;\n};\n</code></pre>\n<p>but this adds extra wrapping (requiring access through <code>.object</code>).</p>\n<p>I'm looking to declare just the alignment, without having to change the interface through which <code>my_vector</code> needs to be accessed, so that the solution is a proper API-compatible drop-in replacement for <code>vector&lt;vector&lt;T&gt;&gt;</code> with the same constructors, methods, behaviour, future-proofness (for when <code>std::vector</code> may get changed in the future) and so on.</p>\n<h2>Remark about importance in parallel programs</h2>\n<p>Aligning the vector metadata fields is important to avoid <em>false sharing</em> in parallel programs. It is extremely common to have a parallelised loop where each loop iteration writes its own output <code>vector</code>, thus a <code>vector&lt;vector&lt;T&gt;&gt;</code> is needed.</p>\n<p>Each thread writes to its respective vector, so you'd think this should have perfectly-linear speedup; but because the vectors' size fields are near each other (fitting into the same cache line), <em>false sharing</em> triggers, and e.g. a <code>push_back()</code> of one thread slows down that of another thread. This is explained e.g. in the talk <a href=\"https://youtu.be/b7fUzKW54z8?si=xw23k_SFzGHICOMM&amp;t=688\" rel=\"nofollow noreferrer\">&quot;Faster than memcpy&quot;</a>.</p>\n<h2>Remark for comparing solutions</h2>\n<p>I found that for quick testing e.g. on <a href=\"https://godbolt.org/\" rel=\"nofollow noreferrer\">godbolt.org</a>, using an outer array instead of vector can be useful to quickly check the involved alignments, e.g.:</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>std::array&lt;      std::vector&lt;int&gt;              , 10&gt; my_vector;\nstd::array&lt; /* insert solution approach here */, 10&gt; my_vector;\n</code></pre>\n<h2>Related questions</h2>\n<ul>\n<li><a href=\"https://stackoverflow.com/questions/72019875/usage-of-alignas-in-template-argument-of-stdvector\">Usage of alignas in template argument of std::vector</a>\n<ul>\n<li>Is almost the same questions as I have, but the question was mis-placed, as the asker did not actually intend to align the vector's individual elements, while this question needs exactly that.</li>\n</ul>\n</li>\n</ul>\n<p>Thank you!</p>\n",
        "tags": [
            "c++",
            "stdvector",
            "memory-alignment",
            "alignas"
        ]
    },
    {
        "index": 29,
        "question_id": 79621902,
        "title": "How do I add alternating white and grey shading to a plot with categorical variables on the y-axis?",
        "body": "<p>I have looked at <a href=\"https://stackoverflow.com/questions/31592484/adding-shading-alternate-areas-for-categorical-variable-in-a-bar-plot-in-ggplot2\">this similar question</a> but am struggling to make it work with my code.</p>\n<p>Here is the plot that I have created:\n<a href=\"https://i.sstatic.net/CbyfeLkr.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/CbyfeLkr.png\" alt=\"enter image description here\" /></a></p>\n<p>What I would like to add are alternating white and grey bars (background) behind each species so that it is easier to tell which dot-and-whiskers relates to which species. Similar to this figure from another paper, but with the bars extending fully across the plot (i.e., to the end of the plot or x-axis). Also, in my plot, the dot-and-whiskers are offset because there was too much overlap, so each background bar would have a blue and a red dot-and-whisker.</p>\n<p><a href=\"https://i.sstatic.net/oTbNY3ZA.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/oTbNY3ZA.png\" alt=\"Source: https://onlinelibrary.wiley.com/doi/full/10.1111/gcb.17178\" /></a></p>\n<p>I've uploaded the dataset to my GitHub page, which can be found <a href=\"https://github.com/kiirsti/stackoverflow/blob/main/treatment_dataframe.csv\" rel=\"nofollow noreferrer\">here</a>.</p>\n<p>And here is the code:</p>\n<pre><code>tr_df &lt;-read_csv(&quot;treatment_dataframe.csv&quot;)\n\ncols &lt;-c(&quot;#fa5f2c&quot;, &quot;#608cd9&quot;)\n\ntr_prot_whisker &lt;-ggplot(tr_df, aes(tr_df$effect_size, species, fill=parameter))+\n   geom_vline(xintercept=0, linetype=&quot;dashed&quot;, color = &quot;grey65&quot;, size=1.5) +\n  geom_errorbarh(aes(xmin = LCI, xmax = UCI), color = &quot;black&quot;, size = 1, height=0.8, \n                 position = position_dodge(width = 1)) +\n  geom_point(color =&quot;black&quot;,shape=21, stroke = 1, size=5, position = position_dodge(width = 1)) +\n  scale_fill_manual(values = cols) +\n  scale_x_continuous(limits=c(-10,5), breaks=c(-10,-8,-6,-4,-2,0,2,4))+\n  labs(y=NULL, x = expression(&quot;Standardized &quot; * beta * &quot; coefficients&quot;)) + #\\n makes the next word go underneath the first\n  theme_classic()+\n  theme(axis.line = element_line(colour=&quot;black&quot;, size=1.3), #because I remove the border of the plot later in this code, this ensures that the axes  \n        panel.border = element_blank(), #removes border at top and right side of graph\n        legend.position = &quot;none&quot;,\n        #legend.text=element_text(size=16),\n        axis.ticks.length = unit(0.2, &quot;cm&quot;),\n        axis.title.x = element_text(size=24, colour=&quot;black&quot;), #controls title of x-axis\n        axis.text.x  = element_text(size=18, colour=&quot;black&quot;), #controls text of the ticks on the x.axis\n        axis.title.y=element_text(size=24, colour=&quot;black&quot;, vjust=2), #controls title of y-axis\n        axis.text.y=element_text(size=16, colour=&quot;black&quot;)) #controls text of the ticks on the y-axis\n\ntr_prot_whisker\n</code></pre>\n<p><strong>EDIT</strong></p>\n<p>As requested, here is the output from running <code>dput(tr_df)</code>.</p>\n<pre><code>structure(list(species = c(&quot;American Black Duck&quot;, &quot;American Wigeon&quot;, \n&quot;Blue-winged Teal&quot;, &quot;Canada Goose&quot;, &quot;Green-winged Teal&quot;, &quot;Mallard&quot;, \n&quot;Northern Shoveler&quot;, &quot;Pied-billed Grebe&quot;, &quot;Red-winged Blackbird&quot;, \n&quot;Ring-necked Duck&quot;, &quot;Sora&quot;, &quot;Swamp Sparrow&quot;, &quot;Wood Duck&quot;, &quot;American\nBlack Duck&quot;,  &quot;American Wigeon&quot;, &quot;Blue-winged Teal&quot;, &quot;Canada Goose&quot;,\n&quot;Green-winged Teal&quot;,  &quot;Mallard&quot;, &quot;Northern Shoveler&quot;, &quot;Pied-billed\nGrebe&quot;, &quot;Red-winged Blackbird&quot;,  &quot;Ring-necked Duck&quot;, &quot;Sora&quot;, &quot;Swamp\nSparrow&quot;, &quot;Wood Duck&quot;), parameter = c(&quot;dd&quot;,  &quot;dd&quot;, &quot;dd&quot;, &quot;dd&quot;, &quot;dd&quot;,\n&quot;dd&quot;, &quot;dd&quot;, &quot;dd&quot;, &quot;dd&quot;, &quot;dd&quot;, &quot;dd&quot;, &quot;dd&quot;,  &quot;dd&quot;, &quot;pt&quot;, &quot;pt&quot;, &quot;pt&quot;,\n&quot;pt&quot;, &quot;pt&quot;, &quot;pt&quot;, &quot;pt&quot;, &quot;pt&quot;, &quot;pt&quot;, &quot;pt&quot;,  &quot;pt&quot;, &quot;pt&quot;, &quot;pt&quot;),\n\neffect_size = c(-0.41, -0.69, 1.16, -0.4, \n1.75, -0.58, -0.04, -5.95, -0.21, -2.74, -4.26, 0.17, -2.83, \n0.24, -0.21, 0.57, 0.25, 0.2, -0.53, 0.15, -1.77, 0.31, -0.84, \n0.26, 0.39, -0.08), \n\nLCI = c(-1.1352, -1.5328, 0.1604, -1.2624, \n0.8092, -1.462, -0.5496, -8.204, -0.7196, -3.7984, -6.5924, -0.2808, \n-4.2412, -0.5048, -1.0136, -0.4296, -0.6908, -0.7016, -1.3924, \n-0.34, -2.8676, -0.0624, -1.5652, -1.1512, -0.0216, -1.3344),\n\nUCI = c(0.3152, 0.1528, 2.1596, 0.4624, 2.6908, 0.302, 0.4696, \n-3.696, 0.2996, -1.6816, -1.9276, 0.6208, -1.4188, 0.9848, \n0.5936, 1.5696, 1.1908, 1.1016, 0.3324, 0.64, -0.6724, 0.6824, \n-0.1148, 1.6712, 0.8016, 1.1744), \n\nshading = c(0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, \n            0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0)), \n\nrow.names = c(NA, -26L), spec = structure(list(\ncols = list(species = structure(list(), class = c(&quot;collector_character&quot;, \n&quot;collector&quot;)), parameter = structure(list(), class = c(&quot;collector_character&quot;, \n&quot;collector&quot;)), effect_size = structure(list(), class = c(&quot;collector_double&quot;, \n&quot;collector&quot;)), LCI = structure(list(), class = c(&quot;collector_double&quot;, \n&quot;collector&quot;)), UCI = structure(list(), class = c(&quot;collector_double&quot;, \n&quot;collector&quot;)), shading = structure(list(), class = c(&quot;collector_double&quot;, \n&quot;collector&quot;))), default = structure(list(), class = c(&quot;collector_guess&quot;, \n&quot;collector&quot;)), delim = &quot;,&quot;), class = &quot;col_spec&quot;), \nclass = c(&quot;spec_tbl_df&quot;,  &quot;tbl_df&quot;, &quot;tbl&quot;, &quot;data.frame&quot;))\n</code></pre>\n",
        "tags": [
            "r",
            "ggplot2",
            "background"
        ]
    },
    {
        "index": 30,
        "question_id": 79621916,
        "title": "Malformed Block in Ansible",
        "body": "<p>I'm trying to run a playbook that gathers yum history logs, and consolidates them on a single server. I ran this playbook</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>---\n- name: Gather yum history from all hosts\n  hosts: all\n  become: true\n  tasks:\n    - name: Run 'yum history' command\n      shell: yum history\n      register: yum_history_output\n\n    - name: Save yum history to local file\n      copy:\n        content: |\n          Host: {{ inventory_hostname }}\n          ========================================\n          {{ yum_history_output.stdout }}\n          ========================================\n        dest: &quot;/tmp/yum_history_{{ inventory_hostname }}.log&quot;\n\n- name: Fetch all yum history logs to control node\n  hosts: all\n  gather_facts: false\n  tasks:\n    - name: Fetch log files to control node\n      fetch:\n        src: &quot;/tmp/yum_history_{{ inventory_hostname }}.log&quot;\n        dest: &quot;./yum_history_logs/&quot;\n        flat: yes\n</code></pre>\n<p>and, after some formatting, got a malformed block error which just seemed to put the whole playbook into a single block. What am I doing wrong?</p>\n<p>I was given a bunch of formatting issues that I fixed, mostly deleting a lot of spaces because it didn't like the spaces in vi, but now I get a malformed block, and have no idea what to do next.</p>\n",
        "tags": [
            "automation",
            "ansible",
            "rhel"
        ]
    },
    {
        "index": 31,
        "question_id": 79622027,
        "title": "Pattern matching for null values &quot;AssignableTo&quot; type?",
        "body": "<p>Given a list of objects to be passed to a method with overloads, I want to determine what overload best matches the object types in order to invoke that method.</p>\n<pre><code>string TheMethod(string? foo, string? bar); // one overload\nstring TheMethod(string? foo);              // another overload\nList&lt;object?&gt; arguments = [...];\n\nswitch (arguments)\n{\n    case [string foo, string bar]:\n        return TheMethod(foo, bar);\n    case [string foo]:\n        return TheMethod(foo);\n}\n</code></pre>\n<p>This works fine when all arguments are non-null, however, I need to account for the possibility of null values. Other polymorphic types doesn't seem to have this problem.</p>\n<p>Is there a way to write patterns such that I can match values that are assignable to the type (specifically for null)?</p>\n<p>There are convoluted ways I could write it to allow for the possibility of null values, but that's not fun:</p>\n<pre><code>switch (arguments)\n{\n    case [var foo, var bar] when (foo is null or string &amp;&amp; bar is null or string):\n        return TheMethod(foo as string, bar as string);\n    ...\n    case [string? foo, string? bar]: // this would be nice, but illegal\n}\n</code></pre>\n<p>Is this the best we can do currently?</p>\n",
        "tags": [
            "c#",
            "null",
            "pattern-matching"
        ]
    },
    {
        "index": 32,
        "question_id": 79622116,
        "title": "In the Independent Read Independent Write (IRIW) scenario, is changing loads to seq_cst alone sufficient to prevent the result in C++23?",
        "body": "<p>In C++23, consider the classic IRIW litmus test, with the modification that all loads are now <code>seq_cst</code>, while stores are still <code>relaxed</code>:</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>void reader0(atomic_int *x, atomic_int *y) {\n  int l0x = x-&gt;load(memory_order_seq_cst);\n  int l0y = y-&gt;load(memory_order_seq_cst);\n}\nvoid reader1(atomic_int *x, atomic_int *y) {\n  int l1y = y-&gt;load(memory_order_seq_cst);\n  int l1x = x-&gt;load(memory_order_seq_cst);\n}\nvoid writer0(atomic_int *x, atomic_int *y) {\n  x-&gt;store(1, memory_order_relaxed); // sx\n}\nvoid writer1(atomic_int *x, atomic_int *y) {\n  y-&gt;store(1, memory_order_relaxed); // sy\n}\n</code></pre>\n<p>Is the outcome <code>l0x = l1y = 1 /\\ l0y = l1x = 0</code> forbidden?</p>\n<hr />\n<p>It seems that this outcome is indeed forbidden. According to the latest draft of C++23 (<a href=\"https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/n4950.pdf\" rel=\"nofollow noreferrer\">N4950</a>), the outcome <code>l0x = l1y = 1 /\\ l0y = l1x = 0</code> would produce a loop in the order S among seq_cst operations: <code>l0x -&gt;sb -&gt; l0y -&gt;cob l1y -&gt;sb l1x -&gt;cob l0x</code>, where sb stands for sequenced-before and cob stands for coherence-ordered before (<a href=\"https://eel.is/c++draft/atomics.order#3\" rel=\"nofollow noreferrer\">[atomics.order] #3</a>). The cob relation here is mediated by the relaxed stores (<a href=\"https://eel.is/c++draft/atomics.order#3.4\" rel=\"nofollow noreferrer\">[atomics.order] #3.4</a>)</p>\n<p>However, herd7 reports that this outcome is allowed in RC11 (although implemented in C, tested using <a href=\"https://github.com/herd/herdtools7/blob/master/herd/libdir/rc11.cat\" rel=\"nofollow noreferrer\"><code>rc11.cat</code></a> from herd7's GitHub repo). Since the standard text seems to come directly from the RC11 paper (at least based on the explanation in <a href=\"https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0668r1.html\" rel=\"nofollow noreferrer\">WG21/P0668R1</a>), this is very surprising. I'm not sure if my reasoning is incorrect, or the standard is subtly different from the RC11 paper, or the C and C++ version of RC11 is different in substantial ways, or herd7's RC11 implementation is missing some guarantees.</p>\n<p>Also, blocking the outcome seems to be really difficult to implement in hardware where the relaxed version of IRIW behavior is already present. This problem came up when trying to prove a non-MCA system can recover the C++ SeqCst semantics if all seq_cst stores &amp; AMOs are made MCA. However, if seq_cst loads alone are sufficient in blocking the difference in observed store order in IRIW, then only seq_cst stores &amp; AMOs being MCA is not enough. Loads would need to somehow wait for/force all inflight overlapping stores across the entire system to be made globally visible (also for forward progress, block overlapping stores by other cores from being committed). This seems REALLY costly, if even possible to do.</p>\n<hr />\n<p><strong>Edited 2025-05-16</strong></p>\n<p>@NateEldredge suggested in the comment that herd7 is able to graph involved abstract orders. The graph is added at the end of the question.</p>\n<p>From the graph, it's clear that in RC11, the <code>eco</code> (extended coherence order, which is equivalent to C++ standard's coherence-ordered before) edges does not contribute to <code>psc</code> (partial SC, the partial order to be extended to a total order). A deeper look into the <a href=\"https://plv.mpi-sws.org/scfix/\" rel=\"nofollow noreferrer\">original paper</a> show that this is actually the <em>intended way</em> how <code>psc</code> should works.</p>\n<p>Now this may answer the original question of mine (RC11 might be different with the standard), and as @PeterCordes have mentioned in the comment, Non-MCA architectures can still efficiently implement SeqCst loads. But this is unsatisfying because the reason the original RC11 paper avoid such a strong semantic of SeqCst was instead because of another observable example on x86. Below is a paraphrased version of <strong>Remark 4</strong> in the RC11 paper.</p>\n<blockquote>\n<p>Consider following strengthened SB example.</p>\n<pre><code>Global atomic variables: x y\nInitial values: x = 0, y = 0\n\nThread 0                | Thread 1\nx =(rlx) 1              | y =(rlx) 1\nr1 =(seq_cst) x // 1    | r3 =(seq_cst) y // 1\nr2 =(seq_cst) y // 0    | r4 =(seq_cst) x // 0\n</code></pre>\n<p>(Even right now) compilers would compile seq_cst loads into plain <code>MOV</code>s. So the annotated result is readily observable on x86 hardware. However, based on similar analysis, C++23 should forbid this.</p>\n</blockquote>\n<p>My experiments:\n<a href=\"https://godbolt.org/z/cbzfeExdr\" rel=\"nofollow noreferrer\">Godbolt</a>, <a href=\"https://gist.github.com/CircuitCoder/e670346f9ded631c294cc2efe08932a9\" rel=\"nofollow noreferrer\">Full code</a></p>\n<p>This makes me very unsure about my reasoning the IRIW case, but if that's correct and can be carry through to the SB case presented here, it seems to indicate that g++ and clang++ on x86 is both unsound w.r.t. seq_cst loads (right now).</p>\n<hr />\n<p>Edited 2025-05-16 (later)</p>\n<p>This (seq_cst being too strong) does seem to an oversight in P0668 and current C++ standard. See: <a href=\"https://cplusplus.github.io/LWG/lwg-active.html#3941\" rel=\"nofollow noreferrer\">https://cplusplus.github.io/LWG/lwg-active.html#3941</a></p>\n<hr />\n<p>The litmus test, command and result:</p>\n<pre><code>herd7 -c11 -cat ./rc11.cat IRIW.litmus\n</code></pre>\n<pre><code>C IRIW\n\n{}\n\nP0 (atomic_int* x,atomic_int* y) {\n  atomic_int l0x = atomic_load_explicit(x,memory_order_seq_cst);\n  atomic_int l0y = atomic_load_explicit(y,memory_order_seq_cst);\n}\n\nP1 (atomic_int* x,atomic_int* y) {\n  atomic_int l1y = atomic_load_explicit(y,memory_order_seq_cst);\n  atomic_int l1x = atomic_load_explicit(x,memory_order_seq_cst);\n}\n\nP2 (atomic_int* x,atomic_int* y) {\n  atomic_store_explicit(x,1,memory_order_relaxed);\n}\n\nP3 (atomic_int* x,atomic_int* y) {\n  atomic_store_explicit(y,1,memory_order_relaxed);\n}\n\nexists\n(0:l0x=1 /\\ 1:l1y=1 /\\ 0:l0y=0 /\\ 1:l1x=0)\n</code></pre>\n<pre><code>Test IRIW Allowed\nStates 16\n0:l0x=0; 0:l0y=0; 1:l1x=0; 1:l1y=0;\n0:l0x=0; 0:l0y=0; 1:l1x=0; 1:l1y=1;\n0:l0x=0; 0:l0y=0; 1:l1x=1; 1:l1y=0;\n0:l0x=0; 0:l0y=0; 1:l1x=1; 1:l1y=1;\n0:l0x=0; 0:l0y=1; 1:l1x=0; 1:l1y=0;\n0:l0x=0; 0:l0y=1; 1:l1x=0; 1:l1y=1;\n0:l0x=0; 0:l0y=1; 1:l1x=1; 1:l1y=0;\n0:l0x=0; 0:l0y=1; 1:l1x=1; 1:l1y=1;\n0:l0x=1; 0:l0y=0; 1:l1x=0; 1:l1y=0;\n0:l0x=1; 0:l0y=0; 1:l1x=0; 1:l1y=1;\n0:l0x=1; 0:l0y=0; 1:l1x=1; 1:l1y=0;\n0:l0x=1; 0:l0y=0; 1:l1x=1; 1:l1y=1;\n0:l0x=1; 0:l0y=1; 1:l1x=0; 1:l1y=0;\n0:l0x=1; 0:l0y=1; 1:l1x=0; 1:l1y=1;\n0:l0x=1; 0:l0y=1; 1:l1x=1; 1:l1y=0;\n0:l0x=1; 0:l0y=1; 1:l1x=1; 1:l1y=1;\nOk\nWitnesses\nPositive: 1 Negative: 15\nCondition exists (0:l0x=1 /\\ 1:l1y=1 /\\ 0:l0y=0 /\\ 1:l1x=0)\nObservation IRIW Sometimes 1 15\nTime IRIW 0.00\nHash=d48f72da473d15179ca978f7ba2eebbb\n</code></pre>\n<p><a href=\"https://i.sstatic.net/88daddTK.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/88daddTK.jpg\" alt=\"Graph generated by herd7\" /></a></p>\n",
        "tags": [
            "c++",
            "cpu-architecture",
            "atomic",
            "memory-barriers",
            "memory-model"
        ]
    },
    {
        "index": 33,
        "question_id": 79622385,
        "title": "Create a dataframe column containing a list of number whose length is determined by another column",
        "body": "<p>I have a data frame of <code>name</code>s, and each <code>name</code> has a <code>count</code> of individuals, e.g.</p>\n<pre class=\"lang-r prettyprint-override\"><code>df = read.table(header=TRUE, text= \n'name count\na 10\nb 1\nc 7\nd 3')\n</code></pre>\n<pre class=\"lang-none prettyprint-override\"><code>&gt; df\n     name count    \n1    a    10        \n2    b     1      \n3    c     7  \n4    d     3  \n</code></pre>\n<p>I want to add another column with a list of <code>'1'</code>s, as a <code>tally</code> column, corresponding to the <code>count</code>. So the output would look like this:</p>\n<pre class=\"lang-none prettyprint-override\"><code>     name count    tally\n1    a    10        c('1', '1', '1', '1', '1', '1', '1', '1', '1', '1')\n2    b     1        c('1')\n3    c     7        c('1', '1', '1', '1', '1', '1', '1')\n4    d     3        c('1', '1', '1')\n</code></pre>\n<p>I was able to get close with a <code>for</code>-loop, but I couldn't see a graceful way to re-join the result to the original data frame, and anyway, I would prefer a <code>{tidyverse}</code> solution with <code>dplyr::mutate()</code>.</p>\n",
        "tags": [
            "r",
            "dataframe",
            "dplyr",
            "tidyverse"
        ]
    },
    {
        "index": 34,
        "question_id": 79623234,
        "title": "std::atomic::is_lock_free() shows true but pthread_mutex_lock() called",
        "body": "<p>I have an atomic variable which contains a 16-bytes member variable, and I hope the load/store operation on it will be lock-free, because it could be achieved by <code>cmpxchg16b</code>.</p>\n<p>here I have sample code.</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>#include &lt;atomic&gt;\n#include &lt;iostream&gt;\n\nint pthread_mutex_lock(pthread_mutex_t *mutex) {\n    std::cout &lt;&lt; &quot;in pthread_mutex_lock&quot; &lt;&lt; std::endl;\n    return 0;\n}\n\nint main() {\n  std::atomic&lt;__int128&gt; var;\n  std::cout &lt;&lt; &quot;is_lock_free: &quot; &lt;&lt; var.is_lock_free() &lt;&lt; std::endl;\n  var.load();\n}\n</code></pre>\n<p>When compiled by <code>g++ test.cpp -latomic</code>, the result is</p>\n<pre><code>is_lock_free: 1\n</code></pre>\n<p>The instruction executed in <code>var.load()</code> is</p>\n<pre class=\"lang-none prettyprint-override\"><code>0x7ffff7bd6740  push %rbx\n0x7ffff7bd6741  xor    %ecx,%ecx\n0x7ffff7bd6743  mov    %rcx,%rbx\n0x7ffff7bd6746  sub    $0x20,%rsp\n0x7ffff7bd674a  movq   $0x0,0x8(%rsp)\n0x7ffff7bd6753  mov    0x8(%rsp),%rdx\n0x7ffff7bd6758  mov    %fs:0x28,%rax\n0x7ffff7bd6761  mov    %rax,0x18(%rsp)\n0x7ffff7bd6766  xor    %eax,%eax\n0x7ffff7bd6768  movq   $0x0,(%rsp)\n0x7ffff7bd6770  lock cmpxchg16b (%rdi)\n0x7ffff7bd6775  je     0x7ffff7bd6780\n0x7ffff7bd6777  mov    %rax,(%rsp)\n0x7ffff7bd677b  mov    %rdx,0x8(%rsp)\n0x7ffff7bd6780  mov    0x18(%rsp),%rsi\n0x7ffff7bd6785  xor    %fs:0x28,%rsi\n0x7ffff7bd678e  mov    (%rsp),%rax\n0x7ffff7bd6792  mov    0x8(%rsp),%rdx\n0x7ffff7bd6797  jne    0x7ffff7bd679f\n0x7ffff7bd6799  add    $0x20,%rsp\n0x7ffff7bd679d  pop    %rbx\n0x7ffff7bd679e  retq     \n</code></pre>\n<p>and <code>is_lock_free</code> is executed as following</p>\n<pre class=\"lang-none prettyprint-override\"><code>cmp    $0x10,%rdi                               \nja     0x7ffff7bd5908 &lt;__atomic_is_lock_free+136&gt;\nlea    0x17d3(%rip),%rax        # 0x7ffff7bd7064\nmovslq (%rax,%rdi,4),%rdx                       \nadd    %rdx,%rax\njmpq   *%rax    \nnopw   0x0(%rax,%rax,1)                         \ntest   $0x3,%sil\nje     0x7ffff7bd58be &lt;__atomic_is_lock_free+62&gt;\nand    $0x7,%esi\nadd    %rsi,%rdi\ncmp    $0x8,%rdi\nsetbe  %al      \nretq            \nnopl   0x0(%rax)\ntest   $0x1,%sil\njne    0x7ffff7bd58c8 &lt;__atomic_is_lock_free+72&gt;\nmov    $0x1,%eax\nretq\nnopl   0x0(%rax)\nmov    %rsi,%rdx\nmov    $0x1,%eax\nand    $0x3,%edx\nadd    %rdi,%rdx\ncmp    $0x4,%rdx\nja     0x7ffff7bd58a6 &lt;__atomic_is_lock_free+38&gt;  \nrepz retq       \nxchg   %ax,%ax  \nand    $0x7,%esi\nsete   %al      \nretq            \nnopw   0x0(%rax,%rax,1)                           \nxor    %eax,%eax\nand    $0xf,%esi\njne    0x7ffff7bd58dc &lt;__atomic_is_lock_free+92&gt;  \nmov    0x2047a3(%rip),%eax        # 0x7ffff7dda0a0\nshr    $0xd,%eax\nand    $0x1,%eax\nretq            \nnopl   0x0(%rax)\nxor    %eax,%eax\nretq\n</code></pre>\n<p>But when compiled by <code>g++ test.cpp -latomic -Wl,-z,now</code>, the result is</p>\n<pre><code>is_lock_free: 1\nin pthread_mutex_lock\n</code></pre>\n<p>Now the instruction executed is</p>\n<pre class=\"lang-none prettyprint-override\"><code>0x7ffff7bd6050  push   %rbx\n0x7ffff7bd6051  mov    %rdi,%rbx\n0x7ffff7bd6054  sub    $0x10,%rsp\n0x7ffff7bd6058  callq  0x7ffff7bd5910\n0x7ffff7bd605d  mov    (%rbx),%rax\n0x7ffff7bd6060  mov    0x8(%rbx),%rdx\n0x7ffff7bd6064  mov    %rbx,%rdi\n0x7ffff7bd6067  mov    %rax,(%rsp)\n0x7ffff7bd606b  mov    %rdx,0x8(%rsp)\n0x7ffff7bd6070  callq  0x7ffff7bd5930\n0x7ffff7bd6075  mov    (%rsp),%rax\n0x7ffff7bd6079  mov    0x8(%rsp),%rdx\n0x7ffff7bd607e  add    $0x10,%rsp\n0x7ffff7bd6082  pop    %rbx   \n</code></pre>\n<p>With gdb step in <code>0x7ffff7bd5910</code>, it calls <code>pthread_mutex_lock</code>, it shows <code>load</code> is implemented by lock.</p>\n<p>Why atomic has different behaviour with its output? And How does <code>-Wl,-z,now</code> cause it?</p>\n<p>How could I ensure 16-bytes load/store is lock-free?</p>\n<p>My enviornment is</p>\n<pre class=\"lang-bash prettyprint-override\"><code>[test@15bf6105d708 test]$&gt; gcc --version\ngcc (GCC) 8.3.1 20190311 (Red Hat 8.3.1-3)\nCopyright (C) 2018 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n[test@15bf6105d708 test]$&gt; uname -a\nLinux 15bf6105d708 5.4.119-19-0009.11 #1 SMP Wed Oct 5 18:41:07 CST 2022 x86_64 x86_64 x86_64 GNU/Linux\n\n[test@15bf6105d708 test]$&gt; lscpu\nArchitecture:          x86_64\nCPU op-mode(s):        32-bit, 64-bit\nByte Order:            Little Endian\nCPU(s):                16\nOn-line CPU(s) list:   0-15\nThread(s) per core:    2\nCore(s) per socket:    8\nSocket(s):             1\nNUMA node(s):          1\nVendor ID:             AuthenticAMD\nCPU family:            23\nModel:                 49\nModel name:            AMD EPYC 7K62 48-Core Processor\nStepping:              0\nCPU MHz:               2595.124\nBogoMIPS:              5190.24\nHypervisor vendor:     KVM\nVirtualization type:   full\nL1d cache:             32K\nL1i cache:             32K\nL2 cache:              4096K\nL3 cache:              16384K\nNUMA node0 CPU(s):     0-15\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm rep_good nopl cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ibpb vmmcall fsgsbase bmi1 avx2 smep bmi2 rdseed adx smap clflushopt sha_ni xsaveopt xsavec xgetbv1 arat\n</code></pre>\n",
        "tags": [
            "c++",
            "gcc",
            "atomic",
            "redhat",
            "stdatomic"
        ]
    },
    {
        "index": 35,
        "question_id": 79623245,
        "title": "Simplify a prime factorization like expression with optimal performance",
        "body": "<p>I am working with a situation in which I need to turn an arithmetic string expression (e.g. <code>(3/2) * (3**4 / (20 * 4))**(-1/4)</code>) into the following prime factorization form: $\\prod_{p:\\text{prime}}p_i^{k_i}$ (in LaTeX format), where $p_i$ are prime numbers and $k_i$ are rational numbers. The result, I want it to be returned as a <code>dict</code> where the keys are prime factors and values are their respective exponents.</p>\n<p>The arithmetic expression contains only multiplication, division, and power operations. The exponent of power can be regarded as a constant (i.e. contains no more recursive sub-structures. When it is a fraction it will be turned to a <code>Fraction</code> object).</p>\n<p>Below is my current attempt to solve this problem by traversing the abstract syntax tree recursively. For a leaf node, which is a single integer value, I take its prime factors and store it in a <code>dict</code>; for power I multiply each element in the <code>dict</code> by the exponent and for multiplication and division I add or subtract each term in the <code>dict</code>. This method works, however, it creates a separate dict for every leaf node. As <code>dict</code> is a mutable type, creating it multiple times isn't efficient.</p>\n<p>I am looking for a solution which can create only one <code>dict</code> at the beginning and perform all updates in this <code>dict</code> without having to create other <code>dict</code>. Also in my actual use case the situation may be that I already have a <code>dict</code> containing a prime factorization and I want to update the <code>dict</code> so that it represents the multiplication of the <code>dict</code>'s factorization and my expression. For the solution of this problem I am investigating into prefix / postfix (Polish / reverse Polish) notation, but I am not sure whether this is the correct direction. So is my requirement of using only one <code>dict</code> (an external data structure, such as a stack is acceptable) possible?</p>\n<pre class=\"lang-py prettyprint-override\"><code>import ast\nfrom fractions import Fraction as Q\nfrom numbers import Integral, Rational\nfrom collections import Counter\nfrom collections.abc import MutableMapping\n\n\ndef _mul(m: MutableMapping[int, Rational], n: Rational):\n    if n == 0:\n        m.clear()\n        return\n    if n == 1:\n        return\n    for k in m:\n        m[k] = m[k] * n\n\n\ndef _cleanZeroes(m: MutableMapping[int, Rational]):\n    for k in frozenset(k for k, v in m.items() if v == 0):\n        del m[k]\n\n\ndef _pf_rec(node: ast.expr):\n    match node:\n        case ast.BinOp(left=n_left, op=ast.Pow(), right=n_right):\n            res_base = _processSubnode(n_left)\n            exp = _processExponent(n_right)\n            _mul(res_base, exp)\n            return res_base\n        case ast.BinOp(left=n_left, op=op, right=n_right):\n            res_left = _processSubnode(n_left)\n            res_right = _processSubnode(n_right)\n            match op:\n                case ast.Mult():\n                    Counter.update(res_left, res_right)\n                    return res_left\n                case ast.Div():\n                    Counter.subtract(res_left, res_right)\n                    return res_left\n                case _:\n                    raise ValueError(f&quot;Invalid operator: {op.__class__.__name__}&quot;)\n        case _:\n            raise ValueError(f&quot;Invalid expression: {ast.unparse(node)}&quot;)\n\n\ndef _processSubnode(node: ast.stmt) -&gt; MutableMapping[int, Rational]:\n    match node:\n        case ast.Constant(value=val):\n            if not isinstance(val, Integral):\n                raise ValueError(f&quot;{ast.unparse(node)} is not an integer.&quot;)\n\n            from primefac import primefac\n\n            res = {}\n            Counter.update(res, primefac(val))\n            return res\n        case _:\n            return _pf_rec(node)\n\n\ndef _processInteger(node: ast.expr) -&gt; int:\n    neg = False\n    match node:\n        case ast.UnaryOp(op=ast.UAdd(), operand=node):\n            ...\n        case ast.UnaryOp(op=ast.USub(), operand=node):\n            neg = True\n    match node:\n        case ast.Constant(value=val):\n            if not isinstance(val, Integral):\n                raise ValueError(f&quot;{ast.unparse(node)} is not an integer.&quot;)\n            if neg:\n                val = -val\n            return val\n        case _:\n            raise ValueError(f&quot;Invalid integer value: {ast.unparse(node)}&quot;)\n\n\ndef _processExponent(node: ast.expr) -&gt; int | Q:\n    neg = False\n    match node:\n        case ast.UnaryOp(op=ast.UAdd(), operand=node):\n            ...\n        case ast.UnaryOp(op=ast.USub(), operand=node):\n            neg = True\n    match node:\n        case ast.Constant(value=exp):\n            # integer exponent\n            if neg:\n                exp = -exp\n            return exp\n        case ast.BinOp(left=n_left, op=ast.Div(), right=n_right):\n            # fractional exponent\n            p = _processInteger(n_left)\n            q = _processInteger(n_right)\n            if neg:\n                p = -p\n            return Q(p, q)\n        case _:\n            raise ValueError(f&quot;Invalid exponent: {ast.unparse(node)}&quot;)\n\n\ndef pfMapping(src: str):\n    node = ast.parse(src, mode=&quot;eval&quot;).body\n    res = _pf_rec(node)\n    _cleanZeroes(res)\n    return res\n\n\nif __name__ == &quot;__main__&quot;:\n    from viztracer import VizTracer\n\n    with VizTracer():\n        expression = &quot;(3/2) * (3**4 / (20 * 4))**(-1/4)&quot;\n        # desired result: {5: 1/4}\n        print(pfMapping(expression))\n        print(pfMapping(expression))\n\n</code></pre>\n",
        "tags": [
            "python",
            "math",
            "primes",
            "abstract-syntax-tree",
            "postfix-notation"
        ]
    },
    {
        "index": 36,
        "question_id": 79623298,
        "title": "DraftEmail removing bcc from email",
        "body": "<p>We used to have simple mailto: links to provide users a simple way to open a new draft email with the relevant emails directly filled in.</p>\n<p>The issue is that there is a limit to the length of href supported by such links (about 2000 chars), and sometimes we'll need more than that.</p>\n<p>So to avoid this issue, I'm shifting to a server-side solution by  building a new <code>DraftEmail</code> and just send it in my <code>Response</code> after a <code>.toString()</code>.</p>\n<p>It works fine as long as the emails are provided in the 'to' and 'cc' fields, but the 'bcc' field doesn't work.</p>\n<p>It seems to be on purpose :</p>\n<p><a href=\"https://github.com/symfony/symfony/blob/7.3/src/Symfony/Component/Mime/DraftEmail.php\" rel=\"nofollow noreferrer\">https://github.com/symfony/symfony/blob/7.3/src/Symfony/Component/Mime/DraftEmail.php</a></p>\n<p>From what I understand, it seems related to the fact that the bcc should not be in the message but in the envelope. Ok, but then what would be a simple way to do what I'm attempting to do? Because as far as I understand, the envelope is used to send the message, but I don't want to send the message, I just want to create it, the sending is handled by the email client.</p>\n<p>Another issue is that unlike mailto: links, a DraftEmail doesn't seem to add the signature of the user, I assume it's because it's an external file and not a new message or a reply, but that's an issue as well.</p>\n<p>Are there alternatives in symfony to mailto: links that does the same thing as far as signatures and bcc recipients are concerned, while not having the length limitation?</p>\n<p>Thank you for your help</p>\n",
        "tags": [
            "php",
            "symfony",
            "mailto",
            "email-client"
        ]
    },
    {
        "index": 37,
        "question_id": 79623448,
        "title": "Any way to get the real last row not affected by autofilter? Without altering current autofilter status, using UsedRange nor looping cells from bottom",
        "body": "<p>Surprisingly it seems that the most common ways to get the last row are all affected by autofilter.</p>\n<p>No matter it's .Find, .End(xlUp), .SpecialCells...once the range is filtered, I just can't get the &quot;real&quot; last row.</p>\n<p>Is there any way to get the last row of the worksheet as if it's unfiltered? Without turning off or resetting the autofilter? Thank you very much!</p>\n",
        "tags": [
            "excel",
            "vba"
        ]
    },
    {
        "index": 38,
        "question_id": 79623528,
        "title": "Set rows to read-only",
        "body": "<p>I have an application with the following requirements:</p>\n<ol>\n<li><p>Before a predefined event (in my application) occurs, I need to update and insert rows in different tables.</p>\n</li>\n<li><p>After the event, certain rows in various tables should be set to &quot;ReadOnly,&quot; meaning no updates or deletes are allowed on these specific rows.</p>\n</li>\n</ol>\n<p>To implement this, I added an IsReadOnly column to all relevant tables and created functions and security policies to enforce these restrictions.</p>\n<pre><code>-- Create schema-bound filter predicate function\nCREATE FUNCTION dbo.ReadOnlyFilterPredicate(@IsReadOnly BIT)\nRETURNS TABLE\nWITH SCHEMABINDING\nAS\nRETURN SELECT 1 AS Result;\n\n-- Create schema-bound block predicate function\nCREATE FUNCTION dbo.ReadOnlyBlockPredicate(@IsReadOnly BIT)\nRETURNS TABLE\nWITH SCHEMABINDING\nAS\nRETURN SELECT 1 AS Result WHERE @IsReadOnly = 0;\n\n-- Create the security policy with the filter predicate\nCREATE SECURITY POLICY ReadOnlyPolicy\nADD FILTER PREDICATE dbo.ReadOnlyFilterPredicate(IsReadOnly) ON dbo.Plant\nWITH (STATE = ON);\n\n-- Alter the security policy to add block predicates for UPDATE and DELETE\nALTER SECURITY POLICY ReadOnlyPolicy\nADD BLOCK PREDICATE dbo.ReadOnlyBlockPredicate(IsReadOnly) ON dbo.Plant\n</code></pre>\n<p>When a row has IsReadOnly = 0, I can update or delete it as expected. Conversely, if a row has IsReadOnly = 1, updates or deletes are not permitted, which is also as expected.</p>\n<p>However, when the event occurs and I attempt to change IsReadOnly from 0 to 1, I encounter an error:</p>\n<blockquote>\n<p>The attempted operation failed because the target object ‘MyTablent' has a block predicate that conflicts with this operation. If the operation is performed on a view, the block predicate might be enforced on the underlying table. Modify the operation to target only the rows that are allowed by the block predicate.</p>\n</blockquote>\n<p>Disabling the security policy temporarily allows me to set IsReadOnly to 1 and then re-enable the policy, which resolves the issue.</p>\n<p>However, during the brief period when the security policy is disabled, there is a risk that unauthorized changes could be made to rows.</p>\n<p>The problem seems to be that the predicate evaluates the &quot;new&quot; value (e.g., IsReadOnly = 1) instead of the actual value in the table, preventing me from changing IsReadOnly.</p>\n<p>I am seeking ideas on how to address this requirement effectively.</p>\n",
        "tags": [
            "sql-server",
            "t-sql",
            "readonly"
        ]
    },
    {
        "index": 39,
        "question_id": 79623534,
        "title": "Call large SQL queries from inside procedures or functions to create common helper functions in Snowflake",
        "body": "<p>I have a system where I need to identify different types of risk associated with entities. I have many large scripts for detecting different risk behaviours associated with entities, with some scripts producing one or more &quot;risk marker types&quot;.</p>\n<p>I have a master event table of all active and past risks. A dummy version is created by the following:</p>\n<pre class=\"lang-sql prettyprint-override\"><code>CREATE OR REPLACE SEQUENCE test_marker_event_id_seq\n   START = 1\n   INCREMENT = 1\n   ORDER;\n\nCREATE OR REPLACE TABLE test_entity_risk_markers\n(\n    mark_event_id NUMBER(10,0) DEFAULT test_marker_event_id_seq.nextval,\n    entity_id NUMBER(10,0),\n    risk_marker_type_id NUMBER(10,0),\n    mark_event_eff_date TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP,\n    mark_event_end_date TIMESTAMP_NTZ DEFAULT TO_DATE('9999-12-31')\n);\n\nINSERT INTO test_entity_risk_markers (\n    entity_id,\n    risk_marker_type_id,\n    mark_event_eff_date,\n    mark_event_end_date\n) VALUES \n    (301, 501, TO_DATE('1994-01-08'), TO_DATE('9999-12-31')),\n    (302, 501, TO_DATE('1994-04-01'), TO_DATE('2003-04-15')),\n    (303, 501, TO_DATE('1994-01-08'), TO_DATE('9999-12-31')),\n    (301, 502, TO_DATE('1994-04-01'), TO_DATE('9999-12-31')),\n    (302, 502, TO_DATE('1994-01-08'), TO_DATE('2003-04-15')),\n    (303, 502, TO_DATE('1994-04-01'), TO_DATE('2003-04-15')),\n    (301, 503, TO_DATE('1994-01-08'), TO_DATE('9999-12-31')),\n    (302, 503, TO_DATE('1994-04-01'), TO_DATE('2003-04-15')),\n    (303, 503, TO_DATE('1994-01-08'), TO_DATE('9999-12-31')),\n    (310, 510, TO_DATE('1994-04-01'), TO_DATE('9999-12-31'));\n</code></pre>\n<div class=\"s-table-container\"><table class=\"s-table\">\n<thead>\n<tr>\n<th>mark_event_id</th>\n<th>entity_id</th>\n<th>risk_marker_type_id</th>\n<th>mark_event_eff_date</th>\n<th>mark_event_end_date</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>301</td>\n<td>501</td>\n<td>1994-01-08 00:00:00.000</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n<tr>\n<td>2</td>\n<td>302</td>\n<td>501</td>\n<td>1994-04-01 00:00:00.000</td>\n<td>2003-04-15 00:00:00.000</td>\n</tr>\n<tr>\n<td>3</td>\n<td>303</td>\n<td>501</td>\n<td>1994-01-08 00:00:00.000</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n<tr>\n<td>4</td>\n<td>301</td>\n<td>502</td>\n<td>1994-04-01 00:00:00.000</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n<tr>\n<td>5</td>\n<td>302</td>\n<td>502</td>\n<td>1994-01-08 00:00:00.000</td>\n<td>2003-04-15 00:00:00.000</td>\n</tr>\n<tr>\n<td>6</td>\n<td>303</td>\n<td>502</td>\n<td>1994-04-01 00:00:00.000</td>\n<td>2003-04-15 00:00:00.000</td>\n</tr>\n<tr>\n<td>7</td>\n<td>301</td>\n<td>503</td>\n<td>1994-01-08 00:00:00.000</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n<tr>\n<td>8</td>\n<td>302</td>\n<td>503</td>\n<td>1994-04-01 00:00:00.000</td>\n<td>2003-04-15 00:00:00.000</td>\n</tr>\n<tr>\n<td>9</td>\n<td>303</td>\n<td>503</td>\n<td>1994-01-08 00:00:00.000</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n<tr>\n<td>10</td>\n<td>310</td>\n<td>510</td>\n<td>1994-04-01 00:00:00.000</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n</tbody>\n</table></div>\n<p>Note in particular ID 1, 3 and 4 which are all active, and ids 2 and 5 which are inactive (as it has a real end date).</p>\n<p>Regardless of the logic in the risk identifier scripts, the output has the same schema, and a dummy output can be produced for a script that identifies marker types 501 and 502 here:</p>\n<pre class=\"lang-sql prettyprint-override\"><code>CREATE OR REPLACE TABLE test_marker_output(\n    entity_id NUMBER(10,0),\n    risk_marker_type_id NUMBER(10,0)\n);\n\nINSERT INTO test_marker_output(\n    entity_id,\n    risk_marker_type_id\n) VALUES\n    (301, 501),\n    (302, 501),\n    (305, 501),\n    (302, 502);\n</code></pre>\n<div class=\"s-table-container\"><table class=\"s-table\">\n<thead>\n<tr>\n<th>entity_id</th>\n<th>risk_marker_type_id</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>301</td>\n<td>501</td>\n</tr>\n<tr>\n<td>302</td>\n<td>501</td>\n</tr>\n<tr>\n<td>305</td>\n<td>501</td>\n</tr>\n<tr>\n<td>302</td>\n<td>502</td>\n</tr>\n</tbody>\n</table></div>\n<p>This simulates identifying a risk for entity 301, 302, and 305 for type 501, and 302 for type 502.</p>\n<p>The following SQL queries update the master table with the relevant info from the output table. In particular the 301-501 pair is already known about and open so no changes are needed (event id 1), the 305-501 event is a new risk and needs to be added (new event id), the 302-501 and 302-502 events were previously closed and need to be reopened (old events 2 and 5, need new events), and 303-501 and 301-502 are no longer detected and need to be closed (event id 3 and 4):</p>\n<pre class=\"lang-sql prettyprint-override\"><code>UPDATE test_entity_risk_markers cbm\n    SET cbm.mark_event_end_date = CURRENT_TIMESTAMP()\n    FROM (\n        WITH\n        mo_types AS (\n            SELECT\n                DISTINCT risk_marker_type_id\n            FROM test_marker_output\n        ),\n        to_close AS (\n            SELECT\n                cbm.*\n            FROM test_entity_risk_markers cbm\n            INNER JOIN mo_types\n            ON mo_types.risk_marker_type_id = cbm.risk_marker_type_id\n            LEFT OUTER JOIN test_marker_output mo\n            ON mo.entity_id = cbm.entity_id AND mo.risk_marker_type_id = cbm.risk_marker_type_id\n            WHERE mo.entity_id IS NULL\n            AND cbm.mark_event_end_date = TO_DATE('9999-12-31')\n        )\n        SELECT * FROM to_close\n    ) tc\n    WHERE cbm.mark_event_id = tc.mark_event_id;\n\nINSERT INTO test_entity_risk_markers(\n    entity_id,\n    risk_marker_type_id\n) SELECT \n    mo.*\nFROM test_marker_output mo\nLEFT JOIN test_entity_risk_markers cbm\nON mo.entity_id = cbm.entity_id AND mo.risk_marker_type_id = cbm.risk_marker_type_id\nWHERE cbm.mark_event_end_date &lt; TO_DATE('9999-12-31')\nOR cbm.mark_event_end_date IS NULL;\n\nSELECT * FROM test_entity_risk_markers;\n</code></pre>\n<div class=\"s-table-container\"><table class=\"s-table\">\n<thead>\n<tr>\n<th>mark_event_id</th>\n<th>entity_id</th>\n<th>risk_marker_type_id</th>\n<th>mark_event_eff_date</th>\n<th>mark_event_end_date</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>301</td>\n<td>501</td>\n<td>1994-01-08 00:00:00.000</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n<tr>\n<td>2</td>\n<td>302</td>\n<td>501</td>\n<td>1994-04-01 00:00:00.000</td>\n<td>2003-04-15 00:00:00.000</td>\n</tr>\n<tr>\n<td>3</td>\n<td>303</td>\n<td>501</td>\n<td>1994-01-08 00:00:00.000</td>\n<td>2025-05-15 14:10:26.873</td>\n</tr>\n<tr>\n<td>4</td>\n<td>301</td>\n<td>502</td>\n<td>1994-04-01 00:00:00.000</td>\n<td>2025-05-15 14:10:26.873</td>\n</tr>\n<tr>\n<td>5</td>\n<td>302</td>\n<td>502</td>\n<td>1994-01-08 00:00:00.000</td>\n<td>2003-04-15 00:00:00.000</td>\n</tr>\n<tr>\n<td>6</td>\n<td>303</td>\n<td>502</td>\n<td>1994-04-01 00:00:00.000</td>\n<td>2003-04-15 00:00:00.000</td>\n</tr>\n<tr>\n<td>7</td>\n<td>301</td>\n<td>503</td>\n<td>1994-01-08 00:00:00.000</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n<tr>\n<td>8</td>\n<td>302</td>\n<td>503</td>\n<td>1994-04-01 00:00:00.000</td>\n<td>2003-04-15 00:00:00.000</td>\n</tr>\n<tr>\n<td>9</td>\n<td>303</td>\n<td>503</td>\n<td>1994-01-08 00:00:00.000</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n<tr>\n<td>10</td>\n<td>310</td>\n<td>510</td>\n<td>1994-04-01 00:00:00.000</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n<tr>\n<td>11</td>\n<td>302</td>\n<td>501</td>\n<td>2025-05-15 14:10:28.015</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n<tr>\n<td>12</td>\n<td>302</td>\n<td>502</td>\n<td>2025-05-15 14:10:28.015</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n<tr>\n<td>13</td>\n<td>305</td>\n<td>501</td>\n<td>2025-05-15 14:10:28.015</td>\n<td>9999-12-31 00:00:00.000</td>\n</tr>\n</tbody>\n</table></div>\n<p>I do not want to copy-paste these 20 lines of code into the bottom of every risk identifier script, especially because others are creating some of these identifier scripts.</p>\n<p>I would like to abstract this code into a procedure or function that could be called and passed a temporary table reference our a query output. Therefore a template risk ID script would be:</p>\n<pre class=\"lang-sql prettyprint-override\"><code>CREATE OR REPLACE TEMP TABLE temp_output(\n    entity_id NUMBER(10,0),\n    risk_marker_type_id NUMBER(10,0)\n);\nINSERT INTO temp_output\nSELECT *\n-- normally some logic to identify risks\nFROM test_marker_output;\nCALL update_master_entity_risk_markers('temp_output');\n</code></pre>\n<p>This would call the procedure which contains the helper queries. But the queries are too large for a procedure and I dont know where to begin to insert such a large query with variables into a function. AS an example, here is the error for the procedure.</p>\n<pre class=\"lang-sql prettyprint-override\"><code>CREATE OR REPLACE PROCEDURE update_master_entity_risk_markers(tabref VARCHAR)\nRETURNS VARCHAR\nLANGUAGE SQL\nAS\n$$\nDECLARE\n    res RESULTSET;\nBEGIN\n  LET stmt VARCHAR := &quot;&quot;&quot;\n    UPDATE test_entity_risk_markers cbm\n        SET cbm.mark_event_end_date = CURRENT_TIMESTAMP()\n        FROM (\n            WITH\n            mo_types AS (\n                SELECT\n                    DISTINCT risk_marker_type_id\n                FROM ?\n            ),\n            to_close AS (\n                SELECT\n                    cbm.*\n                FROM test_entity_risk_markers cbm\n                INNER JOIN mo_types\n                ON mo_types.risk_marker_type_id = cbm.risk_marker_type_id\n                LEFT OUTER JOIN ? mo\n                ON mo.entity_id = cbm.entity_id AND mo.risk_marker_type_id = cbm.risk_marker_type_id\n                WHERE mo.entity_id IS NULL\n                AND cbm.mark_event_end_date = TO_DATE('9999-12-31')\n            )\n            SELECT * FROM to_close\n        ) tc\n        WHERE cbm.mark_event_id = tc.mark_event_id;\n\n    INSERT INTO test_entity_risk_markers(\n        entity_id,\n        risk_marker_type_id\n    ) SELECT \n        mo.*\n    FROM ? mo\n    LEFT JOIN test_entity_risk_markers cbm\n    ON mo.entity_id = cbm.entity_id AND mo.risk_marker_type_id = cbm.risk_marker_type_id\n    WHERE cbm.mark_event_end_date &lt; TO_DATE('9999-12-31')\n    OR cbm.mark_event_end_date IS NULL;\n    &quot;&quot;&quot;;\n  res := (EXECUTE IMMEDIATE stmt USING (tabref, tabref, tabref));\n  RETURN 'Table updated.';\nEND;\n$$;\n</code></pre>\n<pre><code>SQL compilation error:\nObject name '&quot;\n    UPDATE test_entity_risk_markers cbm\n        SET cbm.mark_event_end_date = CURRENT_TIMESTAMP()\n        FROM (\n            WITH\n            mo_types AS (\n                SELECT\n                    DISTINCT risk_marker_type_id\n                FROM ?\n            ),\n            to_close AS (\n                SELECT\n                    cbm.*\n                FROM test_entity_risk_markers cbm\n                INNER JOIN mo_types\n                ON mo_types.risk_marker_type_id = cbm.risk_marker_type_id\n                LEFT OUTER JOIN ? mo\n                ON mo.entity_id = cbm.entity_id AND mo.risk_marker_type_id = cbm.risk_marker_type_id\n                WHERE mo.entity_id IS NULL\n                AND cbm.mark_event_end_date = TO_DATE('9999-12-31')\n            )\n            SELECT * FROM to_close\n        ) tc\n        WHERE cbm.mark_event_id = tc.mark_event_id;\n\n    INSERT INTO test_entity_risk_markers(\n        entity_id,\n        risk_marker_type_id\n    ) SELECT \n        mo.*\n    FROM ? mo\n    LEFT JOIN test_entity_risk_markers cbm\n    ON mo.entity_id = cbm.entity_id AND mo.risk_marker_type_id = cbm.risk_marker_type_id\n    WHERE cbm.mark_event_end_date &lt; TO_DATE('9999-12-31')\n    OR cbm.mark_event_end_date IS NULL;\n    &quot;' exceeds maximum length limit of 255 characters.\n</code></pre>\n<p>How would I construct such a helper procedure or function?</p>\n",
        "tags": [
            "sql",
            "stored-procedures",
            "snowflake-cloud-data-platform",
            "user-defined-functions"
        ]
    },
    {
        "index": 40,
        "question_id": 79623626,
        "title": "Unable to install h3 extension in R",
        "body": "<p>I'm unable to install the <a href=\"https://duckdb.org/community_extensions/extensions/h3.html\" rel=\"nofollow noreferrer\">h3</a> community extension and I couldn't figure out the reason. See my code and error message below. Any idea what's causing the problem?</p>\n<pre><code>library(duckdb)\n\ncon &lt;- duckdb::dbConnect(duckdb::duckdb())\n\ndbExecute(con, &quot;INSTALL h3 FROM community;&quot;)\n</code></pre>\n<blockquote>\n<p>Error in <code>duckdb_result()</code>:\n! rapi_execute: Failed to run query\nError: HTTP Error: Failed to download extension &quot;h3&quot; at URL &quot;http://community-extensions.duckdb.org/v1.2.1/windows_amd64_mingw/h3.duckdb_extension.gz&quot; (HTTP 403)</p>\n</blockquote>\n<blockquote>\n<p>Candidate extensions: &quot;s3&quot;, &quot;http&quot;, &quot;https&quot;, &quot;httpfs&quot;, &quot;motherduck&quot;\nFor more info, visit <a href=\"https://duckdb.org/docs/extensions/troubleshooting/?version=v1.2.1&amp;platform=windows_amd64_mingw&amp;extension=h3\" rel=\"nofollow noreferrer\">https://duckdb.org/docs/extensions/troubleshooting/?version=v1.2.1&amp;platform=windows_amd64_mingw&amp;extension=h3</a>\nRun <code>rlang::last_trace()</code> to see where the error occurred.</p>\n</blockquote>\n",
        "tags": [
            "r",
            "duckdb",
            "h3"
        ]
    },
    {
        "index": 41,
        "question_id": 79624145,
        "title": "CMake: give one source file different flags in several targets declared in the same directory",
        "body": "<p><code>my_tool_func()</code> is a CMake-API utility function that injects per-source compile options into a user-supplied target.\nEverything works until the user (or my “matrix” test-suite) creates several targets in the same CMakeLists.txt that all reuse the same file.\nAt that point CMake merges the per-source properties and each target ends up with the union of flags.</p>\n<h2>Minimal reproducible example</h2>\n<pre><code>// test.cpp\n#include &lt;iostream&gt;\n\nint main()\n{\n#ifdef MODE_A\n    std::cout &lt;&lt; &quot;mode A\\n&quot;;\n#elif defined(MODE_B)\n    std::cout &lt;&lt; &quot;mode B\\n&quot;;\n#elif defined(MODE_C)\n    std::cout &lt;&lt; &quot;mode C\\n&quot;;\n#endif\n}\n</code></pre>\n<pre><code># CMakeLists.txt\n# TARGET_DIRECTORY requires at least 3.18\ncmake_minimum_required(VERSION 3.18) \nproject(multimode LANGUAGES CXX)\n\nset(modes MODE_A MODE_B MODE_C)\n\nforeach(mode IN LISTS modes)\n    add_executable(test.${mode} test.cpp)\n\n    # my_tool_func() effectively does this ↓\n    set_source_files_properties(test.cpp\n        TARGET_DIRECTORY test.${mode} #&lt; Doesn't work\n        PROPERTIES\n            COMPILE_OPTIONS &quot;-D${mode}&quot;\n    )\nendforeach()\n</code></pre>\n<h2>Observed:</h2>\n<p>Because every target is declared in the same directory, CMake stores\n<code>COMPILE_OPTIONS</code> once per directory + filename.\nOn the second and third loop iterations it concatenates the new value, so each\nbuild receives all three switches (<code>-DMODE_A -DMODE_B -DMODE_C</code>).</p>\n<h2>Required</h2>\n<ol>\n<li>In each target test.cpp must compile with exactly one <code>-DMODE_X</code>.</li>\n<li>No other source in the target may see that flag.</li>\n<li>The user’s sources must remain intact (no renaming, copying, or moving).</li>\n</ol>\n<h2>Questions</h2>\n<ol>\n<li><p>Is there any native CMake facility to apply per-target, per-source compile options so identical source paths in the same directory don’t share properties?</p>\n</li>\n<li><p>For my test-suite CMake project that auto-generates an N×M target matrix, what pattern lets me keep all targets in one directory while still assigning unique flags to test.cpp?</p>\n</li>\n<li><p>If a true per-target/per-source mechanism does not exist, can <code>my_tool_func()</code> reliably detect that the same path already has conflicting <code>COMPILE_OPTIONS</code> set elsewhere and emit a warning or error (e.g. by storing state in a project-wide cache variable)?</p>\n</li>\n</ol>\n<p>Any approach that ensures a single, unpolluted flag on <code>test.cpp</code> per target without affecting other files is welcome.</p>\n<hr />\n<p>For the test-suite that generates targets for matrix-type input, a naive solution that comes to mind is to just create the subfolders for each target in the build tree:</p>\n<pre><code>    foreach(_mode ${_modes})\n        string(TOLOWER &quot;${_mode}&quot; _mode)\n        set(_suffix &quot;.${_mode}-mode&quot;)\n        set(_target     &quot;${_base_name}${_suffix}&quot;)\n\n        # in order to not leak the flags from other generated targets,\n        # the targets must reside in different subdirectories\n        set(_subdir &quot;${CMAKE_BINARY_DIR}/${_target}&quot;)\n        file(MAKE_DIRECTORY &quot;${_subdir}&quot;)\n        file(WRITE &quot;${_subdir}/CMakeLists.txt&quot; &quot;add_executable(${_target})&quot;)\n        add_subdirectory(&quot;${_subdir}&quot; &quot;${_subdir}&quot;)\n        target_sources(${_target} PRIVATE &quot;${TEST_SOURCE_DIR}/test.cpp&quot;)\n        # ...\n    endforeach()\n</code></pre>\n",
        "tags": [
            "c++",
            "cmake"
        ]
    },
    {
        "index": 42,
        "question_id": 79624254,
        "title": "Is there a way to determine the stack size limit / end point within a running UEFI application?",
        "body": "<p>I have a fairly large UEFI application (2.1MB UPX compressed) that has a number of functions that allocate reasonably large data structures on the stack (kilobytes).  I'd like to add some debug code that can report the stack's high watermark (similar to what is described in <a href=\"https://stackoverflow.com/questions/389219/how-to-determine-maximum-stack-usage\">How to determine maximum stack usage?</a>, specifically for a UEFI application).  In order to implement this I need to know the location of the end of the stack.</p>\n<p>I've tried:</p>\n<ol>\n<li>Looking through the linker script but didn't see any reference to the stack</li>\n<li>Poking around at run-time allocating increasingly larger data blocks on the stack to see what happens.  The system I'm using has a lot of RAM so this went on for many gigabytes before it crashed</li>\n</ol>\n<p>At this point, I'm thinking the BIOS allocates a single stack and simply passes it along (via the RSP register) to the UEFI application.  I'm hoping there is a protocol to find the end of the stack.</p>\n",
        "tags": [
            "c",
            "stack",
            "x86-64",
            "stack-memory",
            "uefi"
        ]
    },
    {
        "index": 43,
        "question_id": 79624519,
        "title": "Given a pointer x, why does setting y = x pass ownership, but y = &amp;*x does not?",
        "body": "<p>So I am relatively new to Rust and am trying to understand the concept of ownership better. The code below does not compile:</p>\n<pre><code>fn main() {\n  let x = Box::new(1);\n  let y = x;\n  println!(&quot;{}&quot;, x);\n}\n</code></pre>\n<p>This makes sense, because the variable x has passed ownership to y.</p>\n<p>Then I tried the following code, which does compile:</p>\n<pre><code>fn main() {\n  let x = Box::new(1);\n  let y = &amp;*x;\n  println!(&quot;{}&quot;, x);\n}\n</code></pre>\n<p>My question is why? Does y = &amp;*x not have the same effect as y = x?</p>\n<p>Thanks.</p>\n",
        "tags": [
            "rust",
            "borrow-checker"
        ]
    },
    {
        "index": 44,
        "question_id": 79624880,
        "title": "Problems with different pseudo-elements sharing CSS code",
        "body": "<p>Lesson Learned ... Don't try to deal with coding issues when jet-lagged and blind from exhaustion.  Apologies.</p>\n<hr />\n<p>I can not combine both a <code>::before</code> and <code>::after</code> pseudo-element that share the same CSS.</p>\n<p>I have two versions of a logo, with the circle at opposite ends.  The CSS for each version is identical, except for the pseudo-element attached to the class name.</p>\n<pre><code>.rgt .logoname::after {\n  content: url(&quot;circle.svg&quot;);\n  display: inline-block;\n  width: 2.15em;\n  position: absolute;\n  z-index: -1;\n  right: -0.82em;\n  top: -0.55em;\n}\n\n.lft .logoname::before {\n  content: url(&quot;circle.svg&quot;);\n  display: inline-block;\n  width: 2.15em;\n  position: absolute;\n  z-index: -1;\n  left: -0.82em;\n  top: -0.55em;\n}\n</code></pre>\n<p>When I try to combine the two classes, separated by a comma (as below) the <code>::after</code> overrides the <code>::before</code> and so the circle only appears at the end of the name for each one.  I have tried switching the sequence that the classes appear, with the same result.</p>\n<pre><code>.lft .logoname::before, .rgt .logoname::after {\n  content: url(&quot;circle.svg&quot;);\n  display: inline-block;\n  width: 2.15em;\n  position: absolute;\n  z-index: -1;\n  right: -0.82em;\n  top: -0.55em;\n}\n</code></pre>\n<p>The basic code that we are using is below.  The lft (left) or rgt (right) class is applied to the grandparent of logoname to determine which version of the logo we are using in that spot.  It also controls postioning of the tease element.</p>\n<pre><code>&lt;div class=&quot;logowrap light lft&quot;&gt;\n  &lt;div class=&quot;logobox&quot;&gt;\n    &lt;div class=&quot;logoname&quot;&gt;PEDALERS&lt;/div&gt;\n    &lt;div class=&quot;tease&quot;&gt;ride, eat, relax&lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=&quot;logowrap dark rgt&quot;&gt;\n  &lt;div class=&quot;logobox&quot;&gt;\n    &lt;div class=&quot;logoname&quot;&gt;PEDALERS&lt;/div&gt;\n    &lt;div class=&quot;tease&quot;&gt;ride, eat, relax&lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>\n<p>Is there something in the CSS specs that prohibits having two different pseudo-elements share the same CSS code?</p>\n<p>While it is not a hardship to have both if necessary, it is just puzzling me as to why.</p>\n",
        "tags": [
            "html",
            "css",
            "pseudo-element"
        ]
    },
    {
        "index": 45,
        "question_id": 79624989,
        "title": "Linux Loader Lock / loader int __attribute__((constructor))",
        "body": "<p>I am currently developing a program module called test.so.\nInside this test.so, there is code that loads and uses an external library called wow.so.</p>\n<p>To test this module, I created a new test project. The execution flow is as follows:\nTest program (main) → test.so → internally loads wow.so</p>\n<p>Because test.so needs to automatically execute some code upon being loaded,\nI used a constructor function like this:\n<code>static void __attribute__((constructor)) my_init() { ... }</code></p>\n<p>However, this constructor function is not working properly.</p>\n<p>After some research, I found that attempting to load another .so file using dlopen()\nwithin a constructor function can fail. This appears to be due to loader lock or the initialization order of dynamic libraries on Linux.</p>\n<p>Furthermore, I do not have the source code or header files for wow.so; I only have the compiled .so file.\nAlso, I must solve this issue by modifying only test.so — I cannot modify any other part.</p>\n",
        "tags": [
            "c",
            "linux",
            ".so"
        ]
    },
    {
        "index": 46,
        "question_id": 79620135,
        "title": "Is it possible to make a fragment stay visible across two fragment steps, and then disappear?",
        "body": "<p>With <code>{.fragment .fade-in-then-out}</code>, we can display some content that disappears at the next fragment. I would like something like .fade-in-then-still-in-then-out, where the content would remain visible at the next fragment and then disappear at the following one. Is it possible to do that?</p>\n<p>Here is a concrete and reproducible example of what I would like:</p>\n<pre><code>---\ntitle-slide: false\nformat: \n  revealjs:\n    theme: sky\n---\n\n## Test\n\n::: {.fragment .fade-in .tiny-text}\n- first fragment\n:::\n\n::: {.fragment .fade-in .tiny-text}\n&lt;div style = &quot;position: absolute; top: 300px; left: 600px; width: 300px; text-align: center;&quot;&gt;\nsecond fragment: this text should disappear at the fourth fragment.\n&lt;/div&gt;\n:::\n\n::: {.fragment .fade-in .tiny-text}\n&lt;div style = &quot;position: absolute; top: 500px; left: 500px; width: 300px; text-align: center;&quot;&gt;\nthird fragment: this text should disappear at the fourth fragment.\n&lt;/div&gt;\n:::\n\n::: {.fragment .fade-in .tiny-text}\n- fourth fragment: the two texts of the second and third fragments should not be visible anymore.\n:::\n\n    \n&lt;style&gt;\n  .tiny-text {\n    font-size: 0.6em;\n  }\n&lt;/style&gt;\n</code></pre>\n",
        "tags": [
            "quarto",
            "reveal.js"
        ]
    },
    {
        "index": 47,
        "question_id": 79620180,
        "title": "Is XPath 2.0 backwards compatible? If not, where can I find a list of breaking changes?",
        "body": "<p>I am working on an application that extensively uses XPath expressions. The current XPath processor only supports XPath 1.0 syntax. I want to upgrade the application to support XPath 2.0 syntax. Is XPath 2.0 backwards compatible? Will my XPath 1.0 expressions continue to work the same way when processed by an XPath 2.0 processor? If not, what breaking changes do I need to look for in my existing XPath 1.0 expressions? Due to the nature of my application, it may not be feasible to regression test every existing XPath expression.</p>\n",
        "tags": [
            "xpath",
            "xpath-2.0"
        ]
    },
    {
        "index": 48,
        "question_id": 79620262,
        "title": "How to detect if a user truly left a Blazor Server app (vs. simple navigation)?",
        "body": "<p>I'm working on a Blazor Server app and need to detect when a user actually leaves the application (e.g. closes the browser/tab or loses connection), not just when they navigate between pages.</p>\n<p>As you know, each navigation within a Blazor Server app tears down the current circuit and opens a new one — which also triggers OnConnectionDownAsync() and OnConnectionUpAsync() in a custom CircuitHandler. This makes it hard to know whether the user simply navigated or truly disconnected.\nTo solve this, I’m trying the following approach:</p>\n<p><strong>Proposed approach:</strong>\nUse a timeout in OnConnectionDownAsync to delay any &quot;user disconnected&quot; logic, and cancel the timeout if a new circuit connects shortly afterward. Here’s the code:</p>\n<pre><code>private readonly ConcurrentDictionary&lt;string, Timer&gt; _disconnectTimers = new();\nprivate readonly ConcurrentHashSet&lt;string&gt; _activeCircuits = new(); // or use ConcurrentDictionary if needed\n\npublic override Task OnConnectionDownAsync(Circuit circuit, CancellationToken cancellationToken)\n{\n    var timer = new Timer(_ =&gt;\n    {\n        // Check if user has not reconnected\n        if (!_activeCircuits.Contains(circuit.Id))\n        {\n            _userTracker.MarkUserAsOffline(circuit.User);\n        }\n    }, null, TimeSpan.FromSeconds(5), Timeout.InfiniteTimeSpan);\n\n    _disconnectTimers[circuit.Id] = timer;\n\n    return Task.CompletedTask;\n}\n\npublic override Task OnConnectionUpAsync(Circuit circuit, CancellationToken cancellationToken)\n{\n    _activeCircuits.Add(circuit.Id);\n\n    if (_disconnectTimers.TryRemove(circuit.Id, out var timer))\n    {\n        timer.Dispose();\n    }\n\n    _userTracker.MarkUserAsOnline(circuit.User);\n\n    return Task.CompletedTask;\n}\n</code></pre>\n<p><strong>Question:</strong>\nDoes this approach make sense for distinguishing between user navigation and actual disconnects in Blazor Server?</p>\n<p>Are there any edge cases or race conditions I should watch out for?</p>\n<p>Is there a better pattern for handling this kind of circuit tracking?</p>\n<p>I’d appreciate feedback or improvements from anyone who’s dealt with similar scenarios.</p>\n",
        "tags": [
            ".net",
            "blazor",
            "signalr",
            "blazor-server-side"
        ]
    },
    {
        "index": 49,
        "question_id": 79620331,
        "title": "can a range of generators be joined",
        "body": "<p>Is it possible to have a range of generators and if yes, is it possible to join them ?</p>\n<pre><code>#include &lt;algorithm&gt;\n#include &lt;ranges&gt;\n#include &lt;vector&gt; \n#include &lt;cstdio&gt;\n#include &lt;generator&gt;\n#include &lt;iostream&gt;\nusing namespace std;\n \ntemplate&lt;typename T&gt;\nstruct Tree\n{\n    T value;\n    Tree *left{}, *right{};\n \n    std::generator&lt;const T&amp;&gt; traverse_inorder() const\n    {\n        if (left)\n            co_yield std::ranges::elements_of(left-&gt;traverse_inorder());\n \n        co_yield value;\n \n        if (right)\n            co_yield std::ranges::elements_of(right-&gt;traverse_inorder());\n    }\n};\n \nint main()\n{\n    Tree&lt;char&gt; tree1[]\n    {\n                                    {'D', tree1 + 1, tree1 + 2},\n        //                            │\n        //            ┌───────────────┴────────────────┐\n        //            │                                │\n                    {'B', tree1 + 3, tree1 + 4},       {'F', tree1 + 5, tree1 + 6},\n        //            │                                │\n        //  ┌─────────┴─────────────┐      ┌───────────┴─────────────┐\n        //  │                       │      │                         │\n          {'A'},                  {'C'}, {'E'},                    {'G'}\n    };\n\n    generator&lt;const char&amp;&gt; gen = tree1-&gt;traverse_inorder();\n    for (char x : gen)\n        std::cout &lt;&lt; x &lt;&lt; ' ';\n    std::cout &lt;&lt; '\\n';\n\n    generator&lt;const char&amp;&gt; gen3[3]={gen,gen,gen};\n    for (char x : gen3 | views::join)\n        std::cout &lt;&lt; x &lt;&lt; ' ';\n}\n</code></pre>\n<pre class=\"lang-none prettyprint-override\"><code>prog.cc: In function 'int main()':\nprog.cc:47:48: error: use of deleted function 'std::generator&lt;_Ref, _Val, _Alloc&gt;::generator(const std::generator&lt;_Ref, _Val, _Alloc&gt;&amp;) [with _Ref = const char&amp;; _Val = void; _Alloc = void]'\n   47 |     generator&lt;const char&amp;&gt; gen3[3]={gen,gen,gen};\n      |                                                ^\nIn file included from prog.cc:5:\n/opt/wandbox/gcc-head/include/c++/16.0.0/generator:712:7: note: declared here\n  712 |       generator(const generator&amp;) = delete;\n      |       ^~~~~~~~~\nprog.cc:47:48: note: use '-fdiagnostics-all-candidates' to display considered candidates\n   47 |     generator&lt;const char&amp;&gt; gen3[3]={gen,gen,gen};\n      |                                                ^\nprog.cc:47:48: error: use of deleted function 'std::generator&lt;_Ref, _Val, _Alloc&gt;::generator(const std::generator&lt;_Ref, _Val, _Alloc&gt;&amp;) [with _Ref = const char&amp;; _Val = void; _Alloc = void]'\n/opt/wandbox/gcc-head/include/c++/16.0.0/generator:712:7: note: declared here\n  712 |       generator(const generator&amp;) = delete;\n      |       ^~~~~~~~~\nprog.cc:47:48: note: use '-fdiagnostics-all-candidates' to display considered candidates\n   47 |     generator&lt;const char&amp;&gt; gen3[3]={gen,gen,gen};\n      |                                                ^\nprog.cc:47:48: error: use of deleted function 'std::generator&lt;_Ref, _Val, _Alloc&gt;::generator(const std::generator&lt;_Ref, _Val, _Alloc&gt;&amp;) [with _Ref = const char&amp;; _Val = void; _Alloc = void]'\n/opt/wandbox/gcc-head/include/c++/16.0.0/generator:712:7: note: declared here\n  712 |       generator(const generator&amp;) = delete;\n      |       ^~~~~~~~~\nprog.cc:47:48: note: use '-fdiagnostics-all-candidates' to display considered candidates\n   47 |     generator&lt;const char&amp;&gt; gen3[3]={gen,gen,gen};\n      |                                                ^\n</code></pre>\n",
        "tags": [
            "c++",
            "std-ranges",
            "c++23",
            "c++-coroutine"
        ]
    },
    {
        "index": 50,
        "question_id": 79620333,
        "title": "Insert new column (of blanks) into an existing dataframe",
        "body": "<p>I have an existing dataframe:</p>\n<pre><code>data = [[5011025, 234], [5012025, 937], [5013025, 625]]\ndf = pd.DataFrame(data)\n</code></pre>\n<p>output:</p>\n<pre><code>         0    1\n0  5011025  234\n1  5012025  937\n2  5013025  625\n</code></pre>\n<p>What I need to do is insert a new column at <code>0</code> (the same # of rows) that contains 3 spaces. Recreating the dataframe, from scratch, it would be something like this:</p>\n<pre><code>data = [['   ',5011025, 234], ['   ',5012025, 937], ['   ',5013025, 625]]\ndf = pd.DataFrame(data)\n</code></pre>\n<p>desired output:</p>\n<pre><code>     0        1    2\n0       5011025  234\n1       5012025  937\n2       5013025  625\n</code></pre>\n<p>What is the best way to <code>insert()</code> this new column into an existing dataframe, that may be hundreds of rows?\nUltimately, i'm trying to figure out how to write a function that will shift all columns of a dataframe x number of spaces to the right.</p>\n",
        "tags": [
            "python",
            "pandas"
        ]
    },
    {
        "index": 51,
        "question_id": 79620366,
        "title": "How do I parse text from my front-end into R?",
        "body": "<p>I'm building a Vue app that uses R for the back-end. I was able to successfully pull in data from a form into R. I'm using the plumber library. However, I don't know how to parse text.</p>\n<p>Here is the R code I'm using to pull data from my Vue app form. It works properly.</p>\n<pre><code>#* @filter cors\nfunction(req, res) {\n  res$setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;)\n  plumber::forward()\n  print(req$postBody)\n}\n</code></pre>\n<p>The output of the <code>print(req$postBody)</code> looks like this:</p>\n<pre><code> &quot;------WebKitFormBoundaryAuwYTPBpNXvAQ125\\nContent-Disposition: form-data; name=\\&quot;file\\&quot;; filename=\\&quot;test.csv\\&quot;\\nContent-Type: text/csv\\n\\nx,y\\n1,10\\n2,3\\n3,5\\n4,7\\n5,9\\n6,5\\n------WebKitFormBoundaryAuwYTPBpNXvAQ125\\nContent-Disposition: form-data; name=\\&quot;graphType\\&quot;\\n\\nscatter\\n------WebKitFormBoundaryAuwYTPBpNXvAQ125\\nContent-Disposition: form-data; name=\\&quot;xAxis\\&quot;\\n\\nx\\n------WebKitFormBoundaryAuwYTPBpNXvAQ125\\nContent-Disposition: form-data; name=\\&quot;yAxis\\&quot;\\n\\ny\\n------WebKitFormBoundaryAuwYTPBpNXvAQ125\\nContent-Disposition: form-data; name=\\&quot;customText\\&quot;\\n\\nhi it's Priya\\n------WebKitFormBoundaryAuwYTPBpNXvAQ125--&quot;\n</code></pre>\n<p>The above string contains all of my form inputs (such as &quot;hi it's Priya&quot;). However, I can't parse it into the variables that I need. This was my code:</p>\n<pre><code>#* @post /api/generate-graph\n#* @param file:file\n#* @param graphType:string\n#* @param xAxis:string\n#* @param yAxis:string\n#* @param customText:string\n</code></pre>\n<p>but it's not pulling the correct text strings. What am I doing wrong?</p>\n<p>For more context, here is my front end script:</p>\n<pre><code>&lt;script setup&gt;\nimport { ref } from 'vue'\nimport axios from 'axios'\n\nconst file = ref(null)\nconst graphType = ref('scatter')\nconst xAxis = ref('')\nconst yAxis = ref('')\nconst graphData = ref(null)\nconst loading = ref(false)\nconst error = ref(null)\nconst csvPreview = ref(null)\nconst customText = ref('')\nconst availableColumns = ref([])\n\nconst graphTypes = [\n  { value: 'scatter', label: 'Scatter Plot' },\n  { value: 'line', label: 'Line Graph' },\n  { value: 'bar', label: 'Bar Chart' },\n  { value: 'histogram', label: 'Histogram' }\n]\n\nconst handleFileUpload = async (event) =&gt; {\n  const uploadedFile = event.target.files[0]\n  if (uploadedFile &amp;&amp; uploadedFile.type === 'text/csv') {\n    file.value = uploadedFile\n    // Preview CSV data\n    const reader = new FileReader()\n    reader.onload = async (e) =&gt; {\n      const text = e.target.result\n      const lines = text.split('\\n')\n      const headers = lines[0].split(',')\n      csvPreview.value = {\n        headers,\n        firstRow: lines[1].split(',')\n      }\n\n      // Get column names from the backend\n      const formData = new FormData()\n      formData.append('file', uploadedFile)\n      formData.append('graphType', graphType.value)\n      formData.append('xAxis', '')\n      formData.append('yAxis', '')\n      formData.append('customText', customText.value)\n\n      try {\n        const response = await axios.post('http://localhost:8000/api/generate-graph', formData, {\n          headers: {\n            'Content-Type': 'multipart/form-data'\n          }\n        })\n        availableColumns.value = response.data.columns\n      } catch (err) {\n        console.error('Error getting column names:', err)\n        error.value = 'Error getting column names: ' + (err.response?.data || err.message)\n      }\n    }\n    reader.readAsText(uploadedFile)\n  } else {\n    error.value = 'Please upload a valid CSV file'\n  }\n}\n\nconst generateGraph = async () =&gt; {\n  if (!file.value) {\n    error.value = 'Please upload a CSV file first'\n    return\n  }\n\n  if (!xAxis.value || !yAxis.value) {\n    error.value = 'Please specify both X and Y axis columns'\n    return\n  }\n\n  loading.value = true\n  error.value = null\n\n\n  // I think the issue is that there are two types of data being sent to the backend, one is the csv and the other is the form data\n  // I need to send the csv as a file and the form data as a form data object\n  const formData = new FormData()\n  formData.append('file', file.value)\n  formData.append('graphType', graphType.value)\n  formData.append('xAxis', xAxis.value)\n  formData.append('yAxis', yAxis.value)\n  formData.append('customText', customText.value)\n\n  // Debug logging\n  console.log('Form data being sent:')\n  for (let pair of formData.entries()) {\n    console.log(pair[0] + ': ' + pair[1])\n  }\n  console.log('xAxis:', xAxis.value)\n  console.log('yAxis:', yAxis.value)\n  console.log('graphType:', graphType.value)\n  console.log('customText:', customText.value)\n\n  try {\n\n    const response = await axios.post('http://localhost:8000/api/generate-graph', formData, {\n      headers: {\n        'Content-Type': 'multipart/form-data'\n      }\n    })\n    graphData.value = response.data\n  } catch (err) {\n    console.error('Error details:', err)\n    error.value = 'Error generating graph: ' + (err.response?.data || err.message)\n  } finally {\n    loading.value = false\n  }\n}\n\nconst downloadGraph = async (format) =&gt; {\n  if (!graphData.value) return\n\n  try {\n    const response = await axios.get(`http://localhost:8000/api/download`, {\n      params: {\n        format,\n        path: graphData.value[`${format}_path`]\n      },\n      responseType: 'blob'\n    })\n\n    const url = window.URL.createObjectURL(new Blob([response.data]))\n    const link = document.createElement('a')\n    link.href = url\n    link.setAttribute('download', `graph.${format}`)\n    document.body.appendChild(link)\n    link.click()\n    link.remove()\n  } catch (err) {\n    error.value = 'Error downloading graph: ' + err.message\n  }\n}\n\n&lt;/script&gt;\n</code></pre>\n",
        "tags": [
            "javascript",
            "html",
            "r",
            "vue.js",
            "plumber"
        ]
    },
    {
        "index": 52,
        "question_id": 79620434,
        "title": "Cannot add persistent generated datetime column with if statement",
        "body": "<p>I'm confused at the behaviour of persistent generated columns in Mariadb when it comes to IF statements and dates. The following works:</p>\n<pre><code>CREATE TABLE `test1` (\n    `date` datetime(3),\n    `generated` datetime(3) AS (\n      `date` - INTERVAL 1 SECOND\n  ) STORED\n);\n</code></pre>\n<p>As does this:</p>\n<pre><code>CREATE TABLE `test2` (\n    `date` datetime(3),\n    `generated` datetime(3) AS (\n      IF(`date` IS NOT NULL, `date` - INTERVAL 1 SECOND, `date`)\n  ) STORED\n);\n</code></pre>\n<p>As does this:</p>\n<pre><code>CREATE TABLE `test3` (\n    `date` datetime(3),\n    `generated` datetime(3) AS (\n      '2000-01-01 00:00:00'\n  ) STORED\n);\n</code></pre>\n<p>But this doesn't:</p>\n<pre><code>CREATE TABLE `test4` (\n    `date` datetime(3),\n    `generated` datetime(3) AS (\n      IF(`date` IS NOT NULL, `date` - INTERVAL 1 SECOND, '2000-01-01 00:00:00')\n  ) STORED\n);\n</code></pre>\n<p>It throws the following error:</p>\n<pre><code>ERROR 1901 (HY000) at line 16: Function or expression 'if(`date` is not null,`date` - interval 1 second,'2000-01-01 00:00:00')' cannot be used in the GENERATED ALWAYS AS clause of `generated`\n</code></pre>\n<p>I've put together these examples here: <a href=\"https://onecompiler.com/mariadb/43hnm9j7r\" rel=\"nofollow noreferrer\">https://onecompiler.com/mariadb/43hnm9j7r</a>, but have also tested locally with mariadb 10.11, and the behaviour in mysql seems to be the same.</p>\n<p>Making the generated column <code>VIRTUAL</code> rather than <code>STORED</code> fixes the problem, as expected, but in my use case I'd like to be able to add an index on the generated column.</p>\n<p>The docs say:</p>\n<blockquote>\n<p>Non-deterministic built-in functions are not supported in expressions for PERSISTENT or indexed VIRTUAL generated columns.</p>\n</blockquote>\n<p>So what part of the final example there is non-deterministic, when all of its component parts work fine?</p>\n",
        "tags": [
            "mariadb",
            "virtual-column",
            "mariadb-10.11"
        ]
    },
    {
        "index": 53,
        "question_id": 79620454,
        "title": "It is not possible to load data from a specific column in the dataset",
        "body": "<p>I select columns X and Y to solve a linear regression problem.</p>\n<pre><code>X = df.loc[:, ['Water']]\ny = df.loc[:, ['Superplasticizer']]\n</code></pre>\n<p>but in the next line of code, python doesn't see it anymore and has to type it in again. At the same time, it gives an error by the column name that I don't quite understand, so I select the column by its number, but python gives an error due to the number of errors.</p>\n<pre><code>x_train = x[:-250],  X = df.loc[:,df.columns[4] ] #250 = 25% от всех данных\nx_test = х[-250:]\n</code></pre>\n<p>ValueError: too many values to unpack (expected 2) - here's a mistake, I don't understand what the error is at all, I've already searched the entire Internet, I haven't found an answer.</p>\n",
        "tags": [
            "python",
            "pandas"
        ]
    },
    {
        "index": 54,
        "question_id": 79620559,
        "title": "How would I disable &quot;snapping&quot; of elements when moving them in Scene Builder?",
        "body": "<p>I'm designing a UI in JavaFx and I'm using Scene Builder to do so, but I can't move any elements with precision due to the uncontrollable &quot;snapping&quot; of moving elements in scene builder which I can't turn off.</p>\n<p>When I try to move any element in scene builder (text, buttons, fields), I can't move them precisely at all and it always snaps to the wrong place (red lines) and can't move them in a way that takes the position of other elements in mind like google slides for example, so I just want to turn it off, but I cant. The only workaround I have found is manually changing the X and Y of an element to a precise value in the position portion of the &quot;Layout&quot; section but this is also not ideal. is there any way I can turn it off or at least make it better? Or some other way from more experienced javaFX designers to move elements around parallel to other elements / with more precision?</p>\n<p>Another problem is that when I move any element the right side of an anchor pane in scene builder, it ends up making the anchor pane bigger and makes the element stay where it was relative to the new size, but doesn't happen on the left side for some reason which is also pretty annoying but not as annoying as the other problem.\nThanks</p>\n",
        "tags": [
            "java",
            "user-interface",
            "javafx",
            "scenebuilder"
        ]
    },
    {
        "index": 55,
        "question_id": 79620592,
        "title": "SwiftUI Crash VStack Init/Overflow",
        "body": "<p>I am failing app review because of a <code>EXC_BAD_ACCESS (SIGSEGV)</code> when app review simply opens a view. I tried reproducing it on every real/sim device possible and iOS version but I can't. I will add a link below to the symbolicated crash logs. GPT says the crash logs indicate a seg fault on the <code>VStack</code> when the view is initialized due to an overflow in the stack. App review said simply opening the view causes the crash. I've resubmitted to apple review multiple times and somehow they can reproduce it every time, but I can't. Im not the best at understanding these crash logs Id appreciate so help.</p>\n<ul>\n<li>I tried using LazyVstack and Vstack but did not help.</li>\n<li>I tried removing all <code>scrollTransition</code></li>\n<li>My view has no recursion</li>\n<li>There's a total of 20 static items (<code>rowView</code>) in the scrollview</li>\n</ul>\n<p>I'll include a basic structure of my code. I'd appreciate it if anyone see any issues. To be clear, I CANNOT provide a reproducible example because even I can't reproduce on any device. Therefor I provided the basic layout of my view along with the symbolicated crash logs.</p>\n<p><strong>Symbolicated crash log</strong>\n<a href=\"https://docs.google.com/document/d/1In0zJLu0XnS4CAW5Uc5sFzU_Zawm5yfNH7N51Rf2bOQ/edit?usp=sharing\" rel=\"nofollow noreferrer\">https://docs.google.com/document/d/1In0zJLu0XnS4CAW5Uc5sFzU_Zawm5yfNH7N51Rf2bOQ/edit?usp=sharing</a></p>\n<pre><code>struct ToolsView: View {\n    @EnvironmentObject var auth: AuthViewModel\n    @EnvironmentObject var popRoot: PopToRoot\n    @Environment(\\.colorScheme) var colorScheme\n    @State var filter = &quot;No filter&quot;\n    @State var filterImage = &quot;shoe&quot;\n    @Namespace var hero\n\n    @State var sheetIDThanks = UUID().uuidString\n    \n    @State var sentTotal = 0\n    @State private var isShowingMessages = false\n    @State private var recipients: [String] = []\n    \n    let wealthAioPoints = [&quot;A heavy duty automation tool, made simple.&quot;]\n    let wealthAccountsPoints = [&quot;All the accounts you need.&quot;]\n    // ... more points arrays with info\n    \n    var body: some View {\n        ScrollViewReader { proxy in\n            ScrollView {\n                VStack(spacing: 15){ // Line 41 - crash here\n                    Color.clear.frame(height: 1).id(&quot;scrolltop&quot;)\n                    \n                    rowView(type: 0, image: &quot;WealthIcon&quot;, title: &quot;Wealth AIO&quot;, points: wealthAioPoints, owned: auth.currentUser?.hasBotAccess ?? false, price: &quot;$49.99&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: -3, image: &quot;instances&quot;, title: &quot;Wealth Scale&quot;, points: wealthScalePoints, owned: auth.currentUser?.ownedInstances != nil, price: &quot;$34.99&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: -1, image: &quot;Proxies&quot;, title: &quot;Wealth Proxies&quot;, points: wealthProxyPoints, owned: true, price: &quot;&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: -4, image: &quot;WealthAccounts&quot;, title: &quot;Accounts Oasis&quot;, points: wealthAccountsPoints, owned: true, price: &quot;&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: -2, image: &quot;Server&quot;, title: &quot;Wealth Servers&quot;, points: wealthServerPoints, owned: true, price: &quot;&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: 9, image: &quot;aiLogo&quot;, title: &quot;Ai Profile+&quot;, points: aiProfilePoints, owned: (auth.currentUser?.unlockedTools ?? []).contains(&quot;Ai Profile+&quot;), price: &quot;$29.99&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                                            \n                    rowView(type: 7, image: &quot;qApp&quot;, title: &quot;In-App Queue&quot;, points: inAppQPoints, owned: (auth.currentUser?.unlockedTools ?? []).contains(&quot;In-App Queue&quot;), price: &quot;$39.99&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: 8, image: &quot;qDiscord&quot;, title: &quot;Discord Queue&quot;, points: discordQPoints, owned: (auth.currentUser?.unlockedTools ?? []).contains(&quot;Discord Queue&quot;), price: &quot;$99.99&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: 6, image: &quot;variantScraper&quot;, title: &quot;Variant Scraper&quot;, points: variantPoints, owned: (auth.currentUser?.unlockedTools ?? []).contains(&quot;Variant Scraper&quot;), price: &quot;$99.99&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: 1, image: &quot;forwardPro&quot;, title: &quot;Forward Pro&quot;, points: forwardProPoints, owned: (auth.currentUser?.unlockedTools ?? []).contains(&quot;Forward Pro&quot;), price: &quot;$149.99&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: 2, image: &quot;forwardLite&quot;, title: &quot;Forward Lite&quot;, points: forwardLitePoints, owned: (auth.currentUser?.unlockedTools ?? []).contains(&quot;Forward Lite&quot;), price: &quot;$99.99&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: 3, image: &quot;CsvPro&quot;, title: &quot;CSV Pro&quot;, points: csvProPoints, owned: (auth.currentUser?.unlockedTools ?? []).contains(&quot;CSV Pro&quot;), price: &quot;$149.99&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: 4, image: &quot;CsvLite&quot;, title: &quot;CSV Lite&quot;, points: csvLitePoints, owned: (auth.currentUser?.unlockedTools ?? []).contains(&quot;CSV Lite&quot;), price: &quot;$99.99&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                    \n                    rowView(type: 5, image: &quot;stockChecker&quot;, title: &quot;Stock Checker&quot;, points: stockPoints, owned: (auth.currentUser?.unlockedTools ?? []).contains(&quot;Stock Checker&quot;), price: &quot;$49.99&quot;)\n                        .scrollTransition { content, phase in\n                            content\n                                .scaleEffect(phase == .identity ? 1 : 0.65)\n                                .blur(radius: phase == .identity ? 0 : 10)\n                        }\n                        \n                    Color.clear.frame(height: 150)\n                }\n            }\n            .safeAreaPadding(.top, 60 + top_Inset())\n            .scrollIndicators(.hidden)\n            .onChange(of: popRoot.tap) { _, _ in\n                if popRoot.tap == 2 &amp;&amp; appeared {\n                    withAnimation {\n                        proxy.scrollTo(&quot;scrolltop&quot;, anchor: .bottom)\n                    }\n                    popRoot.tap = 0\n                }\n            }\n        }\n        .sheet(isPresented: $isShowingMessages) {\n            MessageUIView(recipients: $recipients, body: $message, completion: handleCompletion(_:))\n        }\n        .sheet(isPresented: $showSettings, content: {\n            SettingsSheetView(hideOrderNums: .constant(nil))\n        })\n        .overlay(alignment: .top) {\n            headerView()\n        }\n        .ignoresSafeArea()\n        .onAppear(perform: {\n            appeared = true\n        })\n        .onDisappear {\n            appeared = false\n        }\n        .sheet(isPresented: $showBuySheet) {\n            buySheet().id(sheetID)\n        }\n        .sheet(isPresented: $showThanksSheet) {\n            thanksSheet().id(sheetIDThanks)\n        }\n    }\n    @ViewBuilder\n    func rowView(type: Int, image: String, title: String, points: [String], owned: Bool, price: String) -&gt; some View {\n        VStack(spacing: 0){\n            Image(image)\n                .resizable().scaledToFill()\n                .frame(height: 100).blur(radius: 6)\n                .clipShape(UnevenRoundedRectangle(topLeadingRadius: 12, topTrailingRadius: 12))\n                .contentShape(UnevenRoundedRectangle(topLeadingRadius: 12, topTrailingRadius: 12))\n                .overlay(alignment: .topLeading){\n                    VStack(alignment: .leading, spacing: 3){\n                        if type == 12 || type == 14 || type == 16 || type == 17 || type == 19 || type == 21 {\n                            Text(&quot;One Time: \\(price)&quot;)\n                                .fontWeight(.heavy).font(.subheadline)\n                                .padding(.horizontal, 10).padding(.vertical, 4)\n                                .background(.ultraThinMaterial)\n                                .clipShape(Capsule()).padding(.leading, 10).padding(.top, 10)\n                        } else if type == -1 || type == -4 {\n                            Text(&quot;Pay as you go&quot;)\n                                .fontWeight(.heavy).font(.subheadline)\n                                .padding(.horizontal, 10).padding(.vertical, 4)\n                                .background(.ultraThinMaterial)\n                                .clipShape(Capsule()).padding(12)\n                        }\n\n                        Spacer()\n                    }\n                }\n                .overlay(alignment: .bottomTrailing){\n                    Image(image)\n                        .resizable().scaledToFill()\n                        .frame(width: 70, height: 70)\n                        .clipShape(RoundedRectangle(cornerRadius: 12))\n                        .contentShape(RoundedRectangle(cornerRadius: 12))\n                        .overlay(content: {\n                            RoundedRectangle(cornerRadius: 12)\n                                .stroke(.gray, lineWidth: 1).opacity(0.6)\n                        })\n                        .offset(y: 36).padding(.trailing, 20)\n                }\n            \n            HStack(alignment: .top){\n                Text(title).font(.title2).bold()\n                Spacer()\n            }.padding(.horizontal, 10).padding(.top, 10)\n            \n            VStack(alignment: .leading, spacing: 7){\n                ForEach(points, id: \\.self) { item in\n                    HStack(spacing: 2){\n                        Text(&quot;-&quot;).font(.system(size: 13)).bold().foregroundStyle(.blue)\n                        \n                        Text(item).multilineTextAlignment(.leading).font(.system(size: 13))\n                        \n                        Spacer()\n                    }\n                }\n                \n            }.padding(.horizontal, 10).padding(.top, 10).padding(.bottom, 10)\n        }\n        .background(content: {\n            TransparentBlurView(removeAllFilters: true)\n                .blur(radius: 14, opaque: true)\n                .background(colorScheme == .dark ? .black.opacity(0.4) : .white.opacity(0.4))\n        })\n        .clipShape(RoundedRectangle(cornerRadius: 12))\n        .contentShape(RoundedRectangle(cornerRadius: 12))\n        .overlay(content: {\n            RoundedRectangle(cornerRadius: 12)\n                .stroke(lineWidth: 1).opacity(0.4)\n        })\n        .padding(.horizontal, 12)\n    }\n}\n</code></pre>\n",
        "tags": [
            "ios",
            "swiftui"
        ]
    },
    {
        "index": 56,
        "question_id": 79620684,
        "title": "Cut operator not discarding choice points?",
        "body": "<p><strong>Disclaimer:</strong> Yes, this is for an assignment, but I think I have an alternative solution already. I just want to figure out why this initial attempt did not work because I can't understand why it isn't functioning as intended.</p>\n<p>I'm coding a predicate <code>path/2</code> (<code>path(+Node1, +Node2)</code>) that takes two nodes and returns <code>true</code> if there is a valid path from <code>Node1</code> to <code>Node2</code> through a separately defined <code>edge/2</code> predicate (semantically, <code>edge(A, B).</code> represents a directed edge from <code>A</code> to <code>B</code>).</p>\n<pre><code>%    WRAPPER\npath(N1, N2) :-\n    pathHelper(N1, N2, []).\n\n%    HELPER\npathHelper(N1, N2, Checked) :-\n    \\+ member(N1, Checked),\n    (\n        (N1 = N2, !); % sort of a base case?\n        NewChecked = [N1 | Checked],\n        (\n            edge(N1, Next),\n            pathHelper(Next, N2, NewChecked)\n        )\n    ).\n</code></pre>\n<p>To my understanding, once it hits <code>(N1 = N2, !);</code> and  is indeed able to unify <code>N1</code> with <code>N2</code>, it should proceed to the <code>!</code> <em>cut</em> and discard all previous choice points, and then proceed to short-circuit out of the rest of the statements, meaning it won't look for other nodes that can form a path. However, given the following knowledge base:</p>\n<pre><code>%    KNOWLEDGE BASE\nedge(a,b).\nedge(b,c).\nedge(c,d).\nedge(d,a).\nedge(d,e).\nedge(b,a).\n</code></pre>\n<p>and the query:</p>\n<p><code>?- path(b, d).</code></p>\n<p>the program displays <code>true.</code> for the path 'b' -&gt; 'c' -&gt; 'd' (verified through trace mode), but also steps back to check 'b' for other connected nodes, landing on 'a' and checking again, then displaying <code>false.</code> From my understanding of how choice points work, the <code>!</code> should have stopped it from backtracking to 'b' to check for more nodes.</p>\n<p>What is flawed about my understanding of the <em>cut</em> operator that is preventing me from understanding why the code results in this output?</p>\n",
        "tags": [
            "recursion",
            "prolog",
            "prolog-cut"
        ]
    },
    {
        "index": 57,
        "question_id": 79620887,
        "title": "Maven downgrades transitive dependency scopes",
        "body": "<p>Let's assume I have a simple Java project. For some reason I need, let's say, some <code>StringUtil</code> class in my tests. So, I add the dependency with a <code>test</code> scope. This works fine and it as it should be.</p>\n<p>But if someone in the future either adds the <code>StringUtil</code> dependency to any of my <code>compile</code> dependencies - or if I add a new <code>compile</code> dependency which also uses it - maven will still see it as a <code>test</code> dependency without any warning or similar - well documented <a href=\"https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html#Dependency_Scope\" rel=\"nofollow noreferrer\">here</a>, even if the dependency actually also needs it during runtime.</p>\n<p>In combination with the spring boot maven plugin, which packages a fat jar, this seems very dangerous, because as <code>test</code>, the <code>StringUtil</code> will not be part of that fat jar, leading to quite obvious runtime problems.</p>\n<p>Anyone ever encountered that and found a good way to handle it?</p>\n",
        "tags": [
            "java",
            "maven",
            "dependency-management",
            "spring-boot-maven-plugin"
        ]
    },
    {
        "index": 58,
        "question_id": 79620943,
        "title": "When does the &#39;FILTER&#39; operation happen?",
        "body": "<pre><code>select * from emp where empno = 7499 and hiredate between '19000101' and '29991212';\n\nId Operation Name                Name\n-- ----------------------------- ------\n0  SELECT STATEMENT\n1   FILTER                       EMP\n2    TABLE ACCESS BY INDEX ROWID PK_EMP\n3     INDEX UNIQUE SCAN\n</code></pre>\n<p>So far, I knew that the 'FILTER' operation occurs in the main query-subquery relationship, but I found that the 'FILTER' operation also occurs in the above simple query(Id = 1).</p>\n<p>I've been running a lot of queries to generalize the situation where the 'FILTER' operation happens, but I can't find the rules. When does the 'FILTER' operation happen?</p>\n<hr />\n<p><strong>UPDATE:</strong></p>\n<pre><code>alter session set nls_date_format = 'YYYYMMDD';\n\nselect * from emp where hiredate between '20000101' and '29991212';\n\n--------------------------------------------\n| Id  | Operation          | Name | E-Rows |\n--------------------------------------------\n|   0 | SELECT STATEMENT   |      |        |\n|*  1 |  FILTER            |      |        |\n|*  2 |   TABLE ACCESS FULL| EMP  |      1 |\n--------------------------------------------\n \nPredicate Information (identified by operation id):\n---------------------------------------------------\n \n   1 - filter(TO_DATE('29991212')&gt;=TO_DATE('20000101'))\n   2 - filter((&quot;HIREDATE&quot;&gt;='20000101' AND &quot;HIREDATE&quot;&lt;='29991212'))\n</code></pre>\n<p>As you can see, even though I changed <code>date</code> to <code>yyyyymmdd</code> format, the FILTER operation still occurs.</p>\n<pre><code>create table test1 ( col1 timestamp );\ninsert into test1 values ( current_timestamp );\n\nselect * from test1 where col1 between '20000101' and '29991212';\n\n--------------------------------------------\n| Id  | Operation         | Name  | E-Rows |\n--------------------------------------------\n|   0 | SELECT STATEMENT  |       |        |\n|*  1 |  TABLE ACCESS FULL| TEST1 |      1 |\n--------------------------------------------\n \nPredicate Information (identified by operation id):\n---------------------------------------------------\n \n   1 - filter((&quot;COL1&quot;&gt;=TO_TIMESTAMP('20000101') AND \n              &quot;COL1&quot;&lt;=TO_TIMESTAMP('29991212')))\n</code></pre>\n<p>As I said in the comments, I don't think it's conversion problem. If it's a conversion problem, I think the FILTER operation should occur in the above query as well.</p>\n",
        "tags": [
            "sql",
            "oracle-database"
        ]
    },
    {
        "index": 59,
        "question_id": 79620987,
        "title": "How to remove the padding of the accordion items on the latest version of flowbite svelte?",
        "body": "<p>I am currently using flowbite version 1.2.0 on my svelte app.</p>\n<p>The issue I have is that I am unable to remove the padding from the AccordionItems contents since I want to control this myself. Looks like by default is at 5 (p-5).</p>\n<p>I have tried applying custom class on the global app.css</p>\n<pre class=\"lang-css prettyprint-override\"><code>@layer components {\n  .no-pad-accordion [data-accordion-content] {\n    @apply p-0 !important;\n  }\n}\n</code></pre>\n<p>To wrap the component but this doesn't work</p>\n<p>And also with:</p>\n<pre class=\"lang-html prettyprint-override\"><code>&lt;Accordion class=&quot;my-accordion&quot;&gt;\n  &lt;AccordionItem&gt;\n    {#snippet header()}My Header{/snippet}\n    &lt;p&gt;My content here…&lt;/p&gt;\n  &lt;/AccordionItem&gt;\n  &lt;!-- more items… --&gt;\n&lt;/Accordion&gt;\n&lt;style&gt;\n  /* Remove body padding */\n  :global(.my-accordion [data-accordion-content]) {\n    @apply !p-0;\n  }\n&lt;/style&gt;\n</code></pre>\n",
        "tags": [
            "javascript",
            "css",
            "svelte",
            "flowbite-svelte"
        ]
    },
    {
        "index": 60,
        "question_id": 79621020,
        "title": "GraphiQL over Springboot shows React errors and blank page",
        "body": "<p>I work on a Kotlin Spring API. It is running inside a Docker container from <code>eclipse-temurin:17-jdktrough</code> image on WSL 2 Ubuntu 22.04 LTS (Host is Windows 11 Entreprise 24H2).</p>\n<p>Project dependencies version :</p>\n<ul>\n<li>Java 17</li>\n<li>Kotlin 1.9.23</li>\n<li>Spring Boot 3.0.4</li>\n<li>POM model version 4.0.0</li>\n</ul>\n<p>The API works except for the <code>/graphiql</code> route. When I try accessing it, I get a blank page with the following console error and warnings :</p>\n<pre><code>Uncaught TypeError: e.useSyncExternalStore is not a function\n    Lu https://unpkg.com/graphiql/graphiql.min.js:31\n    Fu https://unpkg.com/graphiql/graphiql.min.js:31\n    Ru https://unpkg.com/graphiql/graphiql.min.js:31\n    React 16\n    &lt;anonymous&gt; http://localhost:13311/graphiql?path=/graphql:39\ngraphiql.min.js:31:1963\n\nThe above error occurred in the &lt;Ru&gt; component:\n    in Ru (created by nm)\n    in nm\n    in Unknown\nreact-dom.development.js:19662:15\n\nUncaught undefined\nreact-dom.development.js:22800:7\n\nGET\nhttp://localhost:13311/favicon.ico\n[HTTP/1.1 403  31ms]\n\nSource map error: NetworkError when attempting to fetch resource.\nResource URL: https://unpkg.com/graphiql/graphiql.min.js\nSource Map URL: index.umd.js.map\n</code></pre>\n<p>On the network monitor side, everything succeed with a 200 status code except the favicon fetch that fail with a 403 status code.</p>\n<p><code>graphiql.min.js</code> version seems to be automatically chosen as loading <a href=\"https://unpkg.com/graphiql/graphiql.min.js\" rel=\"nofollow noreferrer\">https://unpkg.com/graphiql/graphiql.min.js</a> automatically adds a version to the URL. The error varies based on the graphiql version.</p>\n<ul>\n<li>When the version was @4.0.4 : <code>Uncaught TypeError: e.useInsertionEffect is not a function</code></li>\n<li>When the version is @4.0.5 : <code>Uncaught TypeError: e.useSyncExternalStore is not a function</code></li>\n</ul>\n<p><code>application.properties</code> content :</p>\n<pre class=\"lang-none prettyprint-override\"><code>spring.graphql.graphiql.enabled=true\nspring.graphql.graphiql.path=/graphiql\n#allow all origins\nspring.graphql.cors.allowed-origins=*\nspring.graphql.cors.allowed-methods=*\nspring.graphql.cors.allowed-headers=*\nspring.datasource.url=jdbc:mariadb://${DB_HOST:1.1.1.1}:${DB_PORT:3333}/${DB_BASE:db}\nspring.datasource.username=${DB_USER:user}\nspring.datasource.password=${DB_PASS:password}\nspring.main.allow-bean-definition-overriding=true\n# Hibernate JPA DB initialization :: https://docs.spring.io/spring-boot/docs/1.1.0.M1/reference/html/howto-database-initialization.html\nspring.jpa.generate-ddl=true\nspring.jpa.hibernate.ddl-auto=update\n# https://www.baeldung.com/spring-data-jpa-generate-db-schema\nspring.jpa.properties.jakarta.persistence.schema-generation.scripts.action=create\nspring.jpa.properties.jakarta.persistence.schema-generation.scripts.create-target=create.sql\nspring.jpa.properties.jakarta.persistence.schema-generation.scripts.create-source=metadata\n# dump.sql and triggers.sql execution on load :: https://www.baeldung.com/spring-boot-data-sql-and-schema-sql\n# ? Triggers auto-insertion doesn't work at the moment, see API ticket #79\n#spring.sql.init.mode=always\n#spring.jpa.defer-datasource-initialization=true\n#spring.sql.init.schema-locations=classpath:triggers.sql\n#spring.sql.init.data-locations=classpath:dump.sql\n#\nspring.jpa.show-sql=true\nspring.jpa.properties.hibernate.format_sql=false\nmanagement.endpoints.web.exposure.include=*\nmanagement.endpoint.health.show-details=always\nmanagement.endpoint.health.show-components=always\nmanagement.prometheus.metrics.export.pushgateway.enabled=true\nmanagement.endpoints.web.cors.allowed-origins=*\nmanagement.endpoints.web.cors.allowed-methods=*\nmanagement.endpoints.web.cors.allowed-headers=*\nmanagement.endpoints.web.cors.max-age=3600\nmanagement.health.defaults.enabled=false\nmanagement.health.db.enabled=true\n# JWT Token\nsecurity.jwt.token.secret-key=${JWT_SECRET_KEY:secret-key}\nsecurity.jwt.algorithm=${JWT_ALGORITHM:HS256}\n#server.port=${SPRING_API_PORT:8080}\n</code></pre>\n<p><code>pom.xml</code> content :</p>\n<pre class=\"lang-xml prettyprint-override\"><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;project xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;\n         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;parent&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n        &lt;version&gt;3.0.4&lt;/version&gt;\n        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\n    &lt;/parent&gt;\n    &lt;groupId&gt;com.company&lt;/groupId&gt;\n    &lt;artifactId&gt;SpringAPI&lt;/artifactId&gt;\n    &lt;version&gt;1.0.0&lt;/version&gt;\n    &lt;name&gt;Spring-API&lt;/name&gt;\n    &lt;description&gt;Spring API&lt;/description&gt;\n    &lt;properties&gt;\n        &lt;java.version&gt;17&lt;/java.version&gt;\n        &lt;kotlin.version&gt;1.9.23&lt;/kotlin.version&gt;\n    &lt;/properties&gt;\n    &lt;dependencies&gt;\n        &lt;!-- https://mvnrepository.com/artifact/org.jetbrains.kotlinx/kotlinx-serialization-json-jvm --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.jetbrains.kotlinx&lt;/groupId&gt;\n            &lt;artifactId&gt;kotlinx-serialization-json-jvm&lt;/artifactId&gt;\n            &lt;version&gt;1.5.0&lt;/version&gt;\n            &lt;scope&gt;runtime&lt;/scope&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-data-jdbc&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-graphql&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.tailrocks.graphql&lt;/groupId&gt;\n            &lt;artifactId&gt;graphql-datetime-spring-boot-starter&lt;/artifactId&gt;\n            &lt;version&gt;6.0.0&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n            &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.fasterxml.jackson.module&lt;/groupId&gt;\n            &lt;artifactId&gt;jackson-module-kotlin&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.projectreactor.kotlin&lt;/groupId&gt;\n            &lt;artifactId&gt;reactor-kotlin-extensions&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;\n            &lt;artifactId&gt;kotlin-reflect&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;\n            &lt;artifactId&gt;kotlin-stdlib-jdk8&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.jetbrains.kotlinx&lt;/groupId&gt;\n            &lt;artifactId&gt;kotlinx-coroutines-reactor&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.graphql-java&lt;/groupId&gt;\n            &lt;artifactId&gt;graphql-java-extended-scalars&lt;/artifactId&gt;\n            &lt;version&gt;20.0&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;\n            &lt;scope&gt;runtime&lt;/scope&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.mariadb.jdbc&lt;/groupId&gt;\n            &lt;artifactId&gt;mariadb-java-client&lt;/artifactId&gt;\n            &lt;version&gt;3.1.2&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt;\n            &lt;artifactId&gt;junit-jupiter-engine&lt;/artifactId&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.ninja-squad&lt;/groupId&gt;\n            &lt;artifactId&gt;springmockk&lt;/artifactId&gt;\n            &lt;version&gt;4.0.2&lt;/version&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.projectreactor&lt;/groupId&gt;\n            &lt;artifactId&gt;reactor-test&lt;/artifactId&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.graphql&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-graphql-test&lt;/artifactId&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.h2database&lt;/groupId&gt;\n            &lt;artifactId&gt;h2&lt;/artifactId&gt;\n            &lt;scope&gt;runtime&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.micrometer&lt;/groupId&gt;\n            &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;\n            &lt;artifactId&gt;gson&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n        &lt;!-- SPRING SECURITY --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt;\n            &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt;\n            &lt;version&gt;2.2.12&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt;\n            &lt;artifactId&gt;jaxb-impl&lt;/artifactId&gt;\n            &lt;version&gt;2.2.11&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;!-- JWT Dependency --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;\n            &lt;artifactId&gt;jjwt&lt;/artifactId&gt;\n            &lt;version&gt;0.9.1&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;\n            &lt;artifactId&gt;kotlin-maven-serialization&lt;/artifactId&gt;\n            &lt;version&gt;1.9.23&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.hibernate.validator&lt;/groupId&gt;\n            &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;\n            &lt;version&gt;8.0.1.Final&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;!-- ///////////////////////////////////////////////// --&gt;\n\n        &lt;!--    Logging related dependency    --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;\n            &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;\n            &lt;version&gt;2.23.1&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;\n            &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;\n            &lt;version&gt;2.23.1&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;\n            &lt;artifactId&gt;log4j-slf4j2-impl&lt;/artifactId&gt;\n            &lt;version&gt;2.23.1&lt;/version&gt;\n        &lt;/dependency&gt;\n\n    &lt;/dependencies&gt;\n\n    &lt;build&gt;\n        &lt;sourceDirectory&gt;${project.basedir}/src/main/kotlin&lt;/sourceDirectory&gt;\n        &lt;testSourceDirectory&gt;${project.basedir}/src/test/kotlin&lt;/testSourceDirectory&gt;\n        &lt;plugins&gt;\n\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.graalvm.buildtools&lt;/groupId&gt;\n                &lt;artifactId&gt;native-maven-plugin&lt;/artifactId&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;excludes&gt;\n                        &lt;exclude&gt;\n                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n                        &lt;/exclude&gt;\n                    &lt;/excludes&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;\n                &lt;artifactId&gt;kotlin-maven-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;args&gt;\n                        &lt;arg&gt;-Xjsr305=strict&lt;/arg&gt;\n                    &lt;/args&gt;\n                    &lt;compilerPlugins&gt;\n                        &lt;plugin&gt;spring&lt;/plugin&gt;\n                        &lt;plugin&gt;jpa&lt;/plugin&gt;\n                    &lt;/compilerPlugins&gt;\n                &lt;/configuration&gt;\n                &lt;dependencies&gt;\n                    &lt;dependency&gt;\n                        &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;\n                        &lt;artifactId&gt;kotlin-maven-allopen&lt;/artifactId&gt;\n                        &lt;version&gt;${kotlin.version}&lt;/version&gt;\n                    &lt;/dependency&gt;\n                    &lt;dependency&gt;\n                        &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;\n                        &lt;artifactId&gt;kotlin-maven-noarg&lt;/artifactId&gt;\n                        &lt;version&gt;${kotlin.version}&lt;/version&gt;\n                    &lt;/dependency&gt;\n\n\n                &lt;/dependencies&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n&lt;/project&gt;\n</code></pre>\n<p>I've tried the following without success :</p>\n<ul>\n<li>Deleting Maven's cache</li>\n<li>Re-cloning all the repos of the stack and rebuilding everything</li>\n<li>Updating WSL</li>\n<li>Updating Springboot framework from 3.0.4 to 3.0.12</li>\n<li>Updating Windows from KB5055627 to KB5058411</li>\n<li>Rolling back to a known-to-work version of the API</li>\n<li>Building the known to work version of the API on another physical machine</li>\n</ul>\n<p>I've red graphiql's GitHub <a href=\"https://github.com/graphql/graphiql/blob/main/packages/graphiql/CHANGELOG.md\" rel=\"nofollow noreferrer\">changelog</a> and <a href=\"https://github.com/graphql/graphiql/blob/main/docs/migration/graphiql-4.0.0.md\" rel=\"nofollow noreferrer\">migration guide</a>.</p>\n<p>Also, an update in <a href=\"https://github.com/spring-projects/spring-graphql/issues/1209\" rel=\"nofollow noreferrer\">spring-graphql repo</a> seems to have been done 2 days ago, but as the office closed for the past two weeks, I can't tell if it's the origin of the issue.</p>\n<p>There's a common point between the migration guide and an warning I encountered, refering the <code>index.umd.js</code> deprecated source map. I think of a unwanted automatic update  as I have not updated nor added any dependency in <code>pom.xml</code> and I don't think I can control graphiql configuration from the Spring project, aside from its URL.</p>\n<p>Thank you</p>\n",
        "tags": [
            "spring",
            "spring-boot",
            "graphql",
            "graphiql",
            "spring-graphql"
        ]
    },
    {
        "index": 61,
        "question_id": 79621097,
        "title": "How to use different certificates for each thread (each thread. not thread group)",
        "body": "<p>How can I use different certificates for each thread (each thread, not thread group) in JMeter?</p>\n<p>For example, one cert for the first thread and a second cert for the second thread, and so on.</p>\n",
        "tags": [
            "java",
            "jmeter"
        ]
    },
    {
        "index": 62,
        "question_id": 79621196,
        "title": "Why does only one SIGINT get queued while others are ignored during signal handling in C?",
        "body": "<p>I'm testing Unix signal behavior in C and noticed something odd. When I press Ctrl+C (sending SIGINT) multiple times quickly while the handler is still running (it sleeps for 3 seconds), only two handler calls happen — the first one immediately, and a second one after the first finishes. I sent the signal four times, so why does only one extra signal get handled while the others are ignored? I thought standard signals don’t queue, so shouldn’t all additional ones be skipped? Can someone explain the rules for how Unix handles this kind of signal queuing?</p>\n<p><em>And yes i did use chatgpt to write the question, because English is not good enough.</em></p>\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;signal.h&gt;\n#include &lt;unistd.h&gt;\n\nint x = 0;\n\nvoid signal_handler(int signum) {\n    printf(&quot;start\\n&quot;);\n    sleep(3);\n    printf(&quot;end\\n&quot;);\n}\n\nint main() {\n    signal(SIGINT, signal_handler);\n    while (1);\n    return 0;\n}\n\nin terminal:\n^Cstart\n^C^C^C^C^C^C^Cend\nstart\nend\n\n</code></pre>\n",
        "tags": [
            "c",
            "signals"
        ]
    },
    {
        "index": 63,
        "question_id": 79621278,
        "title": "Next.js + Tailwind CSS: Conflict between breakpoints and custom CSS classes",
        "body": "<p>I defined breakpoints in <code>globals.css</code> like below.</p>\n<pre class=\"lang-css prettyprint-override\"><code>@theme inline {\n  --breakpoint-sm: 375px;\n  --breakpoint-md: 744px;\n  --breakpoint-lg: 1200px;\n  /* ... */\n}\n</code></pre>\n<p>Then in <code>index.css</code>, I created custom CSS classes like this.</p>\n<pre class=\"lang-css prettyprint-override\"><code>.text-700-28 {\n  font: 700 1.75rem &quot;noto&quot;, serif;\n}\n\n.text-700-24 {\n  font: 700 1.5rem &quot;noto&quot;, serif;\n}\n\n.text-400-24 {\n  font: 400 1.5rem &quot;noto&quot;, serif;\n}\n\n/* ... */\n</code></pre>\n<p>When I tried to use the custom classes combined with breakpoints in my components, the responsive styles didn't apply — only <code>text-400-12</code> was applied.</p>\n<pre class=\"lang-html prettyprint-override\"><code>&lt;div className=&quot;rounded-[2px] w-full border-1 flex flex-col border-gray-200 gap-[15px] py-[15px] text-400-12 md:text-400-14 lg:text-400-16&quot;&gt;\n  &lt;div className=&quot;px-[20px]&quot;&gt;Low to High Price&lt;/div&gt;\n  &lt;div className=&quot;px-[20px]&quot;&gt;High to Low Price&lt;/div&gt;\n  &lt;div className=&quot;px-[20px]&quot;&gt;CreatedAt&lt;/div&gt;\n&lt;/div&gt;\n</code></pre>\n<p>Why is this happening?</p>\n",
        "tags": [
            "next.js",
            "tailwind-css",
            "tailwind-css-4"
        ]
    },
    {
        "index": 64,
        "question_id": 79621383,
        "title": "How to wrap a Task in a Task&lt;TResult&gt; without using an async state machine?",
        "body": "<p>I want to wrap a <code>Task</code> in a <code>Task&lt;TResult&gt;</code> without using an async state machine, while preserving the original task's properties. Based on <a href=\"https://stackoverflow.com/questions/22541734/whats-the-best-way-to-wrap-a-task-as-a-tasktresult\">What's the best way to wrap a <code>Task</code> as a <code>Task&lt;TResult&gt;</code></a> and <a href=\"https://stackoverflow.com/questions/47322977/how-to-convert-a-task-into-a-taskt\">How to convert a <code>Task</code> into a <code>Task&lt;T&gt;</code></a>, the consensus seems to be that the best/least error-prone way to do the conversion is by awaiting the non-generic <code>Task</code> to complete, and then return a certain <code>T</code>. Something like this:</p>\n<pre><code>async Task&lt;T&gt; ConvertAsync&lt;T&gt;(Task task, T result)\n{\n    await task;\n    return result;\n}\n</code></pre>\n<p>Is there an alternative, non-async and error-free way of achieving the wrapping?</p>\n<ol>\n<li>The returned <code>Task&lt;T&gt;</code> should have the same <code>Task.Status</code> as the wrapped <code>Task</code>.</li>\n<li>The returned  <code>Task&lt;T&gt;</code> should have its <code>Exception</code> property be the same as the original <code>Task</code>.</li>\n<li>The wrapping/converting should be done as asynchronously as possible, i.e. no blocking during the conversion of the task.</li>\n</ol>\n",
        "tags": [
            "c#",
            "asynchronous",
            "async-await",
            "task",
            "task-parallel-library"
        ]
    },
    {
        "index": 65,
        "question_id": 79621423,
        "title": "Passing parameters using reflection and passing method name as parameter",
        "body": "<p>I have multiple lines which are mocking the method:</p>\n<pre><code>_mockClass.Setup(d =&gt; d.TestAsync(It.IsAny&lt;string&gt;(), It.IsAny&lt;long&gt;()))\n    .ReturnsAsync(1);\n</code></pre>\n<p>I want to make shorthand for the above <code>Setup</code> call:</p>\n<pre><code>Setup(_mockClass.TestAsync, 1)\n</code></pre>\n<p>I wonder how do I write body of the Setup method:<br/>\nWhat I tried</p>\n<pre><code>//psuedo code\npublic void Setup(delegate del, object returnVal)\n{\n    _mockClass.Setup(d =&gt; d.del(It.IsAny&lt;string&gt;(), It.IsAny&lt;long&gt;()))//all It.IsAny pass using reflection?\n    .ReturnsAsync(returnVal);\n}\n</code></pre>\n<p>What I want to do this:\n<code>TestAsync</code> method have so many parameters (10+), and I want to avoid typing <code>It.IsAny&lt;&gt;</code> multiple times.</p>\n<p>Something like<br/>\n<code>mock.Setup(d =&gt; d.TestAsync).ReturnsAsync(1)</code></p>\n",
        "tags": [
            "moq",
            "xunit",
            "xunit.net"
        ]
    },
    {
        "index": 66,
        "question_id": 79621433,
        "title": "How do I get the backtracking technique to solve large mazes too?",
        "body": "<p>I'm developing a backtracking function to solve a maze given by a matrix of 0 and 1. The problem is that, for small matrices, it correctly finds the shortest path, but for matrices 15x15 or larger, it freezes and does nothing. I've tried pruning in various ways, but nothing has solved the larger mazes. I want to do it using the backtracking technique, although I know other techniques are more efficient. There are 8 possible directions.</p>\n<p>When it works (for smaller mazes, not the one in the example) the statistics for the number of nodes visited, promising, and so on, are very high numbers. I don't think it's calculating the execution time correctly either.</p>\n<p>When I debug, it seems to freeze inside that for loop, before the recursive call in the maze_solve function, but I don't know why</p>\n<pre><code> for (map&lt;Step, tuple&lt;int, int&gt;&gt;::const_iterator it = steps_inc.begin(); it != steps_inc.end(); ++it) {\n            int nx = x + get&lt;0&gt;(it-&gt;second);     &lt;=\n            int ny = y + get&lt;1&gt;(it-&gt;second);\n            maze_solve(data, nx, ny, visitado, caminoActual, mejorCamino, stats, profundidadActual + 1);\n        }\n</code></pre>\n<p>I have also been trying the iterative solution, without recursive call, is this how I should do it? An example of an input that doesn't work would be:</p>\n<pre><code>15 15\n1 0 0 1 1 1 1 0 0 0 0 0 1 1 0\n1 0 0 1 0 1 0 0 1 1 1 0 0 0 1\n0 1 0 1 0 1 0 0 1 1 0 1 0 0 0\n1 0 0 1 0 1 0 0 0 1 0 1 0 0 1\n1 0 0 1 0 1 0 0 1 1 0 1 0 0 0\n1 1 1 1 0 1 0 0 1 1 0 1 0 0 1\n1 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n1 0 1 1 1 1 0 0 1 1 0 1 0 0 1\n0 0 1 1 0 0 0 0 1 1 0 1 0 0 1\n1 1 1 0 0 1 1 1 1 0 0 1 0 0 0\n1 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n1 0 0 0 0 1 0 0 1 1 1 1 1 1 1\n1 1 1 1 1 0 0 0 1 1 0 0 0 0 0\n1 0 0 1 1 0 0 1 0 1 0 1 1 1 1\n0 1 1 0 0 0 1 0 1 1 1 1 1 1 1\n</code></pre>\n<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;chrono&gt;\n#include &lt;limits&gt;\n#include &lt;tuple&gt;\n#include &lt;map&gt;\n\nusing namespace std;\n\nenum Step { N, NE, E, SE, S, SW, W, NW };\n\nconst map&lt;Step, tuple&lt;int, int&gt;&gt; steps_inc = {\n    {N,  {-1, 0}}, {NE, {-1, 1}}, {E,  {0, 1}}, {SE, {1, 1}},\n    {S,  {1, 0}},  {SW, {1, -1}}, {W,  {0, -1}}, {NW, {-1, -1}}\n};\n\nconst map&lt;Step, int&gt; stepCode = {\n    {N, 1}, {NE, 2}, {E, 3}, {SE, 4},\n    {S, 5}, {SW, 6}, {W, 7}, {NW, 8}\n};\n\nstruct Data {\n    vector&lt;vector&lt;char&gt;&gt; lab;\n    int filas, columnas;\n};\n\n//Statistics\nstruct Estadisticas {\n    int visitados = 0;\n    int explorados = 0;\n    int hojas = 0;\n    int noFactibles = 0;\n    int noPrometedores = 0;\n};\n\n//If a node is feasible\nbool esFactible(int x, int y, const Data &amp;data, const vector&lt;vector&lt;bool&gt;&gt; &amp;visitado) {\n    return x &gt;= 0 &amp;&amp; x &lt; data.filas &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; data.columnas &amp;&amp;\n           data.lab[x][y] == '1' &amp;&amp; !visitado[x][y];\n}\n\n//Solve maze using the backtracking technique\nvoid maze_solve(const Data &amp;data, int x, int y, vector&lt;vector&lt;bool&gt;&gt; &amp;visitado,\n             vector&lt;pair&lt;int,int&gt;&gt; &amp;caminoActual, vector&lt;pair&lt;int,int&gt;&gt; &amp;mejorCamino,\n             Estadisticas &amp;stats, int profundidadActual) {\n    \n    stats.visitados++;\n\n    if (!esFactible(x, y, data, visitado)) {\n        stats.noFactibles++;\n        return;\n    }\n\n    visitado[x][y] = true;\n    caminoActual.emplace_back(x, y);\n    stats.explorados++;\n\n    if (x == data.filas - 1 &amp;&amp; y == data.columnas - 1) {\n        stats.hojas++;\n        if (mejorCamino.empty() || caminoActual.size() &lt; mejorCamino.size())\n            mejorCamino = caminoActual;\n    } \n    else if (!mejorCamino.empty() &amp;&amp; caminoActual.size() &gt;= mejorCamino.size()) {\n        stats.noPrometedores++;\n    } \n    else {\n        for (map&lt;Step, tuple&lt;int, int&gt;&gt;::const_iterator it = steps_inc.begin(); it != steps_inc.end(); ++it) {\n            int nx = x + get&lt;0&gt;(it-&gt;second);\n            int ny = y + get&lt;1&gt;(it-&gt;second);\n            maze_solve(data, nx, ny, visitado, caminoActual, mejorCamino, stats, profundidadActual + 1);\n        }\n    }\n\n    caminoActual.pop_back();\n    visitado[x][y] = false;\n}\n\nint main(int argc, char *argv[]){\n    Data d;\n    d.filas=15;\n    d.columnas=15;\n    d.lab= { {'1', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '0'},\n                    {'1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '0', '1'},\n                    {'0', '1', '0', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '0'},\n                    {'1', '0', '0', '1', '0', '1', '0', '0', '0', '1', '0', '1', '0', '0', '1'},\n                    {'1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '0'},\n                    {'1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1'},\n                    {'1', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '1', '0', '0', '0'},\n                    {'1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1'},\n                    {'0', '0', '1', '1', '0', '0', '0', '0', '1', '1', '0', '1', '0', '0', '1'},\n                    {'1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '0', '0', '0'},\n                    {'1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0'},\n                    {'1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1'},\n                    {'1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0'},\n                    {'1', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '1', '1'},\n                    {'0', '1', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1'} };\n    for(int i=0;i&lt;d.filas;i++){\n        for(int j=0;j&lt;d.columnas;j++){\n            cout&lt;&lt;d.lab[i][j]&lt;&lt;&quot; &quot;;\n        }\n        cout&lt;&lt;endl;\n    }\n                  \n    auto start = chrono::high_resolution_clock::now();\n\n    vector&lt;vector&lt;bool&gt;&gt; visitado(d.filas, vector&lt;bool&gt;(d.columnas, false));\n    vector&lt;pair&lt;int,int&gt;&gt; caminoActual, mejorCamino;\n    Estadisticas stats;\n\n    maze_solve(d, 0, 0, visitado, caminoActual, mejorCamino, stats, 0);\n\n    auto end = chrono::high_resolution_clock::now();\n    auto duracion = chrono::duration_cast&lt;chrono::milliseconds&gt;(end - start).count();\n\n    //Print statistics\n    cout &lt;&lt; (mejorCamino.empty() ? 0 : mejorCamino.size()) &lt;&lt; endl;\n    cout &lt;&lt; stats.visitados &lt;&lt; &quot; &quot; &lt;&lt; stats.explorados &lt;&lt; &quot; &quot;\n         &lt;&lt; stats.hojas &lt;&lt; &quot; &quot; &lt;&lt; stats.noFactibles &lt;&lt; &quot; &quot;\n         &lt;&lt; stats.noPrometedores &lt;&lt; endl;\n    cout &lt;&lt; duracion &lt;&lt; endl;\n\n    if (!mejorCamino.empty()) {\n            //Print path 2d\n            vector&lt;vector&lt;char&gt;&gt; copia = d.lab;\n            for (size_t i = 0; i &lt; mejorCamino.size(); ++i) {\n                int x = mejorCamino[i].first;\n                int y = mejorCamino[i].second;\n                if (copia[x][y] == '1')\n                    copia[x][y] = '*';\n            }\n            for (auto &amp;fila : copia) {\n                for (char c : fila) cout &lt;&lt; c;\n                cout &lt;&lt; endl;\n            }\n        \n            //Print path &lt;&gt;\n            string path = &quot;&lt;&quot;;\n            for (size_t i = 1; i &lt; mejorCamino.size(); i++) {\n                int dx = mejorCamino[i].first - mejorCamino[i-1].first;\n                int dy = mejorCamino[i].second - mejorCamino[i-1].second;\n                for (map&lt;Step, tuple&lt;int, int&gt;&gt;::const_iterator it = steps_inc.begin(); it != steps_inc.end(); ++it) {\n                    if (dx == get&lt;0&gt;(it-&gt;second) &amp;&amp; dy == get&lt;1&gt;(it-&gt;second)) {\n                        path += to_string(stepCode.at(it-&gt;first));\n                        break;\n                    }\n                }\n            }\n            path += &quot;&gt;&quot;;\n            cout &lt;&lt; path &lt;&lt; endl;\n        \n    } else {\n        cout &lt;&lt; &quot;&lt;0&gt;&quot; &lt;&lt; endl;\n    }\n\n    return 0;\n}\n</code></pre>\n<p>I've tried it many more times, changing many things, and I can't get it to work with that matrix or other large ones:</p>\n<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;tuple&gt;\n#include &lt;utility&gt;\n\nusing namespace std;\n\nenum Step {SE,E,S,NE,SO,N,O,NO};\n\n//Vector of pairs with possible moves in the maze\nconst vector&lt;pair &lt;int, int&gt;&gt; incStep = {{1,1},{0,1},{1,0},{-1,1},{1,-1},{-1,0},{0,-1},{-1,-1}};\n\n//Direction encoding for printing the shortest path\nconst vector&lt;pair &lt;Step, int&gt;&gt; codeStep = {\n{N, 1}, {NE, 2}, {E, 3}, {SE, 4},\n{S, 5}, {SW, 6}, {W, 7}, {NW, 8}\n};\n\nstruct Info{\nvector&lt;vector&lt;char&gt;&gt; maze;\nint rows, columns;\n} info;\n\n//Function that returns whether a position in the maze is feasible\nbool isFeasible(int x, int y, const vector&lt;vector&lt;bool&gt;&gt; &amp;visited) {\nreturn (x &gt;= 0 &amp;&amp; x &lt; info.rows &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; info.columns &amp;&amp; info.maze[x][y] == '1' &amp;&amp; !visited[x][y]);\n}\n\n//Procedure for finding the shortest path using backtracking\nvoid maze_bt(int x, int y, vector&lt;vector&lt;bool&gt;&gt; &amp;visited,\nvector&lt;pair&lt;int,int&gt;&gt; &amp;currentPath, vector&lt;pair&lt;int,int&gt;&gt; &amp;bestPath,\nint currentDepth) {\n\n// If the position is not feasible, exit\nif (!isFeasible(x, y, visited)) {\nreturn;\n}\n\n// Mark visited and add to the current path\nvisited[x][y] = true;\ncurrentPath.emplace_back(x, y);\n\n// If we have reached the destination\nif (x == info.rows - 1 &amp;&amp; y == info.columns - 1) {\n// If there is no previous path or the current one is shorter, update the best path\nif (bestPath.empty() || currentPath.size() &lt; bestPath.size()) {\nbestPath = currentPath;\n}\n} else {\n// Pruning: if a best path already exists and the current one is equal to or longer, do not continue\nif (bestPath.empty() || currentPath.size() &lt; bestPath.size()) {\n// Explore all possible moves\nfor (const auto&amp; mov : incStep) {\nint nx = x + mov.first;\nint ny = y + mov.second;\nmaze_bt(nx, ny, visited, currentPath, bestPath, currentDepth + 1);\n}\n}\n}\n\n//Backtracking: remove from the current path and unmark visited\ncurrentPath.pop_back();\nvisited[x][y] = false;\n}\n\n//Main function\nint main(int argc, char *argv[]){\n\n//Checking addresses and access to elements in possible\n//movements. Print the movement corresponding to North\n//cout &lt;&lt;&quot;The movement corresponding to going North is: &quot;&lt;&lt;incStep[5].first&lt;&lt;&quot; &quot;&lt;&lt;incStep[5].second&lt;&lt;endl;\n\n//We enter the maze data (or read it from a file)\ninfo.rows=15;\ninfo.columns=15;\ninfo.maze={ {'1', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '0'},\n{'1', '0', '1', '0', '1', '0', '1', '0', '1', '1', '1', '0', '0', '0', '1'},\n{'0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '0', '0'},\n{'1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '1', '0', '0'},\n{'1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '1', '0', '1', '0', '0', '1'},\n{'1', '0', '1', '0', '1', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0'},\n{'1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '1', '0', '1'},\n{'1', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '0'},\n{'1', '0', '1', '1', '1', '1', '0', '0', '0', '1', '0', '0', '0', '0'},\n{'1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1'},\n{'0', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1'},\n{'1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '1', '0', '0', '0'},\n{'1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0'},\n{'1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0'},\n{'1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1'},\n{'1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0'},\n{'1', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '1', '1'},\n{'0', '1', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1'} };\n\nvector&lt;vector&lt;bool&gt;&gt; visited(info.rows, vector&lt;bool&gt;(info.columns, false));\nvector&lt;pair&lt;int,int&gt;&gt; currentPath, bestPath;\n\n//We use a function to calculate the shortest path using backtracking\nmaze_bt(0, 0, visited, currentPath, bestPath, 0);\n\n// Display the path sequence\ncout &lt;&lt; &quot;Shortest path found:&quot; &lt;&lt; endl;\nfor (const auto&amp; step : bestPath) {\ncout &lt;&lt; &quot;(&quot; &lt;&lt; step.first &lt;&lt; &quot;,&quot; &lt;&lt; step.second &lt;&lt; &quot;) &quot;;\n}\ncout &lt;&lt; endl;\n\n// Mark the path in the maze with '*'\nvector&lt;vector&lt;char&gt;&gt; mazeWithPath = info.maze;\nfor (const auto&amp; step : bestPath) {\nmazeWithPath[step.first][step.second] = '*';\n}\n\n// Display the maze with the path\ncout &lt;&lt; &quot;Maze with the shortest path marked with '*':&quot; &lt;&lt; endl;\nfor (int i = 0; i &lt; info.rows; ++i) {\nfor (int j = 0; j &lt; info.columns; ++j) {\ncout &lt;&lt; mazeWithPath[i][j] &lt;&lt; &quot; &quot;;\n}\ncout &lt;&lt; endl;\n}\n\nreturn 0;\n}\n\n</code></pre>\n<p>What should I change? What am I doing wrong?</p>\n",
        "tags": [
            "c++",
            "matrix",
            "backtracking",
            "maze"
        ]
    },
    {
        "index": 67,
        "question_id": 79621451,
        "title": "Issue with fentry BPF program attaching to open system call",
        "body": "<p>I'm attempting to write a tracing eBPF program using the fentry attach type to hook into the open system call. Here's a minimal example:</p>\n<pre class=\"lang-c prettyprint-override\"><code>SEC(&quot;fentry/__x64_sys_open&quot;)\nint BPF_PROG(trace_sys_open, const char *filename, int flags, umode_t mode)\n{\n    if (flags &amp; O_CREAT) {\n        bpf_printk(&quot;fentry: open() with O_CREAT\\n&quot;);\n    }\n    return 0;\n}\n</code></pre>\n<p>However, when I attempt to load the BPF program, I get the following error:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>$ sudo ./file_tracing\nlibbpf: prog 'trace_sys_open': BPF program load failed: Permission denied\nlibbpf: prog 'trace_sys_open': -- BEGIN PROG LOAD LOG --\nreg type unsupported for arg#0 function trace_sys_open#15\n0: R1=ctx(off=0,imm=0) R10=fp0\n; int BPF_PROG(trace_sys_open, const char *filename, int flags, umode_t mode)\n0: (79) r1 = *(u64 *)(r1 +8)\nfunc '__x64_sys_open' doesn't have 2-th argument\ninvalid bpf_context access off=8 size=8\nprocessed 1 insns (limit 1000000) max_states_per_insn 0 total_states 0 peak_states 0 mark_read 0\n-- END PROG LOAD LOG --\nlibbpf: prog 'trace_sys_open': failed to load: -13\nlibbpf: failed to load object 'file_tracing_bpf'\nfailed to load BPF object: -13\n</code></pre>\n<p>It seems that the BPF loader expects a different function signature. According to the kernel source (fs/open.c), the open syscall is defined as:</p>\n<pre class=\"lang-c prettyprint-override\"><code>SYSCALL_DEFINE3(open, const char __user *, filename, int, flags, umode_t, mode)\n{\n    if (force_o_largefile())\n        flags |= O_LARGEFILE;\n    return do_sys_open(AT_FDCWD, filename, flags, mode);\n}\n</code></pre>\n<p>So I tried updating the prototype to explicitly include __user, like so:</p>\n<pre class=\"lang-c prettyprint-override\"><code>SEC(&quot;fentry/__x64_sys_open&quot;)\nint BPF_PROG(trace_sys_open, const char __user *filename, int flags, umode_t mode)\n{\n    if (flags &amp; O_CREAT) {\n        bpf_printk(&quot;fentry: open() with O_CREAT\\n&quot;);\n    }\n    return 0;\n}\n</code></pre>\n<p>But this fails to compile:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>$ clang -O2 -g -target bpf -I../helpers -I.output -D__TARGET_ARCH_x86 -c file_tracing.bpf.c -o .output/file_tracing.bpf.o\nfile_tracing.bpf.c:24:48: error: expected ')'\nint BPF_PROG(trace_sys_open, const char __user *filename, int flags, umode_t mode)\n                                               ^\nfile_tracing.bpf.c:24:5: note: to match this '('\nint BPF_PROG(trace_sys_open, const char __user *filename, int flags, umode_t mode)\n    ^\n/usr/include/bpf/bpf_tracing.h:430:11: note: expanded from macro 'BPF_PROG'\n____##name(unsigned long long *ctx, ##args);                                \\\n          ^\nfile_tracing.bpf.c:24:5: error: too many arguments to function call, expected 2, have 4\nint BPF_PROG(trace_sys_open, const char __user *filename, int flags, umode_t mode)\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/include/bpf/bpf_tracing.h:435:20: note: expanded from macro 'BPF_PROG'\n        return ____##name(___bpf_ctx_cast(args));                           \\\n               ~~~~~~~~~~ ^~~~~~~~~~~~~~~~~~~~~\n/usr/include/bpf/bpf_tracing.h:410:39: note: expanded from macro '___bpf_ctx_cast'\n#define ___bpf_ctx_cast(args...)      ___bpf_apply(___bpf_ctx_cast, ___bpf_narg(args))(args)\n                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/include/bpf/bpf_helpers.h:184:29: note: expanded from macro '___bpf_apply'\n#define ___bpf_apply(fn, n) ___bpf_concat(fn, n)\n                            ^\nnote: (skipping 1 expansions in backtrace; use -fmacro-backtrace-limit=0 to see all)\n&lt;scratch space&gt;:26:1: note: expanded from here\n___bpf_ctx_cast3\n^\n/usr/include/bpf/bpf_tracing.h:400:39: note: expanded from macro '___bpf_ctx_cast3'\n#define ___bpf_ctx_cast3(x, args...)  ___bpf_ctx_cast2(args), (void *)ctx[2]\n                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/include/bpf/bpf_tracing.h:399:63: note: expanded from macro '___bpf_ctx_cast2'\n#define ___bpf_ctx_cast2(x, args...)  ___bpf_ctx_cast1(args), (void *)ctx[1]\n                                                              ^\nfile_tracing.bpf.c:24:5: note: '____trace_sys_open' declared here\n/usr/include/bpf/bpf_tracing.h:429:48: note: expanded from macro 'BPF_PROG'\nstatic __always_inline typeof(name(0))                                      \\\n                                                                            ^\n&lt;scratch space&gt;:20:1: note: expanded from here\n____trace_sys_open\n^\nfile_tracing.bpf.c:24:48: error: expected ')'\nint BPF_PROG(trace_sys_open, const char __user *filename, int flags, umode_t mode)\n                                               ^\nfile_tracing.bpf.c:24:5: note: to match this '('\nint BPF_PROG(trace_sys_open, const char __user *filename, int flags, umode_t mode)\n    ^\n/usr/include/bpf/bpf_tracing.h:439:11: note: expanded from macro 'BPF_PROG'\n____##name(unsigned long long *ctx, ##args)\n          ^\nfile_tracing.bpf.c:26:9: error: use of undeclared identifier 'flags'\n    if (flags &amp; O_CREAT) {\n        ^\n4 errors generated.\nmake: *** [Makefile:28: .output/file_tracing.bpf.o] Error 1\n</code></pre>\n<p>As an alternative, I tried attaching to do_sys_openat2() and using the raw struct pt_regs *ctx approach:</p>\n<pre class=\"lang-c prettyprint-override\"><code>SEC(&quot;fentry/__x64_sys_open&quot;)\nint trace_sys_open(struct pt_regs *ctx)\n{\n    int flags = (int) PT_REGS_PARM2(ctx);\n    if (flags &amp; O_CREAT) {\n        return 0;\n    }\n    return 0;\n}\n</code></pre>\n<p>This version compiles and loads without issue.</p>\n<p>However, when I try to delegate to a helper function:</p>\n<pre class=\"lang-c prettyprint-override\"><code>SEC(&quot;fentry/__x64_sys_open&quot;)\nint trace_sys_open(struct pt_regs *ctx)\n{\n    int flags = (int) PT_REGS_PARM2(ctx);\n    if (flags &amp; O_CREAT) {\n        return handle_event_tracing(ctx);\n    }\n    return 0;\n}\n</code></pre>\n<p>It fails again at load time:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>$ sudo ./file_tracing\nlibbpf: prog 'trace_sys_open': BPF program load failed: Permission denied\nlibbpf: prog 'trace_sys_open': -- BEGIN PROG LOAD LOG --\nreg type unsupported for arg#0 function trace_sys_open#13\n0: R1=ctx(off=0,imm=0) R10=fp0\n; int trace_sys_open(struct pt_regs *ctx)\n0: (bf) r6 = r1                       ; R1=ctx(off=0,imm=0) R6_w=ctx(off=0,imm=0)\n; int flags = (int) PT_REGS_PARM2(ctx);\n1: (79) r1 = *(u64 *)(r6 +104)\ninvalid bpf_context access off=104 size=8\nprocessed 2 insns (limit 1000000) max_states_per_insn 0 total_states 0 peak_states 0 mark_read 0\n-- END PROG LOAD LOG --\nlibbpf: prog 'trace_sys_open': failed to load: -13\nlibbpf: failed to load object 'file_tracing_bpf'\nfailed to load BPF object: -13\n</code></pre>\n<p>It seems like passing struct pt_regs * to this helper function breaks the verifier due to an incompatible or unsafe context pointer.</p>\n<p>Heres a reproducable example:</p>\n<pre class=\"lang-c prettyprint-override\"><code>// test.bpf.c\n\n#include &lt;vmlinux.h&gt;\n#include &lt;bpf/bpf_tracing.h&gt;\n#include &lt;bpf/bpf_core_read.h&gt;\n\n#define TASK_COMM_LEN 16\n#define O_CREAT 0100\n\nstruct event {\n    __u64 ts;\n    pid_t pid;\n    __u32 tid;\n    uid_t uid;\n    char comm[TASK_COMM_LEN];\n    __u64 cgroup_id;\n};\n\nstruct {\n    __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY);\n    __uint(key_size, sizeof(u32));\n    __uint(value_size, sizeof(u32));\n} events SEC(&quot;.maps&quot;);\n\nstatic __always_inline\nint handle_event_tracing(void *ctx)\n{\n    struct event event = {};\n    event.cgroup_id = bpf_get_current_cgroup_id();\n    u64 pid_tgid = bpf_get_current_pid_tgid();\n    event.pid = pid_tgid &gt;&gt; 32;\n    event.tid = pid_tgid &amp; 0xFFFFFFFF;\n    event.uid = bpf_get_current_uid_gid() &gt;&gt; 32;\n    bpf_get_current_comm(&amp;event.comm, sizeof(event.comm));\n    bpf_perf_event_output(ctx, &amp;events, BPF_F_CURRENT_CPU,\n                  &amp;event, sizeof(event));\n    return 0;\n}\n\nSEC(&quot;fentry/__x64_sys_open&quot;)\nint trace_sys_open(struct pt_regs *ctx)\n{\n    int flags = (int) PT_REGS_PARM2(ctx);\n    if (flags &amp; O_CREAT) {\n        return handle_event_tracing(ctx);\n    }\n    return 0;\n}\n\nchar LICENSE[] SEC(&quot;license&quot;) = &quot;GPL&quot;;\n\n</code></pre>\n<pre class=\"lang-c prettyprint-override\"><code>$ bpftool btf dump file /sys/kernel/btf/vmlinux format c &gt; vmlinux.h\n$ clang -O2 -g -I. -target bpf -D__TARGET_ARCH_x86 -c test.bpf.c -o test.bpf.o\n$ bpftool gen skeleton test.bpf.o &gt; test.skel.h\n$ sudo bpftool prog load ./test.bpf.o /sys/fs/bpf/test_prog\n</code></pre>\n",
        "tags": [
            "ebpf"
        ]
    },
    {
        "index": 68,
        "question_id": 79621497,
        "title": "Perl best practices: modifying array elements with map",
        "body": "<p>I am using perlcritic to check code, trying to avoid errors.</p>\n<p>I'm also trying to minimize new code loops like foreach, minimizing indentations, etc.  I've found that an occasional <code>map</code> can help to make code more readable.</p>\n<pre><code>#!/usr/bin/env perl\n\nuse 5.040.2;\nuse warnings FATAL =&gt; 'all';\nuse autodie ':default';\nuse DDP {output =&gt; 'STDOUT', array_max =&gt; 10, show_memsize =&gt; 1};\n\nmy @arr = (1..9);\n@arr = map {$_ /= 4} @arr;\np @arr;\n</code></pre>\n<p>this code works perfectly, as shown with <a href=\"https://metacpan.org/pod/DDP\" rel=\"nofollow noreferrer\"><code>DDP</code></a>.</p>\n<p><em>However</em>, I got the following warning from perlcritic in bold:</p>\n<blockquote>\n<p>Don't modify $_ in list functions at line 9, column 8.  See page 114 of PBP.  (Severity: 5)</p>\n</blockquote>\n<p>I've read through perl best practices, and the examples that the author gave that show why <code>map</code> is a bad choice to modify arrays like that are much more complex than what I do.</p>\n<p>Should I be using map, and disregard the warning from perlcritic?</p>\n",
        "tags": [
            "perl",
            "perl-critic"
        ]
    },
    {
        "index": 69,
        "question_id": 79621559,
        "title": "How to get the centerline of a character using Javascript?",
        "body": "<p>I want to extract the centerline of a character, through client-side JavaScript, from .ttf (TrueType Fonts). TrueType fonts store characters as 2 paths, an inner and outer paths. However, I need the centerline of the character (refer image, I am trying to achieve something similar to this.)</p>\n<p><a href=\"https://i.sstatic.net/mLOILcLD.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/mLOILcLD.png\" alt=\"Reference Image\" /></a></p>\n<p>How would I go about implementing this?</p>\n<p>I am already able to extract the outer and inner path from fonts using opentype.js</p>\n",
        "tags": [
            "javascript",
            "svg",
            "vector-graphics",
            "truetype"
        ]
    },
    {
        "index": 70,
        "question_id": 79621633,
        "title": "How to workaround QLineEdit bug under Android",
        "body": "<p>I'm migrating my code from Qt 6.2.2 to Qt 6.9.0.</p>\n<p>I see a regression: <code>QLineEdit</code> content is not visible untill you close the virtual keyboard. This is not user friendly and I really need to workaround this issue, reported since Qt 6.7.2 and not resolved yet.</p>\n<p>See <a href=\"https://bugreports.qt.io/browse/QTBUG-128794\" rel=\"nofollow noreferrer\">https://bugreports.qt.io/browse/QTBUG-128794</a>.</p>\n<pre><code>#include &lt;QApplication&gt;\n#include &lt;QMainWindow&gt;\n#include &lt;QVBoxLayout&gt;\n#include &lt;QLineEdit&gt;\nint main( int argc, char* argv[] )\n{\n    // https://bugreports.qt.io/browse/QTBUG-128794\n    QApplication app( argc, argv );    \n    QMainWindow wnd;\n    QWidget widget( &amp;wnd );\n    wnd.setCentralWidget( &amp;widget );\n    widget.setLayout( new QVBoxLayout(&amp;widget) );\n    widget.layout()-&gt;addWidget( new QLineEdit() );\n    widget.layout()-&gt;addWidget( new QLineEdit() );\n    wnd.show();\n    return app.exec();\n}\n</code></pre>\n<p>Does not behave right: <a href=\"https://bugreports.qt.io/secure/attachment/175388/175388_QLineEdit+Android.mp4\" rel=\"nofollow noreferrer\">https://bugreports.qt.io/secure/attachment/175388/175388_QLineEdit+Android.mp4</a></p>\n<p>I was trying to workaround this by catching an event in <code>QApplication::notify</code> and trying to update the <code>QLineEdit</code>:</p>\n<pre><code>class MyApplication : public QApplication\n{\npublic:\n    using QApplication::QApplication;\n\n    bool notify(QObject * receiver, QEvent * event)\n    {\n        if ( event-&gt;type() == QEvent::InputMethod )\n        {\n            QInputMethodEvent* inputEvent = (QInputMethodEvent*)event;\n            QLineEdit* lineEdit = (QLineEdit*) receiver;\n            lineEdit-&gt;setText(inputEvent-&gt;preeditString());\n        }\n        return QApplication::notify(receiver,event);\n    }\n};\n</code></pre>\n<p>But this does not work. Could anyone help with setting up a valid workaround?</p>\n",
        "tags": [
            "android",
            "c++",
            "qt"
        ]
    },
    {
        "index": 71,
        "question_id": 79621854,
        "title": "Compute cumulative mean &amp; std on polars dataframe (using over)",
        "body": "<p>I want to compute the cumulative mean &amp; std on a polars dataframe column.</p>\n<p>For the <code>mean</code> I tried this:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import polars as pl\n\ndf = pl.DataFrame({\n    'value': [4, 6, 8, 11, 5, 6, 8, 15],\n    'class': ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'B']\n})\n\ndf.with_columns(cum_mean=pl.col('value').cum_sum().over('class') \n                       / pl.int_range(pl.len()).add(1).over('class'))\n</code></pre>\n<p>which correctly gives</p>\n<pre><code>shape: (8, 3)\n┌───────┬───────┬──────────┐\n│ value ┆ class ┆ cum_mean │\n│ ---   ┆ ---   ┆ ---      │\n│ i64   ┆ str   ┆ f64      │\n╞═══════╪═══════╪══════════╡\n│ 4     ┆ A     ┆ 4.0      │\n│ 6     ┆ A     ┆ 5.0      │\n│ 8     ┆ B     ┆ 8.0      │\n│ 11    ┆ A     ┆ 7.0      │\n│ 5     ┆ B     ┆ 6.5      │\n│ 6     ┆ A     ┆ 6.75     │\n│ 8     ┆ B     ┆ 7.0      │\n│ 15    ┆ B     ┆ 9.0      │\n└───────┴───────┴──────────┘\n</code></pre>\n<p>However, this seems very clunky, and becomes a little more complicated (and possibly error-prone) for <code>std</code>.</p>\n<p>Is there a nicer (possibly built-in) version for computing the cum mean &amp; cum std?</p>\n",
        "tags": [
            "python",
            "python-3.x",
            "python-polars",
            "cumulative-sum"
        ]
    },
    {
        "index": 72,
        "question_id": 79621980,
        "title": "making plotly subplots using crosstalk SharedData object",
        "body": "<p>I would like to make plotly subplots using a <code>crosstalk::SharedData</code> object in R. I can think of 2 ways to approach this:</p>\n<ol>\n<li>use <code>plotly::ggplotly()</code> on a faceted ggplot</li>\n<li>create each subplot directly with <code>plotly</code> using <code>dplyr::group_map()</code> on a grouped dataframe and pass the list of subplots to <code>plotly::subplot()</code>.</li>\n</ol>\n<br> \n<p>Problems with the first approach:</p>\n<ul>\n<li><code>ggplot2::facet_grid()</code> blocks off space for all facet levels, even if they're filtered out the data (see image below).</li>\n<li>I prefer making the plots directly in <code>plotly</code> because complex plots don't convert from ggplot to plotly very nicely.</li>\n</ul>\n<br>\n<p>Problems with the second approach:</p>\n<ul>\n<li>I don't know how to do this successfully. I can't directly pass a <code>crosstalk::SharedData</code> object to <code>dplyr</code> functions like <code>group_by</code>. The documentation for <code>crosstalk</code> makes it sound like I can extract the filtered data using <code>shared_data$data(withFilter = TRUE)</code>, but doing so returns all the data regardless of the filter condition.</li>\n</ul>\n<p>Here's what I end up with\n<a href=\"https://i.sstatic.net/6N6RqVBM.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/6N6RqVBM.png\" alt=\"enter image description here\" /></a></p>\n<p>code:</p>\n<pre><code>---\ntitle: &quot;test_crosstalk&quot;\nformat: html\n---\n\n```{r}\n#| echo: false\n#| warning: false\n\ndata(mtcars)\n\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(crosstalk)\n```\n\n# create plots\n\n```{r}\n\n# create a SharedData object\nsd &lt;- crosstalk::SharedData$new(data = mtcars)\n\ncrosstalk::bscols(\n  widths = c(12, # put the filter on its own row\n             6, 6,\n             6, 6), \n  # create an interactive filter checkbox\n  crosstalk::filter_checkbox(\n    id = &quot;cyl&quot;,\n    label = &quot;Filter Cylinders&quot;,\n    sharedData = sd,\n    group = ~cyl, \n    inline = TRUE\n  ),\n  # ggplotly\n  plotly::ggplotly(ggplot(data = sd, \n                          mapping = aes(x = hp, \n                                        y = qsec, \n                                        color = factor(cyl), \n                                        group = factor(cyl))) + \n                     geom_point()  + \n                     ggtitle(&quot;ggplotly&quot;) +\n                     facet_grid(rows = dplyr::vars(cyl), drop = T)\n                   ),\n  # plotly with subplots\n  # can't directly use dplyr functions (like group_by) on a SharedData object, so pull the (supposedly filtered) data out of the SharedData object first\n  sd$data(withFilter = T) %&gt;%\n    dplyr::group_by(cyl) %&gt;%\n    dplyr::group_map(~{\n      plotly::plot_ly(\n        data = .x,\n        x = ~hp,\n        y = ~qsec,\n        type = &quot;scatter&quot;,\n        mode = &quot;markers&quot;\n      )\n    }) %&gt;%\n    do.call(what = function(...){\n            plotly::subplot(...,\n                            nrows  = length(unique(sd$data(withFilter = T)$cyl)),\n                            shareX = TRUE,\n                            shareY = TRUE,\n                            margin = 0.0025 # this controls the internal margins\n                            )},\n            args = .) %&gt;% \n    plotly::layout(title = 'Plotly with sd$data(withFilter=T)'),\n  # a plotly plot with crosstalk filtering, but w/o faceting\n  plotly::plot_ly(\n    data = sd,\n    x = ~hp,\n    y = ~qsec,\n    color = ~factor(cyl),\n    type = &quot;scatter&quot;,\n    mode = &quot;markers&quot;\n  ) %&gt;% \n    plotly::layout(title = 'Plotly w/o faceting'),\n  # a plotly plot with faceting, but w/o crosstalk filtering\n  mtcars %&gt;%\n    dplyr::group_by(cyl) %&gt;%\n    dplyr::group_map(~{\n      plotly::plot_ly(\n        data = .x,\n        x = ~hp,\n        y = ~qsec,\n        # color = ~cyl,\n        type = &quot;scatter&quot;,\n        mode = &quot;markers&quot;\n      )\n    }) %&gt;% \n    do.call(what = function(...){\n            plotly::subplot(..., \n                            nrows  = length(unique(mtcars$cyl)), \n                            shareX = TRUE, \n                            shareY = TRUE,\n                            margin = 0.025 # this controls the internal margins\n                            )},\n            args = .) %&gt;% \n    plotly::layout(title = 'Plotly without crosstalk filtering')\n  )\n\n\n```\n\n</code></pre>\n<p>(A generalization of this question is how to use dplyr functions, like <code>dplyr::filter</code> or <code>dplyr::group_by()</code> on a <code>crosstalk::SharedData</code> object.)</p>\n",
        "tags": [
            "r",
            "plotly",
            "crosstalk"
        ]
    },
    {
        "index": 73,
        "question_id": 79622010,
        "title": "How to animate a dot on a path along two intertwined ellipses",
        "body": "<p>I'm trying to create a small animation where a dot would smoothly go along two intertwined ellipses, like <a href=\"https://i.sstatic.net/M6vnIx3p.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/M6vnIx3p.png\" alt=\"in this drawing\" /></a></p>\n<p>I managed to create an almost-working path using an online tool to turn  shapes into a single path :</p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"false\" data-babel=\"false\" data-babel-preset-react=\"false\" data-babel-preset-ts=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-css lang-css prettyprint-override\"><code>.wrapper {\n    margin-top: 25dvh;\n    height: 50dvh;\n    width: 50dvh;\n    background-color: black;\n    margin: auto;\n}</code></pre>\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>&lt;div class=\"wrapper\"&gt;\n        &lt;svg viewBox=\"0 0 130 130\" xmlns=\"http://www.w3.org/2000/svg\"&gt;\n            &lt;path\n                fill=\"none\"\n                stroke=\"lightgrey\"\n                d=\"M 115.9656 66.951 A 52.9167 26.4583 0 0 1 63.049 93.4094 A 52.9167 26.4583 0 0 1 10.1323 66.951 A 52.9167 26.4583 0 0 1 63.049 40.4927 A 52.9167 26.4583 0 0 1 115.9656 66.951 Z M 62.9167 14.2985 A 26.3265 52.7849 0 0 1 89.2432 67.0833 A 26.3265 52.7849 0 0 1 62.9167 119.8682 A 26.3265 52.7849 0 0 1 36.5901 67.0833 A 26.3265 52.7849 0 0 1 62.9167 14.2985 Z\" /&gt;\n\n            &lt;circle r=\"5\" fill=\"red\"&gt;\n                &lt;animateMotion\n                    dur=\"10s\"\n                    repeatCount=\"indefinite\"\n                    path=\"M 115.9656 66.951 A 52.9167 26.4583 0 0 1 63.049 93.4094 A 52.9167 26.4583 0 0 1 10.1323 66.951 A 52.9167 26.4583 0 0 1 63.049 40.4927 A 52.9167 26.4583 0 0 1 115.9656 66.951 Z M 62.9167 14.2985 A 26.3265 52.7849 0 0 1 89.2432 67.0833 A 26.3265 52.7849 0 0 1 62.9167 119.8682 A 26.3265 52.7849 0 0 1 36.5901 67.0833 A 26.3265 52.7849 0 0 1 62.9167 14.2985 Z\" /&gt;\n             &lt;/circle&gt;\n&lt;/svg&gt;\n    &lt;/div&gt;</code></pre>\n</div>\n</div>\n</p>\n<p>But of course the starting point of each ellipse is different, while I would want them superposed - for instance in A (in my little drawing above).\nSo my questions are:</p>\n<ul>\n<li>What would be the best / simplest way to do that?</li>\n<li>Is there a way to move the ellipses' starting point?</li>\n<li>I tried to draw the path with a successions of arcs - e.g: ABC, CFA,\nADF, FHA - but couldn't manage the math to recreate the ellipses (I\nreally suck at maths......): any clue about how to calculate key point\ncoords, rx, ry and all?</li>\n</ul>\n<p>Thanks for your help :)</p>\n",
        "tags": [
            "animation",
            "math",
            "svg",
            "path",
            "ellipse"
        ]
    },
    {
        "index": 74,
        "question_id": 79622089,
        "title": "Git diff-files sometimes reports unchanged files as modified -- prevent work tree out of sync with the index?",
        "body": "<p>I use <code>git diff-files --quiet</code> inside a script to check if my working copy is dirty. (Following <a href=\"https://stackoverflow.com/questions/2657935/checking-for-a-dirty-index-or-untracked-files-with-git/2659808#2659808\">this advice</a>.) Usually it works fine, but rarely it reports true when there are no changes. Running <code>git status</code> reports no modified files but my next <code>diff-files</code> will also report no modified files. If I don't run <code>status</code>, then <code>diff-files</code> will consistently indicate the working copy is dirty.</p>\n<p>I can use <code>git diff-files --exit-code --no-textconv</code> for similar behaviour but with output, and it shows results like this (but many lines of output -- possibly one for every tracked file):</p>\n<pre><code>:100644 100644 a806cd354388da20a1c63986b807369bb580c278 0000000000000000000000000000000000000000 M      tools/premake4/BUILD.txt\n:100644 100644 dd522a73a8b10de80e5ab1532f354b8a514ce786 0000000000000000000000000000000000000000 M      tools/premake4/CHANGES.txt\n:100644 100644 e43ffa877f2b4e291605620500a16c72b8b403f3 0000000000000000000000000000000000000000 M      tools/premake4/LICENSE.txt\n:100644 100644 c7df2ad722874e767105f7741f8c75e4999001e7 0000000000000000000000000000000000000000 M      tools/premake4/README.txt\n</code></pre>\n<p><a href=\"https://git-scm.com/docs/git-diff-files#_raw_output_format\" rel=\"nofollow noreferrer\">git diff-files help</a> says: <em>0{40} if deletion, unmerged or &quot;work tree out of sync with the index&quot;.</em> Since <code>git status</code> resolves it, presumably my problem is &quot;work tree out of sync with the index&quot;.</p>\n<p>How can I make my tooling more reliable without always running <code>git status</code>? <code>diff-files</code> doesn't appear to take a <code>--update-index-if-necessary</code> option.</p>\n",
        "tags": [
            "git",
            "git-plumbing"
        ]
    },
    {
        "index": 75,
        "question_id": 79622090,
        "title": "How are constexpr device variables accessible from host?",
        "body": "<p>My colleague came across <a href=\"https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(filename:%271%27,fontScale:14,fontUsePx:%270%27,j:1,lang:cuda,selection:(endColumn:12,endLineNumber:16,positionColumn:12,positionLineNumber:16,selectionStartColumn:12,selectionStartLineNumber:16,startColumn:12,startLineNumber:16),source:%27%23include+%3Carray%3E%0A%23include+%3Ccstdio%3E%0A%0A__device__+constexpr+std::array%3Cint,+2%3E+a+%3D+%7B15,+1%7D%3B%0A%0A__host__+__device__+void+my_print(const+char*+c_str,+const+int%26+i)+%7B%0A++++std::printf(c_str)%3B%0A++++std::printf(%22+i%3D%25d+%26i%3D%25p%5Cn%22,+i,+%26i)%3B%0A%7D%0A%0A//+Type+your+code+here,+or+load+an+example.%0A__global__+void+display()+%7B%0A++++my_print(%22device%22,+a%5B0%5D)%3B%0A%7D%0A%0Aint+main()+%7B%0A++++display%3C%3C%3C1,+1%3E%3E%3E()%3B%0A++++cudaDeviceSynchronize()%3B%0A++++my_print(%22host%22,+a%5B0%5D)%3B%0A++++return+0%3B%0A%7D%0A%27),l:%275%27,n:%270%27,o:%27CUDA+C%2B%2B+source+%231%27,t:%270%27)),k:53.9311241065627,l:%274%27,n:%270%27,o:%27%27,s:0,t:%270%27),(g:!((g:!((h:compiler,i:(compiler:nvcc128u1,filters:(b:%270%27,binary:%271%27,binaryObject:%271%27,commentOnly:%270%27,debugCalls:%271%27,demangle:%270%27,directives:%270%27,execute:%270%27,intel:%270%27,libraryCode:%270%27,trim:%271%27,verboseDemangling:%270%27),flagsViewOpen:%271%27,fontScale:14,fontUsePx:%270%27,j:1,lang:cuda,libs:!(),options:%27-expt-relaxed-constexpr+-rdc%3Dtrue+-std%3Dc%2B%2B17+%27,overrides:!(),selection:(endColumn:1,endLineNumber:1,positionColumn:1,positionLineNumber:1,selectionStartColumn:1,selectionStartLineNumber:1,startColumn:1,startLineNumber:1),source:1),l:%275%27,n:%270%27,o:%27+NVCC+12.8.1+(Editor+%231)%27,t:%270%27)),k:50,l:%274%27,m:47.61904761904763,n:%270%27,o:%27%27,s:0,t:%270%27),(g:!((h:output,i:(compilerName:%27x86-64+gcc+12.2%27,editorid:1,fontScale:14,fontUsePx:%270%27,j:1,wrap:%271%27),l:%275%27,n:%270%27,o:%27Output+of+NVCC+12.8.1+(Compiler+%231)%27,t:%270%27)),header:(),l:%274%27,m:23.764515257899,n:%270%27,o:%27%27,s:0,t:%270%27),(g:!((h:device,i:(compilerName:%27NVCC+12.8.1%27,device:PTX,editorid:1,fontScale:14,fontUsePx:%270%27,j:1,selection:(endColumn:1,endLineNumber:1,positionColumn:1,positionLineNumber:1,selectionStartColumn:1,selectionStartLineNumber:1,startColumn:1,startLineNumber:1),treeid:0),l:%275%27,n:%270%27,o:%27Device+Viewer+NVCC+12.8.1+(Editor+%231,+Compiler+%231)%27,t:%270%27)),l:%274%27,m:28.61643712305338,n:%270%27,o:%27%27,s:0,t:%270%27)),k:46.0688758934373,l:%273%27,n:%270%27,o:%27%27,t:%270%27)),l:%272%27,n:%270%27,o:%27%27,t:%270%27)),version:4\" rel=\"nofollow noreferrer\">this situation</a> where global <code>__device__ constexpr</code> variables are accessible from both the host and the device.</p>\n<pre><code>#include &lt;array&gt;\n#include &lt;cstdio&gt;\n\n__device__ constexpr std::array&lt;int, 2&gt; a = {15, 1};\n\n__host__ __device__ void my_print(const char* c_str, const int&amp; i) {\n    std::printf(c_str);\n    std::printf(&quot; i=%d &amp;i=%p\\n&quot;, i, &amp;i);\n}\n\n// Type your code here, or load an example.\n__global__ void display() {\n    my_print(&quot;device&quot;, a[0]);\n}\n\nint main() {\n    display&lt;&lt;&lt;1, 1&gt;&gt;&gt;();\n    cudaDeviceSynchronize();\n    my_print(&quot;host&quot;, a[0]);\n    return 0;\n}\n</code></pre>\n<p>Here is the output from a run, which looks reasonable:</p>\n<pre><code>device i=15 &amp;i=0x7e97e9200000\nhost i=15 &amp;i=0x482008\n</code></pre>\n<p>Our situation is related to <a href=\"https://stackoverflow.com/questions/34041372/access-cuda-global-device-variable-from-host\">this question</a>. However, unlike that case, we know the variable's value at compile time. Is the current situation well-defined?</p>\n",
        "tags": [
            "c++",
            "cuda",
            "constexpr",
            "nvcc"
        ]
    },
    {
        "index": 76,
        "question_id": 79622175,
        "title": "How to get &lt;tab&gt; value suggestions dynamically, without throwing an error if user provided a value that does not exist?",
        "body": "<p>Lets say, I have two functions <code>get-foo</code> and <code>new-foo</code>, that I am using to read and edit a tree structure resource. Its really nothing sophisticated, I am using the file system to implement the structure.</p>\n<p>The issue am having is <code>get-foo</code> works as I want it to, it will force the user to only input values that are found in the tree structure.</p>\n<p>My issue is, <code>new-foo</code> is not working as I want it to, I would like values from the tree structure to be suggested similar to how they are   with <code>get-foo</code>, but the user must be able to input arbitrary values, so they can extend the structure.  Currently <code>new-foo</code> will throw an error if the value does not exist.</p>\n<p>My code:</p>\n<pre><code>Function get-foo{\n    param(\n    [ValidateSet([myTree], ErrorMessage = &quot;&quot;&quot;{0}&quot;&quot; Is not a valid structure&quot;)]\n    [string]$name\n    )\n    $name\n}\n\nFunction new-foo{\n    param(\n    [ValidateSet([myTree])]\n    [string]$name\n    )\n    $name\n}\n\n\nClass myTree : System.Management.Automation.IValidateSetValuesGenerator{\n    [string[]] GetValidValues(){\n        return [string[]] (Get-ChildItem -path &quot;C:\\temp&quot; -Recurse |ForEach-Object {($_.FullName -replace 'c:\\\\temp\\\\')})\n    }}\n</code></pre>\n<p><code>get-foo</code> and <code>new-foo</code> both have a <code>name</code> parameter,  the user is expected to provide a name. The functions check the directory <code>c:\\temp</code>, for valid names.</p>\n<p>For example,  if <code>c:temp</code> was as follows:</p>\n<pre><code>C:\\temp\\animal\n    C:\\temp\\animals\\cat\n    C:\\temp\\animals\\dog\n    C:\\temp\\animals\\fish\nC:\\temp\\colours\n    C:\\temp\\colours\\green\n    C:\\temp\\colours\\orange\n    C:\\temp\\colours\\red\nC:\\temp\\plants\n    C:\\temp\\plants\\carrots\n    C:\\temp\\plants\\patato\n    C:\\temp\\plants\\vegatables\n</code></pre>\n<p>Then with <code>get-foo -name anima...&lt;tab&gt;</code>, then the auto competition examples would be:</p>\n<ul>\n<li><code>get-foo -name animals\\cat</code></li>\n<li><code>get-foo -name animals\\dog</code></li>\n<li><code>get-foo -name animals\\fish</code></li>\n</ul>\n<p>But <code>new-foo</code> will throw an error if the value <code>name</code> does not already exist. Is there a mechanism that I can use to still get dynamic autocompletion but without the error? I checked the parameter attribute section, from my reading only <code>validatSet</code> seems applicable.</p>\n<p>Am on pwsh 7.4</p>\n<p>Edit: I made a slight edit above, <code>new-foo</code>'s <code>-name</code> parameter was not using the same validateSet class as <code>set-foo</code>, they are both using the same validateSet class.</p>\n",
        "tags": [
            "powershell",
            "tab-completion"
        ]
    },
    {
        "index": 77,
        "question_id": 79622224,
        "title": "How to display two blank paragraphs on small screens only, just to add a double space above the paragraph with text?",
        "body": "<p>How to display two blank paragraphs on small screens only, just to add a double space above the paragraph with text  ? The following creates just a single space above the paragraph with text:-</p>\n<p><strong>CSS and HTML</strong></p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\" data-babel-preset-react=\"false\" data-babel-preset-ts=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-css lang-css prettyprint-override\"><code>p.mobiles {\n      display: inline;\n    }\n    @media (max-width: 480px) {\n    p.mobiles {\n      display: inline !important;\n      margin-top: 3em !important;\n      }\n    }\n    @media (min-width: 481px) and (max-width: 767px) {\n    p.mobiles {\n      display: inline !important;\n      }\n    }\n    @media (min-width: 768px) and (max-width: 1024px) {\n    p.mobiles {\n      display: none;\n      }\n    }\n    @media (min-width: 1025px) and (max-width: 1280px) {\n    p.mobiles {\n      display: none;\n      }\n    }\n    @media (min-width: 1281px) {\n    p.mobiles {\n      display: none;\n      }\n    }</code></pre>\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>&lt;h1&gt;Heading&lt;/h1)&gt;\n&lt;p class=\"mobiles\"&gt;&amp;nbsp;&lt;/p&gt;&lt;p class=\"mobiles\"&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p style=\"color:black;font-family:&amp;quot;verdana&amp;quot;;font-size:18px;line-height:18px;text-align:justify;\" align=\"left\"&gt;To display only on small screens&lt;/p&gt;</code></pre>\n</div>\n</div>\n</p>\n",
        "tags": [
            "paragraph"
        ]
    },
    {
        "index": 78,
        "question_id": 79622239,
        "title": "CharsetDecoder with DirectByteBuffer and HeapByteBuffer performance difference",
        "body": "<p>My use case is the following: reading DirectByteBuffers from the network and decoding them into UTF-8 strings. I’ve observed that using a UTF_8 CharsetDecoder with a DirectByteBuffer is 3–4 times slower than with a HeapByteBuffer. From what I understand, this is due to intrinsic optimizations for ASCII input, as described here: <a href=\"https://cl4es.github.io/2021/02/23/Faster-Charset-Decoding.html\" rel=\"nofollow noreferrer\">https://cl4es.github.io/2021/02/23/Faster-Charset-Decoding.html</a> (<a href=\"https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/sun/nio/cs/UTF_8.java#L231\" rel=\"nofollow noreferrer\">https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/sun/nio/cs/UTF_8.java#L231</a>)</p>\n<p>This brings me to a couple of questions:</p>\n<ol>\n<li><p>Why can’t these optimizations be applied to DirectByteBuffer as well? Is it that intrinsic implementation is not possible in that case?</p>\n</li>\n<li><p>Would it be a reasonable approach to copy the contents of a DirectByteBuffer into a HeapByteBuffer (e.g., in 8KB chunks) before decoding? I’ve noticed this leads to lower decode latency, though I assume it comes at the cost of increased CPU usage.</p>\n</li>\n</ol>\n<p>Here is a small example:</p>\n<pre class=\"lang-kotlin prettyprint-override\"><code>fun main() {\n  val decoder = StandardCharsets.UTF_8.newDecoder()\n  val encoder = StandardCharsets.UTF_8.newEncoder()\n\n  repeat(10_000) {\n    val text = (0..10_000).joinToString(&quot;,&quot;) { UUID.randomUUID().toString() }\n    val direct = ByteBuffer.allocateDirect(10_000 * 100)\n    val heap = ByteBuffer.allocate(10_000 * 100)\n    val heapTmp = ByteBuffer.allocate(10_000 * 100)\n\n    val directEncoderTime = measureTime {\n      encoder.encode(CharBuffer.wrap(text), direct, true)\n      direct.flip()\n    }\n    val heapEncoderTime = measureTime {\n      encoder.encode(CharBuffer.wrap(text), heap, true)\n      heap.flip()\n    }\n    println(&quot;Direct encoding: $directEncoderTime&quot;)\n    println(&quot;Heap encoding: $heapEncoderTime&quot;)\n\n    val (directToHeapDecoded, directToHeapDecodeTime) = measureTimedValue {\n      heapTmp.put(direct)\n      heapTmp.flip()\n      direct.position(0)\n      decoder.decode(heapTmp)\n    }\n    val (directDecoded, directDecodeTime) = measureTimedValue {\n      decoder.decode(direct)\n    }\n    val (heapDecoded, heapDecodeTime) = measureTimedValue {\n      decoder.decode(heap)\n    }\n    println(&quot;DirectToHeap decoding: $directToHeapDecodeTime&quot;)\n    println(&quot;Direct decoding: $directDecodeTime&quot;)\n    println(&quot;Heap decoding: $heapDecodeTime&quot;)\n  }\n}\n</code></pre>\n",
        "tags": [
            "kotlin",
            "character-encoding",
            "bytebuffer"
        ]
    },
    {
        "index": 79,
        "question_id": 79622285,
        "title": "Downcasting to Float32 displays additional precision numbers in polars which dont exists in source file/data",
        "body": "<p>Whenever we downcast a column from float 64 to float 32, it seems that polars adds extra precision numbers to the display output which didnt even exist.\nWhen I compare the actual values, they seem to match, but the display setting throws off any checks done by naked eye.\nI know there is a display config to fix this and limit precision points when displaying data, but I am just curious as to why this happens in the first place and why some random numbers are added as padding.</p>\n<p>I first noticed this when reading data from a csv file with schema overrides where data seemed off when read and printed with polars and compared against csv file opened in a text editor</p>\n<pre><code>import polars as pl\ndf1 = pl.DataFrame(\n{\n&quot;col1&quot;:[2021.9952, 2024.0, 2024.25, 2024.456]\n}\n)\nprint(&quot;original values&quot;)\nprint(df1)\n\nshape: (4, 1)\n┌───────────┐\n│ col1      │\n│ ---       │\n│ f64       │\n╞═══════════╡\n│ 2021.9952 │\n│ 2024.0    │\n│ 2024.25   │\n│ 2024.456  │\n└───────────┘\n\ndiff1 = df1[&quot;col1&quot;][1] -  df1[&quot;col1&quot;][0]\nprint(&quot;Original: diff row1 - row0&quot;)\nprint(diff1)\n2.004799999999932\n\nprint(&quot;Origirnal value equality&quot;)\nprint(df1[&quot;col1&quot;][0] == 2021.9952)\nTrue\n\nprint(&quot;dDowncasting to float 32&quot;)\nprint(df1.cast({&quot;col1&quot;:pl.Float32}))\n\nshape: (4, 1)\n┌─────────────┐\n│ col1        │\n│ ---         │\n│ f32         │\n╞═════════════╡\n│ 2021.995239 │\n│ 2024.0      │\n│ 2024.25     │\n│ 2024.456055 │\n└─────────────┘\n\nprint(&quot;Downcasted: diff row1 - row0&quot;)\ndiff2 = df1[&quot;col1&quot;][1] -  df1[&quot;col1&quot;][0]\nprint(diff2)\n2.004799999999932\nprint(&quot;Downcasted value equality&quot;)\nprint(df1[&quot;col1&quot;][0] == 2021.9952)\nTrue\n</code></pre>\n<p>Expected:\nI expected the down casted values to look the same as before or maybe with padded zeros instead of random numbers -</p>\n<pre><code>┌───────────┐\n│ col1      │\n│ ---       │\n│ f32       │\n╞═══════════╡\n│ 2021.9952 │\n│ 2024.0    │\n│ 2024.25   │\n│ 2024.456  │\n└───────────┘\n\nor\n\n┌───────────┐\n│ col1      │\n│ ---       │\n│ f32       │\n╞═══════════╡\n│ 2021.99520│\n│ 2024.00000│\n│ 2024.25000│\n│ 2024.45600│\n└───────────┘\n</code></pre>\n",
        "tags": [
            "python",
            "python-polars"
        ]
    },
    {
        "index": 80,
        "question_id": 79622310,
        "title": "Loading CSV data from Box into Javascript?",
        "body": "<p>I have some regularly-updated CSV files on Box that I would like to display on a website. My plan was to create the table with html, then read the CSV file with d3 and update the contents of the table. If the CSV data were on GitHub, I could do something like this:</p>\n<pre><code>d3.csv(data_url).then(create_table);\nfunction create_table(data) {\n   &lt;code to update a table&gt;\n}\n</code></pre>\n<p>However, that doesn't seem to work with a Box URL. I can generate a URL for the data on Box with the format &quot;https://xxxxxxxx.box.com/shared/static/xxxxxxxxx.csv&quot;. Going to that link directly will download the CSV file, but inserting it into the code above produces a &quot;Cross-Origin Request Blocked&quot; error. Is this possible? Since the CSV files update hourly, it would be best if I could read directly from Box to my website, rather than moving the data elsewhere.</p>\n",
        "tags": [
            "javascript",
            "html",
            "csv",
            "d3.js"
        ]
    },
    {
        "index": 81,
        "question_id": 79622313,
        "title": "C++ log method capturing source line with variadic arguments",
        "body": "<p>I'm trying to write a logging function (instead of a macro) which has variadic arguments for formatting, but still captures the source location of the caller.</p>\n<p>I have:</p>\n<pre><code>template &lt;typename... Args&gt;\ninline static void LOG_MSG(const std::string&amp; str, \n                           Args&amp;&amp;... args, \n                           const std::source_location location = std::source_location::current())\n{\n\n}\n</code></pre>\n<p>called via:</p>\n<pre><code>LOG_MSG(&quot;test {}&quot;, 42);\n</code></pre>\n<p>but I get:</p>\n<pre><code>candidate function template not viable: no known conversion from 'int' to 'const std::source_location' for 2nd argument\n</code></pre>\n<p>How should this be done?</p>\n",
        "tags": [
            "c++"
        ]
    },
    {
        "index": 82,
        "question_id": 79622326,
        "title": "C++ format string compile-time validity check",
        "body": "<p>I am trying to implement a C++ <code>Translate</code> function for localization.</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>// Language package, containing key-value pairs of translation, e.g.,\n// g_LanguagePack[&quot;HELLO@1&quot;] = &quot;Hello, {}!&quot;\n// The &quot;@N&quot; suffix indicates that this format string has N parameters.\n// When there is no parameter, the suffix can be omitted.\nstd::unordered_map&lt;std::string, std::string&gt; g_LanguagePack;\n\n// The translator function\ntemplate &lt;typename VA...&gt;\nstd::sting Translate(const std::string&amp; key, VA&amp;&amp;... params);\n</code></pre>\n<p>When invoked, e.g., <code>Translate(&quot;HELLO@1&quot;, &quot;FOO&quot;)</code> will do a lookup in the language package and return the localized string <code>&quot;Hello, FOO!&quot;</code>.</p>\n<p><code>key</code> is guaranteed to be a compile-time string (so <code>key</code>'s type may need to be changed), and in practice developers may provide mismatching number of parameters, or missing <code>@N</code> while providing parameters. So I think it is necessary to add a check mechanism to ensure <code>N == sizeof...(VA)</code>.</p>\n<p>At the beginning, I used <code>static_assert</code>  in <code>Checker</code>, and it failed because <strong>static assertion expression is not an integral constant expression</strong>. Then I learned <a href=\"https://stackoverflow.com/questions/47543586/user-defined-literal-string-compile-time-length-check\">User-defined literal string: compile-time length check</a> that I can directly use assert in <code>consteval</code> functions, and it works.</p>\n<p>However, the GPT said it's not recommended to call <code>assert</code> in <code>consteval</code> functions (I am not sure about it, since it compiles on both Clang and MSVC). And, if it is not recomended, what could be a better implementation?</p>\n<pre><code>template &lt;std::size_t N, typename... VA&gt;\nconsteval void Checker(const char (&amp;key)[N], VA&amp;&amp;... va)\n{\n    std::string_view string_view(key, N - 1);\n    std::size_t param_cnt = 0;\n    auto indicator_index = string_view.find('@');\n    if (indicator_index == std::string_view::npos) // no params\n    {\n        assert(sizeof...(VA) == 0);\n    }\n    else\n    {\n        // parse param_cnt_\n        for (auto i = indicator_index + 1; string_view.begin() + i != string_view.end(); i++)\n        {\n            auto digit = string_view.at(i); // get digit\n            assert('0' &lt;= digit &amp;&amp; digit &lt;= '9');\n            param_cnt = param_cnt * 10 + digit - '0';\n        }\n        assert(sizeof...(va) == param_cnt);\n    }\n}\n\nint main(int argc, char* argv[])\n{\n    Checker(&quot;foo@2&quot;, 1, 2);\n    Checker(&quot;foo@1&quot;, &quot;string&quot;);\n    return 0;\n}\n\n</code></pre>\n<p>Then comes the tricky part. I tried to use Checker in <code>Translate</code>, unfortunately, it did not work. It's because <code>key</code>, when passed as parameter, is no longer guaranteed to be a compile-time constant.</p>\n<pre><code>template &lt;std::size_t N, typename... VA&gt;\nstd::string Translate(const char (&amp;key)[N], VA&amp;&amp;... va)\n{\n  Checker(key, va...); // Function parameter 'key' with unknown value cannot be used in a constant expression\n  // do translation\n  return &quot;&quot;;\n}\n</code></pre>\n",
        "tags": [
            "c++",
            "c++20",
            "compile-time-constant",
            "compile-time-type-checking"
        ]
    },
    {
        "index": 83,
        "question_id": 79622426,
        "title": "Can Duration.isZero() return false and yet Duration.toMillis() returns zero?",
        "body": "<p>In order to calculate a wait() duration, we do some math on Durations:</p>\n<pre><code>   Instant start = Instant.now();\n   while(!exiting) {\n       synchronized(waitObject)\n       {\n           Duration toWait = TOTAL_WAIT_TIME.minus(Duration.between(start, Instant.now()));\n           if (!toWait.isNegative() &amp;&amp; !toWait.isZero() {\n               waitObject.wait(toWait.toMillis());\n           }\n       }\n   }\n</code></pre>\n<p>Obviously there's more in this code, but that distills it to its basics for this question.</p>\n<p>What we are seeing in our testing is that the argument being passed into wait() can be zero.</p>\n",
        "tags": [
            "java"
        ]
    },
    {
        "index": 84,
        "question_id": 79622512,
        "title": "Move Facet label to the left to make space for legend",
        "body": "<p>I am using facet_wrap and need to move the x axis table left and the y2 axis lable up to make room for my legend and was wondering if the is possible.</p>\n<p>Below is my code and an image of what I am trying to achieve.</p>\n<p><a href=\"https://i.sstatic.net/XWUJtXbc.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/XWUJtXbc.png\" alt=\"enter image description here\" /></a></p>\n<pre><code>p &lt;- ggplot(data_Long, aes(x = Week, y = count)) +\n  geom_line(aes(colour = Temp, linetype = Water)) +\n  labs(x = &quot;Germination weeks&quot;, y = &quot;% Germination&quot;, colour = &quot;Temperature (°C)&quot;, \n       linetype = &quot;Water Availibility&quot;) +\n  ylim(0, 100) +\n  theme_classic() +\n  theme(\n    strip.text.x = element_text(size=10, face=&quot;italic&quot;), legend.position = c(0.85,0.15))+\n  scale_y_continuous( limits=c(0, 100),\n                      sec.axis = sec_axis(~ ., \n                                          breaks = c(25, 50, 75), \n                                          labels = c(&quot;5/15&quot;, &quot;10/25&quot;, &quot;15/40&quot;), \n                                          name = &quot;Temperature (°C)&quot;)) +\n  geom_segment(aes(x = 0, y = 75, xend = 8, yend = 75), colour = &quot;grey&quot;, size=0.2) +\n  geom_segment(aes(x = 8, y = 50, xend = 12, yend = 50), colour = &quot;grey&quot;, size=0.2) +\n  geom_segment(aes(x = 12, y = 25, xend = 24, yend = 25), colour = &quot;grey&quot;, size=0.2) +\n  geom_segment(aes(x = 24, y = 50, xend = 26, yend = 50), colour = &quot;grey&quot;, size=0.2) +\n  geom_segment(aes(x = 8, y = 75, xend = 8, yend = 50), colour = &quot;grey&quot;, size=0.2) +\n  geom_segment(aes(x = 12, y = 50, xend = 12, yend = 25), colour = &quot;grey&quot;, size=0.2) +\n  geom_segment(aes(x = 24, y = 25, xend = 24, yend = 50), colour = &quot;grey&quot;, size=0.2) +\n  annotate('rect', xmin=13, xmax=24, ymin=0, ymax=25, alpha=.1, fill='blue')+ ######Win1\n  annotate('rect', xmin=7, xmax=7.2, ymin=0, ymax=75, alpha=.1, fill='blue')+ #####Wet 1\n  annotate('rect', xmin=9, xmax=9.2, ymin=0, ymax=50, alpha=.1, fill='blue') + #####Wet 2\n  annotate('rect', xmin=11, xmax=11.2, ymin=0, ymax=50, alpha=.1, fill='blue') + #####Wet 3\n  facet_wrap(~Species, ncol = 2)+\n  scale_color_manual(values=c(&quot;royalblue&quot;, &quot;orange&quot;, &quot;forestgreen&quot;, &quot;firebrick3&quot;))+\n  scale_x_continuous(breaks=c(0, 5, 10, 15, 20, 25 ))\n\np\n</code></pre>\n",
        "tags": [
            "r",
            "ggplot2",
            "grid",
            "label",
            "facet"
        ]
    },
    {
        "index": 85,
        "question_id": 79622648,
        "title": "invalid go version &#39;1.23.0&#39;: must match format 1.23. unknown directive: toolchain error",
        "body": "<p>When working with an old version of Ignite CLI (v0.26.1), I got this error every time I ran <code>ignite chain serve</code>.</p>\n<pre class=\"lang-bash prettyprint-override\"><code>✘ :3: invalid go version '1.23.0': must match format 1.23\n:5: unknown directive: toolchain                       \n</code></pre>\n<p>I tried to change <code>go 1.23.0</code> to <code>go 1.23</code> in <code>go.mod</code> file, but <code>go mod tidy</code> and <code>ignite chain serve</code> always reverted it to <code>go 1.23.0</code>, which then threw the error.</p>\n<p>I am using MacOs</p>\n<pre class=\"lang-bash prettyprint-override\"><code>go version\ngo version go1.23.0 darwin/arm64\n</code></pre>\n",
        "tags": [
            "go"
        ]
    },
    {
        "index": 86,
        "question_id": 79622673,
        "title": "Not able to understand mutablity when it comes to mutable refferences",
        "body": "<p>I have recently started learning rust from : <a href=\"https://doc.rust-lang.org/book/\" rel=\"nofollow noreferrer\">https://doc.rust-lang.org/book/</a>.\nWhile learning about ownership, I came up with following piece of code:</p>\n<pre><code>let mut s = String::from(&quot;hello&quot;);\n\nlet r1 = &amp;mut s;\n</code></pre>\n<p>Here it confused me, why are we not using 'mut' keyword before r1 too?\nWhat if we use 'mut' keyword, what will it signify?</p>\n<p>Because I am still able to modify content with:</p>\n<pre><code>r1.push_str(&quot; World!&quot;);\n</code></pre>\n",
        "tags": [
            "rust"
        ]
    },
    {
        "index": 87,
        "question_id": 79622807,
        "title": "What is the advantage of using OpenTelemetry with AzureMonitor instead of ApplicationInsights directly?",
        "body": "<p>What is the advantage of using intermediary layer (OpenTelemetry) instead directly ApplicationInsights?</p>\n<p>For example:</p>\n<pre><code>builder.Services.AddOpenTelemetry().UseAzureMonitor();\n</code></pre>\n<p>instead of</p>\n<pre><code>builder.Services.AddApplicationInsightsTelemetry();\n</code></pre>\n<p>There already is logging abstraction built in .NET (<code>ILogger</code>, <code>ILoggerProvider</code>), which allows to easily switch to different logging libraries without changing application code, so I'm missing the point of the OpenTelemetry layer here.</p>\n",
        "tags": [
            ".net",
            "logging",
            "azure-application-insights",
            "open-telemetry"
        ]
    },
    {
        "index": 88,
        "question_id": 79623014,
        "title": "Pythonic way to append function output to existing lists?",
        "body": "<p>I have two functions that each return a tuple of lists. What is the most pythonic way to merge them? I am using tmp vars at the moment, which I find a bit awkward. Is there maybe a one-line-solution?</p>\n<p>Here is my existing code, reduced to the bare minimum:</p>\n<pre><code>def check_this() -&gt; Tuple[List[str], List[str]]:\n    problems = []\n    warnings = []\n    # do some tests to fill those lists with various error messages\n    return problems, warnings\n\ndef check_that() -&gt; Tuple[List[str], List[str]]:\n    problems = []\n    warnings = []\n    # do some more tests to fill those lists with various error messages\n    return problems, warnings\n\ndef log_check_results(problems: List[str], warnings: List[str]):\n    logging.error(&quot;\\n&quot;.join(problems))\n    logging.warning(&quot;\\n&quot;.join(warnings))\n</code></pre>\n<p>I do not want to merge the check methods because they check completely different aspects of the project.</p>\n<p>This was my first approach:</p>\n<pre class=\"lang-py prettyprint-override\"><code>problems, warnings = check_this()\np, w = check_that()\nproblems.extend(p)\nwarnings.extend(w)\nlog_check_results(problems, warnings)\n</code></pre>\n<p>I have tried the following but find it harder to read (hence the question for a &quot;pythonic&quot; solution.)</p>\n<pre class=\"lang-py prettyprint-override\"><code>problems, warnings = zip(check_this(), check_that())\nlog_check_results([m for l in problems for m in l],\n                  [m for l in warnings for m in l])\n</code></pre>\n<p>Any better ideas?</p>\n",
        "tags": [
            "python"
        ]
    },
    {
        "index": 89,
        "question_id": 79623104,
        "title": "Spotlight only finds titles, not contentDescription using AppIntents/CoreSpotlight in iOS 18",
        "body": "<p>I’m implementing Spotlight search for notes app, using iOS 18’s AppIntents and CoreSpotlight. While my notes are indexed, the transcript and aiSummary fields (assigned to contentDescription and textContent) aren’t appearing in search results.</p>\n<p>Current Implementation:</p>\n<p>Indexing Setup:</p>\n<pre><code>@available(iOS 18.0, *)  \nstruct NoteEntryEntity: AppEntity, IndexedEntity, Identifiable {  \n    // ...  \n    var attributeSet: CSSearchableItemAttributeSet {  \n        let attributeSet = defaultAttributeSet  \n        attributeSet.title = title  \n        attributeSet.contentDescription = transcript  \n        attributeSet.textContent = [transcript, aiSummary].compactMap { $0 }.joined(separator: &quot;\\n\\n&quot;)  \n        attributeSet.keywords = (noteTags?.compactMap { $0.name } ?? [])  \n        return attributeSet  \n    }  \n}  \n</code></pre>\n<p>Problem:\nSpotlight only finds titles, not transcript/aiSummary content.</p>\n<p>Question:\nHow does spotlight support search for content description?</p>\n<p>I would really appreciate any input for this.</p>\n",
        "tags": [
            "ios",
            "ios18",
            "appintents",
            "corespotlight"
        ]
    },
    {
        "index": 90,
        "question_id": 79623161,
        "title": "Will unique pointer free the memory?",
        "body": "<p>Let's say you allocate an object and pass the address in a Windows message (posted, not sent). In the message handler, the address is recovered and used to initialize a <code>std::unique_ptr</code>. Will the smart pointer's destructor delete the object?</p>\n<pre><code>auto* data = new BackupStatusMsg{ pct, st, e1, e2, msg };\n::PostMessage(m_hWnd, WM_BACKUP_STATUS, 0, reinterpret_cast&lt;LPARAM&gt;(data));\n</code></pre>\n<p>And in handler method:</p>\n<pre><code>LRESULT DialogClass::OnSomething(WPARAM, LPARAM lp)\n{\n    std::unique_ptr&lt;BackupStatusMsg&gt; p(reinterpret_cast&lt;BackupStatusMsg*&gt;(lp));\n\n    // .....\n\n    return 0;\n}\n</code></pre>\n<p>Will this object be deleted when <code>OnSomething</code> returns?</p>\n",
        "tags": [
            "c++",
            "winapi",
            "mfc",
            "smart-pointers",
            "unique-ptr"
        ]
    },
    {
        "index": 91,
        "question_id": 79623372,
        "title": "How to list all visible products for specific product category in WooCommerce",
        "body": "<p>I want to simply display all products for a specific product category [e.g. &quot;smart-shoes&quot; term slug] on my WooCommerce website.  I only want visible products in that category listed.</p>\n<p>Here is my code:</p>\n<pre><code>$args = array(\n 'number' =&gt; $number,\n 'orderby' =&gt; 'title',\n 'order' =&gt; 'ASC',\n 'hide_empty' =&gt; $hide_empty,\n 'include' =&gt; $ids\n);\n$product_categories = get_terms( 'product_cat', $args );\n$count = count($product_categories);\nif ( $count &gt; 0 ){\n foreach ( $product_categories as $product_category ) {\n echo '&lt;h4&gt;&lt;a href=&quot;' . get_term_link( $product_category ) . '&quot;&gt;' . $product_category-&gt;name . '&lt;/a&gt;&lt;/h4&gt;';\n $args = array(\n\n 'posts_per_page' =&gt; -1,\n 'tax_query' =&gt; array(\n 'relation' =&gt; 'AND',\n   \n array(\n 'taxonomy' =&gt; 'product_cat',\n 'field' =&gt; 'slug',\n 'terms' =&gt; $product_category-&gt;slug\n   \n )\n   \n ),\n 'post_type' =&gt; 'product',\n  'orderby' =&gt; 'title',\n 'order' =&gt; 'ASC',\n\n );\n $products = new WP_Query( $args );\n echo &quot;&lt;ul&gt;&quot;;\n while ( $products-&gt;have_posts() ) {\n $products-&gt;the_post();\n ?&gt;\n &lt;li&gt;\n &lt;a href=&quot;&lt;?php the_permalink(); ?&gt;&quot;&gt;\n &lt;?php the_title(); ?&gt;\n &lt;/a&gt;\n &lt;/li&gt;\n &lt;?php\n }\n echo &quot;&lt;/ul&gt;&quot;;\n }\n}\n</code></pre>\n<p>So far with the code I have been using can only list all categories and all products, even hidden ones.</p>\n<p>Any insights? I have been googling and tinkering for hours, without success.</p>\n",
        "tags": [
            "php",
            "wordpress",
            "woocommerce",
            "product",
            "custom-taxonomy"
        ]
    },
    {
        "index": 92,
        "question_id": 79623404,
        "title": "How to hide/show a shinyWidgets dropdown with shinyjs?",
        "body": "<p>Is there a way to hide shinyWidgets dropdown with shinyjs? Since dropdown has an id argument, i thought it could be hidden/shown like any other input. But somehow its not working. Below you find a minimal Reprex:</p>\n<pre><code>library(shiny)\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n  shinyjs::useShinyjs(),# this enables shinyjs functionality\n    # Application title\n    titlePanel(&quot;Old Faithful Geyser Data&quot;),\n\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n        sidebarPanel(\n          shinyjs::hidden(\n            shinyWidgets::dropdown(inputId = &quot;dropdown&quot;,\n            sliderInput(&quot;bins&quot;,\n                        &quot;Number of bins:&quot;,\n                        min = 1,\n                        max = 50,\n                        value = 30)\n              )\n            )\n          ),\n\n\n        # Show a plot of the generated distribution\n        mainPanel(\n          actionButton(&quot;showdd&quot;, &quot;show dropdown&quot;),\n           plotOutput(&quot;distPlot&quot;)\n        )\n    )\n)\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n\n  observeEvent(input$showdd,{\n    print(&quot;test&quot;)\n    shinyjs::show(id = &quot;dropdown&quot;)\n    shinyjs::show(id = &quot;bins&quot;)\n  } )\n  \n  \n    output$distPlot &lt;- renderPlot({\n        # generate bins based on input$bins from ui.R\n        x    &lt;- faithful[, 2]\n        bins &lt;- seq(min(x), max(x), length.out = input$bins + 1)\n\n        # draw the histogram with the specified number of bins\n        hist(x, breaks = bins, col = 'darkgray', border = 'white',\n             xlab = 'Waiting time to next eruption (in mins)',\n             main = 'Histogram of waiting times')\n    })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)\n</code></pre>\n",
        "tags": [
            "r",
            "shiny",
            "shinyjs",
            "shinywidgets"
        ]
    },
    {
        "index": 93,
        "question_id": 79623523,
        "title": "Add Column Names to retrieved data from pymysql",
        "body": "<p>I have a simple SQL command via pymsql to retrieve data</p>\n<pre><code>db = pymysql.connect(\n    db=DATABASE,\n    passwd=DB_PASSWORD,\n    host=DB_HOST,\n    user=DB_USER,\n)\ncursor = db.cursor()\ncursor.execute(&quot;&quot;&quot;\n    select flight, aircraft_model\n    from flights\n    where flights.aircraft_type in ('boeing', 'airbus')\n&quot;&quot;&quot;)\nres = cursor.fetchall()\n</code></pre>\n<p>This will return a array of tuples e.g.</p>\n<pre><code>[\n('tk123', 'b737'),\n('us123', 'a230')\n]\n</code></pre>\n<p>How can I have the first tuple to be the column names e.g.</p>\n<pre><code>[\n('flight', 'aircraft_model')\n('tk123', 'b737'),\n('us123', 'a230')\n]\n</code></pre>\n<p>I thought it was quite obvious from above, but I am not looking for similar to <a href=\"https://stackoverflow.com/questions/5010042/mysql-get-column-name-or-alias-from-query\">MySQL: Get column name or alias from query</a> as that has a different output format than I specified.</p>\n",
        "tags": [
            "python",
            "pymysql"
        ]
    },
    {
        "index": 94,
        "question_id": 79623635,
        "title": "What&#39;s the difference between cloning an mpsc::Sender and wrapping it in Arc for sharing between threads?",
        "body": "<p>I'm building a Rust client that includes a Sender field:</p>\n<pre class=\"lang-rust prettyprint-override\"><code>struct Client {\n   tx: std::sync::mpsc::Sender&lt;String&gt;,\n   some_other_stuff: i32,\n}\n</code></pre>\n<p>To share this Client between threads, I wrapped it in an <code>Arc&lt;Client&gt;</code> and used <code>Arc::clone()</code> to pass handles around. Later I realized that <code>mpsc::Sender</code> is itself cheaply cloneable via <code>.clone()</code>, and I'm now wondering if I missed something fundamental.</p>\n<p>To illustrate my question, consider the following simplified example:</p>\n<pre class=\"lang-rust prettyprint-override\"><code>use std::sync::{mpsc, Arc};\nuse std::thread;\n\nfn main() {\n    let (tx, rx) = mpsc::channel::&lt;u32&gt;();\n\n    // Variant A – real clone\n    let tx1 = tx.clone();\n    let tx2 = tx.clone();\n\n    // Variant B – wrap one Sender in Arc\n    let arc_tx = Arc::new(tx);          // only **one** Sender internally\n    let arc_tx1 = arc_tx.clone();       // just more Arc pointers\n    let arc_tx2 = arc_tx.clone();\n\n    // spawn threads and send a few numbers …\n}\n</code></pre>\n<p>Both approaches seem to let multiple threads send messages concurrently. But is there a practical or semantic difference between:</p>\n<ul>\n<li>Cloning the Sender (<code>tx.clone()</code>), versus</li>\n<li>Sharing a single Sender via <code>Arc&lt;Sender&lt;T&gt;&gt;</code>?</li>\n</ul>\n<p>Which approach is preferred, and why? And if cloning is the right choice, how can I rewrite my <code>Client</code> struct to use <code>.clone()</code> on <code>Sender</code> when sharing handles?</p>\n",
        "tags": [
            "rust",
            "rust-tokio"
        ]
    },
    {
        "index": 95,
        "question_id": 79623641,
        "title": "How to properly combine two ggplots and properly align axis and strips/titles?",
        "body": "<p>I need to combine two ggplots. They should have labels (A, B, and C) as for being used in a publication. The first plot is a <code>facet_wrap()</code>. This is my code:</p>\n<pre><code>library(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\n# First plot with facets\np1 &lt;- ggplot(mtcars %&gt;%\n               filter(cyl %in% c(&quot;4&quot;, &quot;6&quot;)) %&gt;%\n               mutate(cyl_label=paste0(&quot;label_&quot;, cyl)), \n             aes(x=mpg, y=wt)) +\n  geom_point() +\n  theme_bw() +\n  theme(aspect.ratio = 2,\n        strip.text.x = element_text(hjust = 0, colour = &quot;black&quot;, size = 14,\n                                    margin = unit(c(t=0.15,r=0,b=0.15,l=0), &quot;cm&quot;)),\n    strip.background = element_blank()) +\n  facet_wrap(~ cyl_label, \n             labeller = labeller(cyl_label = c(label_4 = &quot;(A) First plot&quot;,\n                                               label_6 = &quot;(B) Second plot&quot;))) +\n  theme(aspect.ratio = 2)\n\n# Second plot with title\np2 &lt;- ggplot(mtcars, aes(x=hp, y=wt)) +\n  geom_point() +\n  ggtitle(&quot;(C) Third plot&quot;) +\n  theme_bw() +\n  theme(\n    aspect.ratio = 1, \n    plot.title = element_text(hjust = 0, colour = &quot;black&quot;, size = 14,\n                              margin = unit(c(t=0.15,r=0,b=0.15,l=0), &quot;cm&quot;)))\n\n# Combine plots side by side\ncombined_plot &lt;- p1 + p2 + \n  plot_layout(ncol = 2) \n</code></pre>\n<p>This is the plot I got:</p>\n<p><img src=\"https://i.sstatic.net/kZJIPAGb.png\" alt=\"\" /></p>\n<p>The combined plot have two issues:</p>\n<ol>\n<li>The &quot;(C)&quot; label is not aligned, and</li>\n<li>the y dimension of both plots is not aligned.</li>\n</ol>\n<p>Interestingly, the second plot by itself has the title in the correct position:</p>\n<p><img src=\"https://i.sstatic.net/OlvHfzd1.png\" alt=\"\" /></p>\n",
        "tags": [
            "r",
            "ggplot2",
            "patchwork"
        ]
    },
    {
        "index": 96,
        "question_id": 79623642,
        "title": "Python Threading + Tkinter: Event.set() doesn&#39;t terminate thread if bound to Tk window closing",
        "body": "<p>I'm writing an app that generates a live histogram to be displayed in a Tkinter window. This is more or less how the app works:</p>\n<ul>\n<li>A <code>Histogram</code> class is responsible for generating the embedded histogram inside the Tk window, collecting data and update the histogram accordingly.</li>\n<li>There is a 'Start' button that creates a thread which is responsible for\n<ol>\n<li>collecting data points and putting them in a queue,</li>\n<li>calling an <code>update_histogram</code> function which pulls the new data from the queue and redraws the histogram.</li>\n</ol>\n</li>\n<li>Since the function in the thread runs a loop indefinitely, there's also a 'Stop' button which stops the loop by setting an <code>Event()</code>.</li>\n<li>The <code>stop</code> function called by the button is also called when trying to close the window <em>while the thread is running</em>.</li>\n</ul>\n<h3>The issue</h3>\n<p>Even if the same <code>stop</code> function is called by clicking the button or upon closing the window, if I try to close the window during a run the app freezes (<code>is_alive()</code> returns <code>True</code>), but not if I first click on the 'Stop' button and <em>then</em> close the window (<code>is_alive()</code> returns <code>False</code>). What am I doing wrong?</p>\n<h3>MWE</h3>\n<pre class=\"lang-py prettyprint-override\"><code>import tkinter as tk\nfrom tkinter import ttk\nfrom threading import Thread, Event\nfrom queue import Queue\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\nimport numpy as np\n\nclass Histogram():\n    def __init__(self, root: tk.Tk):\n        self.root = root\n        self.buffer: list[float] = []\n        self.event = Event()\n        self.queue = Queue()\n        self.stopped = False\n        self.fig, self.ax = plt.subplots(figsize=(4, 3), dpi=64, layout='tight')\n        self.ax.set_xlim(0, 80)\n        self.ax.set_ylim(0, 30)\n        self.ax.set_xlabel('Time (ns)')\n        self.ax.set_ylabel('Counts')\n        self.canvas = FigureCanvasTkAgg(self.fig, master=self.root)\n        self.canvas.draw()\n        self.canvas.get_tk_widget().grid(\n            column=0, columnspan=2, row=1, padx=6, pady=6, sticky='nesw'\n            )\n\n    def start(self) -&gt; None:\n        self.cleanup()  # Scrape canvas &amp; buffer if restarting\n        self.thread = Thread(target=self.follow)\n        self.thread.start()\n        self.stopped = True\n        self.root.protocol('WM_DELETE_WINDOW', self.kill)\n\n    def follow(self) -&gt; None:\n        count = 1\n        while not self.event.is_set():\n            data = np.random.normal(loc=40.0, scale=10.0)\n            self.queue.put(data)\n            self.update_histogram(n=count)\n            count += 1\n\n        self.event.clear()\n        self.stopped = True\n\n    def update_histogram(self, n: int) -&gt; None:\n        data = self.queue.get()\n        self.buffer.append(data)\n\n        if n % 5 == 0:  # Update every 5 new data points\n            if self.ax.patches:\n                _ = [b.remove() for b in self.ax.patches]\n            counts, bins = np.histogram(self.buffer, bins=80, range=(0, 80))\n            self.ax.stairs(counts, bins, color='blueviolet', fill=True)\n            # Add 10 to y upper limit if highest bar exceeds 95% of it\n            y_upper_lim = self.ax.get_ylim()[1]\n            if np.max(counts) &gt; y_upper_lim * 0.95:\n                self.ax.set_ylim(0, y_upper_lim + 10)\n            self.canvas.draw()\n        self.queue.task_done()\n\n    def cleanup(self) -&gt; None:\n        if self.ax.patches:\n            _ = [b.remove() for b in self.ax.patches]\n        self.buffer = []\n\n    def stop(self) -&gt; None:\n        self.event.set()\n\n    def kill(self) -&gt; None:\n        self.stop()\n        all_clear = self.stopped\n        while not all_clear:\n            all_clear = self.stopped\n        print(f'{self.thread.is_alive()=}')\n        self.root.quit()\n        self.root.destroy()\n\ndef main():\n    padding = dict(padx=12, pady=12, ipadx=6, ipady=6)\n    root = tk.Tk()\n    root.title('Live Histogram')\n\n    hist = Histogram(root=root)\n\n    start_button = ttk.Button(root, text='START', command=hist.start)\n    start_button.grid(column=0, row=0, **padding, sticky='new')\n    stop_button = ttk.Button(root, text='STOP', command=hist.stop)\n    stop_button.grid(column=1, row=0, **padding, sticky='new')\n\n    root.mainloop()\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n<p><strong>Note 1</strong>: The reason why I went for this fairly complicated setup is that I've learned that any other loop run in the main thread will cause the Tkinter mainloop to freeze, so that you can't interact with any widget while the loop is running.</p>\n<p><strong>Note 2</strong>: I'm pretty sure I'm doing exactly what the accepted answer says in <a href=\"https://stackoverflow.com/questions/20709416/thread-doesnt-close-on-exiting-tk-window\">this post</a> but here it doesn't work.</p>\n<p>This has been driving me crazy for days! Thank you in advance :)</p>\n",
        "tags": [
            "python",
            "multithreading",
            "tkinter",
            "python-multithreading",
            "matplotlib-widget"
        ]
    },
    {
        "index": 97,
        "question_id": 79623661,
        "title": "How do I stop the Eclipse C/C++ formatter from de-indenting when I formatting a second time",
        "body": "<p>I'm using the Eclipse C/C++ formatter and run into an issue where it removes indents on line wrapping on the second save. For example I'll write some code:</p>\n<pre><code>int array[] = {1, 2, 3, 4, 5, 6, 7, 8, 9};\n</code></pre>\n<p>It'll then format it to (exaggerated line limit):</p>\n<pre><code>int array[] = {1, 2, 3, 4,\n        5, 6, 7, 8, 9};\n</code></pre>\n<p>I'll then change something else in the file and format again. It now removes the line wrapping indentation on the original, unchanged code:</p>\n<pre><code>int array[] = {1, 2, 3, 4,\n5, 6, 7, 8, 9};\n</code></pre>\n<p>I've tried messing with the settings but can't find what could stop it. I'm expecting it to stay line wrapped with the indentation on wrapped lines (what's seen after the first formatting). I don't want to use the &quot;on/off tags&quot; as i think they're bulky. Is there an option in the formatter that can stop this?</p>\n<p>For clarification I'm using STM32CubeIDE version 1.18.0,\nand using a modified K&amp;R [built in] profile for the formatter, but it looks like the issue is in the unmodified profile as well.</p>\n",
        "tags": [
            "c",
            "eclipse",
            "eclipse-cdt"
        ]
    },
    {
        "index": 98,
        "question_id": 79623671,
        "title": "Find the largest itemset in agroup of itemsets with the same support efficiently",
        "body": "<p>I have a spark-DataFrame with two columns, ID and Items. Items is a list of strings.</p>\n<p>My goal is to find frequent subsets of the itemsets in my data. I am familiar with apriori and fp-growth and used the latter to find frequent subsets. But I have one more requirement, in cases where multiple itemsets along a path in the fp-tree have the same support, I only want to keep the largest itemset. In my example, [&quot;a&quot;] has the same support as [&quot;a&quot;, &quot;b&quot;]. Thus I am only interested in keeping the latter.</p>\n<p>Even that is in principal not a problem, simplest solution is grouping itemsets by support, selecting the one with the most items in it and delete all subsets of that set. My problem is that the number of possible combinations is extremly large. I have 60 different items and itemsets of up to 50 items.</p>\n<p>So my question is, is there anyway to make this more efficient?</p>\n<p>Here is a basic example of what I am initially doing:</p>\n<pre><code>from pyspark.ml.fpm import FPGrowth\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import explode, udf\nfrom pyspark.sql.types import ArrayType, IntegerType, StructType, StructField\n\n\nbasic_data = {100: [['a', 'b']],\n              101: [['a', 'b', 'c']],\n              102: [['a', 'b', 'c', 'd']],\n              103: [['a', 'b', 'c']],\n              104: [['a', 'b']],\n              105: [['a', 'b']],\n              106: [['c', 'e']],\n              107: [['c', 'e']],\n              108: [[ 'c', 'e']],\n              }\n\ndata = [(key, value[0]) for key, value in basic_data.items()]\nschema = ['id', 'items']\ndf = spark.createDataFrame(data, schema=schema)\n\nfpGrowth = FPGrowth(itemsCol = 'items', minSupport=0.3)\nmodel = fpGrowth.fit(df)\n\n# Display frequent itemsets\nfrequentItemsets = model.freqItemsets\nfrequentItemsets.show()\n</code></pre>\n<p>Which gives me this result:</p>\n<pre><code>+---------+----+\n|    items|freq|\n+---------+----+\n|      [a]|   6|\n|      [b]|   6|\n|   [b, a]|   6|\n|      [c]|   6|\n|   [c, b]|   3|\n|[c, b, a]|   3|\n|   [c, a]|   3|\n|      [e]|   3|\n|   [e, c]|   3|\n+---------+----+\n</code></pre>\n<p>I then group the data by frequency:</p>\n<pre><code>df = frequentItemsets.groupBy('freq').agg(F.collect_list('items').alias('items_list'))\ndf.show(truncate=False)\n\n+----+----------------------------------------+\n|freq|items_list                              |\n+----+----------------------------------------+\n|6   |[[b], [b, a], [a], [c]]                 |\n|3   |[[c, b], [c, b, a], [c, a], [e], [e, c]]|\n+----+----------------------------------------+\n</code></pre>\n<p>Next for each frequency I remove all itemsets that are subsets of another itemset with the same frequency. So for instance I remove [b] and [a] from the first row, because they are both subsets of [a,b].\nMy code for this is not the best, but I hope you get the idea:</p>\n<pre><code>def getlongestitem(itemlist:list)-&gt;int:\n    longestlen = 0\n    longestitem_index = -1\n    for i in range(len(itemlist)):\n        if len(itemlist[i]) &gt; longestlen:\n            longestlen = len(itemlist[i])\n            longestitem_index = i\n    return longestitem_index\n\n\ndef find_subsets(itemlist:list, index:int)-&gt;list:\n    '''\n    Find all subsets of itemlist that are subsets of itemlist[index]\n    Return a list of indexes of the subsets\n    '''\n    subset_indexes = []\n    longestitem = itemlist[index]\n    for i in range(len(itemlist)):\n        if all(element in longestitem for element in itemlist[i]):\n            subset_indexes.append(i)\n    return subset_indexes\n\n\ndef extract_items(itemlist:list)-&gt;list:\n    '''\n    Find the largest item in itemlist and find all subsets of itemlist that are subsets of the largest item.\n    Remove the largest item and all its subsets from itemlist. Repeat until itemlist is empty.\n    Return a list of the largest items.\n    '''\n    items = []\n    processed_indices = set()  # Track indices of processed items\n\n    while len(processed_indices) &lt; len(itemlist):\n        longestitem_index = getlongestitem(itemlist)\n        \n        while longestitem_index in processed_indices:\n            itemlist[longestitem_index] = []  \n            longestitem_index = getlongestitem(itemlist)\n        \n        subset_indexes = find_subsets(itemlist, longestitem_index)\n        items.append(itemlist[longestitem_index])\n        \n        processed_indices.update(subset_indexes)\n    \n    return items\n\n\nextract_items_udf = udf(extract_items, ArrayType(ArrayType(StringType())))\n\ndf_with_items = df.withColumn(&quot;extracted_items&quot;, extract_items_udf(df[&quot;items_list&quot;]))\n\nresult_df = df_with_items.select(df_with_items[&quot;freq&quot;], explode(df_with_items[&quot;extracted_items&quot;]).alias(&quot;items&quot;))\n\nresult_df.show(truncate=False)\n</code></pre>\n<p>The results then looks like this:</p>\n<pre><code>+----+---------+\n|freq|items    |\n+----+---------+\n|3   |[c, b, a]|\n|3   |[e, c]   |\n|6   |[b, a]   |\n|6   |[c]      |\n+----+---------+\n</code></pre>\n<p>Now that is all fine and runs - on a small dataset. But my issue is that the number of items I have is around 60 and thus the number of combinations is extremly large. fpgrowth delivered results but the next step, removing those subsets crashes because I run out of memory. I tried batching this by looking at one frequency at a time but even then I have the problem that there are so many itemsets with the same frequency that I can not process this well.</p>\n",
        "tags": [
            "python",
            "algorithm",
            "pyspark",
            "data-mining",
            "fpgrowth"
        ]
    },
    {
        "index": 99,
        "question_id": 79623834,
        "title": "Spring repository: find by id on related table",
        "body": "<p>I have two models (written in Kotlin):</p>\n<pre><code>@Entity\n@Table(name = &quot;a&quot;)\nclass AModel(\n\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    var id: Long? = null,\n)\n</code></pre>\n<p>and a second one with a one to one relation to this previos one</p>\n<pre><code>@Entity\n@Table(name = &quot;b&quot;)\nclass BModel(\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    var id: Long? = null,\n\n    @field:OneToOne\n    @JoinColumn(name = &quot;original_a_id&quot;)\n    var originalA: AModel? = null,\n)\n</code></pre>\n<p>Then in BRepository I have a method to fetch a instance of B by the id of the related model A.</p>\n<p><code>fun findByOriginalAId(originalAId: Long): BModel?</code></p>\n<p>That until recently it worked correctly, but I'm trying to upgrade my app to Spring 3.4 and latest version of Hibernate and suddenly this is a problem.\nThis method on the repository no longer finds the model.\nThe only change I implemented was to change the type of the id fields to Long? and default to null, and deleage to hibernate the actual value generation, which I read I need to do.</p>\n<p>I found a workaround for the repository method to annotate it with</p>\n<p><code>@Query(&quot;SELECT b FROM BModel b WHERE b.originalA.id = :originalAId&quot;)</code></p>\n<p>But why do I suddenly need to do this? Is there a way to obtain the same result without the cumbersome annotation?</p>\n",
        "tags": [
            "java",
            "spring",
            "kotlin",
            "hibernate"
        ]
    },
    {
        "index": 100,
        "question_id": 79623886,
        "title": "How to express a trait bound for `&amp;&#39;static str: From&lt;&amp;&#39;a T&gt;`?",
        "body": "<p>I'm trying to implement something like this:</p>\n<pre class=\"lang-rust prettyprint-override\"><code>pub trait InnerTypeTrait:\n    Debug + Clone + std::fmt::Display + PartialEq + Eq + Into&lt;&amp;'static str&gt; + Send + Sync + 'static\n{\n}\n\n#[derive(Debug, Clone, strum::Display, PartialEq, Eq, strum::IntoStaticStr)]\npub enum OuterType&lt;R: InnerTypeTrait&gt; {\n    Foo\n    #[strum(transparent)]\n    Bar(R),\n}\n</code></pre>\n<p>So that I can use Strum's macros to generate <code>&amp;'static str</code> for me and use a generic parameter in the enum variant.</p>\n<p>Strum requires (for <code>IntoStaticStr</code>) that R needs to implement <code>&amp;'a str: From&lt;&amp;'a R&gt;</code> conversion.</p>\n<p>When I'm adding this (high-level) bound in <code>where</code>:</p>\n<pre><code>pub enum OuterType&lt;R: InnerTypeTrait&gt;\nwhere\n    for&lt;'a&gt; &amp;'static str: From&lt;&amp;'a R&gt; {\n...\n</code></pre>\n<p>then I hit a recursion limit:</p>\n<pre><code>overflow evaluating the requirement `for&lt;'a&gt; &amp;'static str: std::convert::From&lt;&amp;'a str&gt;`\n</code></pre>\n<p>I'm a bit at a loss - how do I define in a trait (or on the enum) this requirement so that Strum is happy? :)</p>\n",
        "tags": [
            "rust"
        ]
    }
]